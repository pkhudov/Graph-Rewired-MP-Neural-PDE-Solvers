Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Number of parameters: 1031645
Training started at: 2024-11-14 20:50:45
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.299027780557431
Training Loss (progress: 0.10): 0.5219014397825744
Training Loss (progress: 0.20): 0.35808636358669427
Training Loss (progress: 0.30): 0.2716706807575162
Training Loss (progress: 0.40): 0.2318165289014258
Training Loss (progress: 0.50): 0.2027026684605446
Training Loss (progress: 0.60): 0.17485034185794895
Training Loss (progress: 0.70): 0.16618341295450653
Training Loss (progress: 0.80): 0.16675033951372537
Training Loss (progress: 0.90): 0.13216706473528683
Evaluation on validation dataset:
Step 25, mean loss 0.19606178552794293
Step 50, mean loss 0.22497099835642814
Step 75, mean loss 0.21739660849772618
Step 100, mean loss 0.3627746720108594
Step 125, mean loss 0.26402436247913735
Step 150, mean loss 0.3233461073045686
Step 175, mean loss 0.582640930034078
Step 200, mean loss 0.5813850777045562
Step 225, mean loss 0.5034865687025202
Unrolled forward losses 29.502742560742032
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.2281246567101951
Step 50, mean loss 0.2621045822064969
Step 75, mean loss 0.2639316223851498
Step 100, mean loss 0.3184042700447482
Step 125, mean loss 0.33852276941219506
Step 150, mean loss 0.28780715764990783
Step 175, mean loss 0.3503237822587969
Step 200, mean loss 0.5155433033838935
Step 225, mean loss 0.591427097235167
Unrolled forward losses 29.862708087927764
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1:26:48.246022 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.3007632793031708
Training Loss (progress: 0.10): 0.26691322170840315
Training Loss (progress: 0.20): 0.25265295231919344
Training Loss (progress: 0.30): 0.24487892453835094
Training Loss (progress: 0.40): 0.22731695313655145
Training Loss (progress: 0.50): 0.2348913889352924
Training Loss (progress: 0.60): 0.19817498452954763
Training Loss (progress: 0.70): 0.210171020041676
Training Loss (progress: 0.80): 0.19979005097456057
Training Loss (progress: 0.90): 0.19332524790964709
Evaluation on validation dataset:
Step 25, mean loss 0.13749090107300388
Step 50, mean loss 0.16648884270310937
Step 75, mean loss 0.13639915006790893
Step 100, mean loss 0.15197121739216524
Step 125, mean loss 0.17398281301154023
Step 150, mean loss 0.2108989204771061
Step 175, mean loss 0.3080007137131836
Step 200, mean loss 0.4495746274830634
Step 225, mean loss 0.3854415307193019
Unrolled forward losses 6.257036917557994
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.16330955871706435
Step 50, mean loss 0.15215083258180068
Step 75, mean loss 0.15887777534971884
Step 100, mean loss 0.17625234742478432
Step 125, mean loss 0.2236355416602644
Step 150, mean loss 0.19145715713428374
Step 175, mean loss 0.2353099018228932
Step 200, mean loss 0.304538081472513
Step 225, mean loss 0.37299719163602246
Unrolled forward losses 7.9005828305078
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  3:00:59.552598 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.24422179827319984
Training Loss (progress: 0.10): 0.2446306490439787
Training Loss (progress: 0.20): 0.2521571296971093
Training Loss (progress: 0.30): 0.23093039393777967
Training Loss (progress: 0.40): 0.24054879488088904
Training Loss (progress: 0.50): 0.2313371435962195
Training Loss (progress: 0.60): 0.2417827614569498
Training Loss (progress: 0.70): 0.22831671095005993
Training Loss (progress: 0.80): 0.21329116753636512
Training Loss (progress: 0.90): 0.2256842233394704
Evaluation on validation dataset:
Step 25, mean loss 0.1366172450222496
Step 50, mean loss 0.13219468224603786
Step 75, mean loss 0.1260164403768928
Step 100, mean loss 0.12934334354536875
Step 125, mean loss 0.13912092678228027
Step 150, mean loss 0.16352557290318298
Step 175, mean loss 0.262308928932083
Step 200, mean loss 0.367152634769177
Step 225, mean loss 0.32199933388092583
Unrolled forward losses 4.215657666346024
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.136349739353745
Step 50, mean loss 0.1217376237694712
Step 75, mean loss 0.12865700857576776
Step 100, mean loss 0.1425356655326357
Step 125, mean loss 0.195164803616459
Step 150, mean loss 0.14573360992295156
Step 175, mean loss 0.17400017140735086
Step 200, mean loss 0.23855462921418186
Step 225, mean loss 0.302885642110497
Unrolled forward losses 4.699630759130334
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  4:40:42.747931 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.23934867412320932
Training Loss (progress: 0.10): 0.23151023045507432
Training Loss (progress: 0.20): 0.21786779065215048
Training Loss (progress: 0.30): 0.2105122773658889
Training Loss (progress: 0.40): 0.21345875035476997
Training Loss (progress: 0.50): 0.1897518844725745
Training Loss (progress: 0.60): 0.2063231266929961
Training Loss (progress: 0.70): 0.1911351237847968
Training Loss (progress: 0.80): 0.19601824799642328
Training Loss (progress: 0.90): 0.20307181054161993
Evaluation on validation dataset:
Step 25, mean loss 0.09252916245425877
Step 50, mean loss 0.09731833824480217
Step 75, mean loss 0.09955397001863314
Step 100, mean loss 0.10356476492189388
Step 125, mean loss 0.11580611317291697
Step 150, mean loss 0.1333347808384419
Step 175, mean loss 0.23194931424985246
Step 200, mean loss 0.3230656809394595
Step 225, mean loss 0.26886544995254147
Unrolled forward losses 3.120947777757575
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10023492948454149
Step 50, mean loss 0.09010211906028232
Step 75, mean loss 0.10442306821058445
Step 100, mean loss 0.12078247745272142
Step 125, mean loss 0.1492962068932267
Step 150, mean loss 0.1266334271675514
Step 175, mean loss 0.15317351750944425
Step 200, mean loss 0.20211633598552126
Step 225, mean loss 0.2504265345011879
Unrolled forward losses 3.726729399137541
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  6:21:10.261067 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.20606716497655533
Training Loss (progress: 0.10): 0.21038610162239268
Training Loss (progress: 0.20): 0.2135757296150406
Training Loss (progress: 0.30): 0.18447428884114167
Training Loss (progress: 0.40): 0.17945307550734652
Training Loss (progress: 0.50): 0.18579943118357217
Training Loss (progress: 0.60): 0.21110133722120583
Training Loss (progress: 0.70): 0.19223426736709912
Training Loss (progress: 0.80): 0.18537053058454886
Training Loss (progress: 0.90): 0.19265181869187606
Evaluation on validation dataset:
Step 25, mean loss 0.08006230285696318
Step 50, mean loss 0.09460832365334643
Step 75, mean loss 0.07887009756551171
Step 100, mean loss 0.09415174818931121
Step 125, mean loss 0.10557137607500514
Step 150, mean loss 0.12283754932399157
Step 175, mean loss 0.20349157630458076
Step 200, mean loss 0.29780905298464366
Step 225, mean loss 0.22359849871070422
Unrolled forward losses 3.1128729655018432
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0879628582770161
Step 50, mean loss 0.07308288014008817
Step 75, mean loss 0.08092258700615376
Step 100, mean loss 0.10699367015073695
Step 125, mean loss 0.1469244796057434
Step 150, mean loss 0.11942678295796627
Step 175, mean loss 0.14383770157265804
Step 200, mean loss 0.19687832578228037
Step 225, mean loss 0.25114220834820433
Unrolled forward losses 3.677331823890899
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  8:03:33.926894 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.16542216700872764
Training Loss (progress: 0.10): 0.1578794686901691
Training Loss (progress: 0.20): 0.16266765466632496
Training Loss (progress: 0.30): 0.16267862235073302
Training Loss (progress: 0.40): 0.16209388561530563
Training Loss (progress: 0.50): 0.16303823736326623
Training Loss (progress: 0.60): 0.15287366213304127
Training Loss (progress: 0.70): 0.15832794148883492
Training Loss (progress: 0.80): 0.1599799866919003
Training Loss (progress: 0.90): 0.16097982496516614
Evaluation on validation dataset:
Step 25, mean loss 0.07451093706565964
Step 50, mean loss 0.07814131211255362
Step 75, mean loss 0.07812061240694525
Step 100, mean loss 0.08383500436631255
Step 125, mean loss 0.09446951994408274
Step 150, mean loss 0.11135862877160727
Step 175, mean loss 0.1933969867789483
Step 200, mean loss 0.28296584614204556
Step 225, mean loss 0.20507767009073619
Unrolled forward losses 2.5259703577218575
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07760081578630698
Step 50, mean loss 0.06494143921742057
Step 75, mean loss 0.07851515595588465
Step 100, mean loss 0.09411473458804034
Step 125, mean loss 0.1305342233446343
Step 150, mean loss 0.10787272750932303
Step 175, mean loss 0.13372221735532502
Step 200, mean loss 0.16974261454010026
Step 225, mean loss 0.21850268002731665
Unrolled forward losses 2.908972134423176
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  9:46:15.943142 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.1510338135434641
Training Loss (progress: 0.10): 0.15857179612396324
Training Loss (progress: 0.20): 0.15283174708538427
Training Loss (progress: 0.30): 0.15921361515521465
Training Loss (progress: 0.40): 0.1548708881386135
Training Loss (progress: 0.50): 0.16263499439772586
Training Loss (progress: 0.60): 0.15311980527885943
Training Loss (progress: 0.70): 0.14588000655408423
Training Loss (progress: 0.80): 0.1490732283802522
Training Loss (progress: 0.90): 0.15813275245779806
Evaluation on validation dataset:
Step 25, mean loss 0.06715498292897915
Step 50, mean loss 0.08051438796657603
Step 75, mean loss 0.072743819724469
Step 100, mean loss 0.07699555342812471
Step 125, mean loss 0.08416799852775775
Step 150, mean loss 0.10296910804270287
Step 175, mean loss 0.178620159160221
Step 200, mean loss 0.2669021476238467
Step 225, mean loss 0.19696439526093304
Unrolled forward losses 2.40461211752097
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07537509193138162
Step 50, mean loss 0.05875701987847951
Step 75, mean loss 0.06826797824462832
Step 100, mean loss 0.08708489758505192
Step 125, mean loss 0.1220167120561855
Step 150, mean loss 0.09697989483897917
Step 175, mean loss 0.12287338136541652
Step 200, mean loss 0.15744127041148057
Step 225, mean loss 0.21511824049172248
Unrolled forward losses 2.803523535636173
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  11:28:56.267578 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.14731488824804176
Training Loss (progress: 0.10): 0.14887414054579354
Training Loss (progress: 0.20): 0.14274280297851338
Training Loss (progress: 0.30): 0.15278289251697733
Training Loss (progress: 0.40): 0.1534311152622123
Training Loss (progress: 0.50): 0.15065753821984101
Training Loss (progress: 0.60): 0.16042260324025887
Training Loss (progress: 0.70): 0.15423971764247377
Training Loss (progress: 0.80): 0.1422327605760634
Training Loss (progress: 0.90): 0.16229612047177192
Evaluation on validation dataset:
Step 25, mean loss 0.07195124566060818
Step 50, mean loss 0.0713863598179899
Step 75, mean loss 0.06870568996869303
Step 100, mean loss 0.07368494832732175
Step 125, mean loss 0.0801195553006009
Step 150, mean loss 0.09822829489726448
Step 175, mean loss 0.1783426175013841
Step 200, mean loss 0.2397449080074362
Step 225, mean loss 0.19245872610706574
Unrolled forward losses 2.4633762207992387
Unrolled forward base losses 2.927822615141285
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.1433032710691602
Training Loss (progress: 0.10): 0.1511044456332312
Training Loss (progress: 0.20): 0.15677099599165223
Training Loss (progress: 0.30): 0.14486920178927148
Training Loss (progress: 0.40): 0.14459400747754234
Training Loss (progress: 0.50): 0.14572821765298238
Training Loss (progress: 0.60): 0.14278182588991484
Training Loss (progress: 0.70): 0.13992663789143917
Training Loss (progress: 0.80): 0.14031249665206658
Training Loss (progress: 0.90): 0.13459668408509706
Evaluation on validation dataset:
Step 25, mean loss 0.060346050026206854
Step 50, mean loss 0.06342201338747877
Step 75, mean loss 0.07203858959775594
Step 100, mean loss 0.0793004243131586
Step 125, mean loss 0.07900413016044965
Step 150, mean loss 0.09625060533002555
Step 175, mean loss 0.1775706642511296
Step 200, mean loss 0.23425828001050739
Step 225, mean loss 0.1870091665884501
Unrolled forward losses 2.2163685370208057
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.062457700244052894
Step 50, mean loss 0.053561994735945875
Step 75, mean loss 0.07046072491301154
Step 100, mean loss 0.08337707342875325
Step 125, mean loss 0.11675714371651462
Step 150, mean loss 0.10113861356052084
Step 175, mean loss 0.11710384566232133
Step 200, mean loss 0.15129024949435504
Step 225, mean loss 0.1951625601600866
Unrolled forward losses 2.5572773179866175
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  14:55:48.855309 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.136959324922362
Training Loss (progress: 0.10): 0.15196259224268846
Training Loss (progress: 0.20): 0.14387455718012127
Training Loss (progress: 0.30): 0.14340610812630933
Training Loss (progress: 0.40): 0.1417898182837766
Training Loss (progress: 0.50): 0.15015194066851012
Training Loss (progress: 0.60): 0.14010854010797608
Training Loss (progress: 0.70): 0.13946850494452526
Training Loss (progress: 0.80): 0.14631316308709358
Training Loss (progress: 0.90): 0.1445029191358513
Evaluation on validation dataset:
Step 25, mean loss 0.05889485723174316
Step 50, mean loss 0.06914712909269768
Step 75, mean loss 0.06032565127735799
Step 100, mean loss 0.07062216142532868
Step 125, mean loss 0.07536748431613041
Step 150, mean loss 0.09439403504057958
Step 175, mean loss 0.17660150013296436
Step 200, mean loss 0.21977378229039826
Step 225, mean loss 0.1739039992109649
Unrolled forward losses 2.0938390104548157
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06199592461351104
Step 50, mean loss 0.052560902059768225
Step 75, mean loss 0.060800529646690936
Step 100, mean loss 0.07621218191345078
Step 125, mean loss 0.1105506331088964
Step 150, mean loss 0.09311596157987376
Step 175, mean loss 0.10856893246661682
Step 200, mean loss 0.14452040907848931
Step 225, mean loss 0.19204847990951973
Unrolled forward losses 2.5777030274388375
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  16:38:31.464638 

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.1307361883662962
Training Loss (progress: 0.10): 0.12321958299346364
Training Loss (progress: 0.20): 0.13568029693164624
Training Loss (progress: 0.30): 0.12039328840787847
Training Loss (progress: 0.40): 0.13160606797711247
Training Loss (progress: 0.50): 0.1296744522878437
Training Loss (progress: 0.60): 0.12757100444359246
Training Loss (progress: 0.70): 0.11877508750580208
Training Loss (progress: 0.80): 0.1324443115938696
Training Loss (progress: 0.90): 0.13305978245837816
Evaluation on validation dataset:
Step 25, mean loss 0.05631046001389202
Step 50, mean loss 0.06030058111933877
Step 75, mean loss 0.05860696744192717
Step 100, mean loss 0.06870166341815562
Step 125, mean loss 0.0718278295429991
Step 150, mean loss 0.09096873987115606
Step 175, mean loss 0.16614061140107225
Step 200, mean loss 0.20944040721797852
Step 225, mean loss 0.17185267902581208
Unrolled forward losses 2.150983146158177
Unrolled forward base losses 2.927822615141285
Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.12374736728936873
Training Loss (progress: 0.10): 0.12484245053969417
Training Loss (progress: 0.20): 0.13260087422253775
Training Loss (progress: 0.30): 0.11564571409205948
Training Loss (progress: 0.40): 0.13003864092450562
Training Loss (progress: 0.50): 0.12165522786103594
Training Loss (progress: 0.60): 0.12335709791504354
Training Loss (progress: 0.70): 0.1363806398937961
Training Loss (progress: 0.80): 0.1310573309316522
Training Loss (progress: 0.90): 0.12831151234325922
Evaluation on validation dataset:
Step 25, mean loss 0.05487840373079194
Step 50, mean loss 0.05980497690318095
Step 75, mean loss 0.059208548344695425
Step 100, mean loss 0.06479825067207123
Step 125, mean loss 0.07019103602052523
Step 150, mean loss 0.09152522028755597
Step 175, mean loss 0.164512965140786
Step 200, mean loss 0.20647684654385753
Step 225, mean loss 0.17009772850989952
Unrolled forward losses 2.039607104340841
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.056310868912303996
Step 50, mean loss 0.049192115487344784
Step 75, mean loss 0.05925414659562317
Step 100, mean loss 0.07384062498938529
Step 125, mean loss 0.10872476335757149
Step 150, mean loss 0.09053552647754329
Step 175, mean loss 0.1064659666902092
Step 200, mean loss 0.13315514428031977
Step 225, mean loss 0.18828258750860594
Unrolled forward losses 2.4321372036630526
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  20:04:29.902216 

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.1249753663407584
Training Loss (progress: 0.10): 0.11971000946288014
Training Loss (progress: 0.20): 0.12363122097063871
Training Loss (progress: 0.30): 0.12233639511374449
Training Loss (progress: 0.40): 0.1303203877117982
Training Loss (progress: 0.50): 0.1205274294958268
Training Loss (progress: 0.60): 0.13400018434592925
Training Loss (progress: 0.70): 0.1267789661241514
Training Loss (progress: 0.80): 0.12067511298606906
Training Loss (progress: 0.90): 0.12563829483610553
Evaluation on validation dataset:
Step 25, mean loss 0.05578365768646032
Step 50, mean loss 0.05738512041660949
Step 75, mean loss 0.05945133673327579
Step 100, mean loss 0.06602455709874952
Step 125, mean loss 0.06777697852017728
Step 150, mean loss 0.0879824208668312
Step 175, mean loss 0.16013744855898326
Step 200, mean loss 0.2036561902330533
Step 225, mean loss 0.16744824576715678
Unrolled forward losses 2.124891131866344
Unrolled forward base losses 2.927822615141285
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.11836721988520703
Training Loss (progress: 0.10): 0.1312108937246254
Training Loss (progress: 0.20): 0.12870345463165894
Training Loss (progress: 0.30): 0.11924369284824465
Training Loss (progress: 0.40): 0.13020299315957687
Training Loss (progress: 0.50): 0.11896895884954656
Training Loss (progress: 0.60): 0.1198433531465634
Training Loss (progress: 0.70): 0.12544632027850464
Training Loss (progress: 0.80): 0.12650674163786269
Training Loss (progress: 0.90): 0.13534033024955114
Evaluation on validation dataset:
Step 25, mean loss 0.054166956535942695
Step 50, mean loss 0.05730325273373703
Step 75, mean loss 0.06000494212453324
Step 100, mean loss 0.0645123606368652
Step 125, mean loss 0.06899343409904851
Step 150, mean loss 0.08837919149350537
Step 175, mean loss 0.1615031083224151
Step 200, mean loss 0.2031480310696206
Step 225, mean loss 0.16622459248582347
Unrolled forward losses 1.9910455968540224
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.054247605822583644
Step 50, mean loss 0.04733311509978362
Step 75, mean loss 0.058747607266370835
Step 100, mean loss 0.07210188989075855
Step 125, mean loss 0.10908094473364552
Step 150, mean loss 0.08995734221609178
Step 175, mean loss 0.1063274091631023
Step 200, mean loss 0.13156048035939646
Step 225, mean loss 0.18369102548723928
Unrolled forward losses 2.4859504035381743
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  23:31:25.763696 

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.11603838424997485
Training Loss (progress: 0.10): 0.12495590886541803
Training Loss (progress: 0.20): 0.12459640976585508
Training Loss (progress: 0.30): 0.12138424233295493
Training Loss (progress: 0.40): 0.1254208316922653
Training Loss (progress: 0.50): 0.11471354322093832
Training Loss (progress: 0.60): 0.12925932522892836
Training Loss (progress: 0.70): 0.11835162057192591
Training Loss (progress: 0.80): 0.12494058105620065
Training Loss (progress: 0.90): 0.123349901590023
Evaluation on validation dataset:
Step 25, mean loss 0.056684966603521715
Step 50, mean loss 0.05876984854898264
Step 75, mean loss 0.06158620559811862
Step 100, mean loss 0.0643355743714896
Step 125, mean loss 0.06666650690934399
Step 150, mean loss 0.0889670107709387
Step 175, mean loss 0.16705128719152487
Step 200, mean loss 0.2019420585234354
Step 225, mean loss 0.15803972215855988
Unrolled forward losses 1.9286844994728751
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05248509227474332
Step 50, mean loss 0.04496123244742781
Step 75, mean loss 0.059734191171029814
Step 100, mean loss 0.07018389132196867
Step 125, mean loss 0.10186892455400917
Step 150, mean loss 0.0887037152609754
Step 175, mean loss 0.10760554180688363
Step 200, mean loss 0.1364652034409156
Step 225, mean loss 0.1847855346644022
Unrolled forward losses 2.340750743628769
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 1:15:13.045327 

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.12367984316453366
Training Loss (progress: 0.10): 0.11913084240439975
Training Loss (progress: 0.20): 0.11608568794518948
Training Loss (progress: 0.30): 0.12116846749668636
Training Loss (progress: 0.40): 0.1121344487662609
Training Loss (progress: 0.50): 0.12438526669444443
Training Loss (progress: 0.60): 0.11685667071737973
Training Loss (progress: 0.70): 0.11982691994451578
Training Loss (progress: 0.80): 0.11841495181726894
Training Loss (progress: 0.90): 0.11196597688869465
Evaluation on validation dataset:
Step 25, mean loss 0.052607170641447674
Step 50, mean loss 0.05625876386549791
Step 75, mean loss 0.0579335083097275
Step 100, mean loss 0.06302764598262708
Step 125, mean loss 0.06592953359477616
Step 150, mean loss 0.08529864481632518
Step 175, mean loss 0.16167085919445257
Step 200, mean loss 0.19923244434982326
Step 225, mean loss 0.16000070573416333
Unrolled forward losses 1.9252684382411889
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05166445429068989
Step 50, mean loss 0.04454766444381276
Step 75, mean loss 0.056156365708538776
Step 100, mean loss 0.07019809261438845
Step 125, mean loss 0.10231559865413434
Step 150, mean loss 0.0870047030462346
Step 175, mean loss 0.10386985396364615
Step 200, mean loss 0.13161236503010512
Step 225, mean loss 0.18123300524807961
Unrolled forward losses 2.3242157557607066
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 2:59:20.412244 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.11570920311050113
Training Loss (progress: 0.10): 0.11629348489645314
Training Loss (progress: 0.20): 0.11954605665595554
Training Loss (progress: 0.30): 0.1166686240144397
Training Loss (progress: 0.40): 0.1248041829915934
Training Loss (progress: 0.50): 0.11987257426094396
Training Loss (progress: 0.60): 0.1202559118826657
Training Loss (progress: 0.70): 0.1311865417361012
Training Loss (progress: 0.80): 0.10958761837460566
Training Loss (progress: 0.90): 0.11617105468742887
Evaluation on validation dataset:
Step 25, mean loss 0.053256900345131475
Step 50, mean loss 0.05794036737790196
Step 75, mean loss 0.057682181101980944
Step 100, mean loss 0.0638595640763811
Step 125, mean loss 0.06701153599812823
Step 150, mean loss 0.08520278601673117
Step 175, mean loss 0.16093893312460328
Step 200, mean loss 0.1940541844133329
Step 225, mean loss 0.15920632343317556
Unrolled forward losses 1.9580238376735737
Unrolled forward base losses 2.927822615141285
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.12794943433463407
Training Loss (progress: 0.10): 0.1143736109082678
Training Loss (progress: 0.20): 0.11871702850889049
Training Loss (progress: 0.30): 0.12536800934655548
Training Loss (progress: 0.40): 0.11000926271742134
Training Loss (progress: 0.50): 0.1054211269834648
Training Loss (progress: 0.60): 0.11752326366923561
Training Loss (progress: 0.70): 0.1180133872053817
Training Loss (progress: 0.80): 0.10813256838794112
Training Loss (progress: 0.90): 0.12224768730961183
Evaluation on validation dataset:
Step 25, mean loss 0.05114105899437763
Step 50, mean loss 0.05442983170722309
Step 75, mean loss 0.05614946167163754
Step 100, mean loss 0.06392139953828974
Step 125, mean loss 0.06586691438626249
Step 150, mean loss 0.08565610826024496
Step 175, mean loss 0.15716332541640857
Step 200, mean loss 0.19529788296288914
Step 225, mean loss 0.1564637919529227
Unrolled forward losses 1.9099639672333644
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05078609626147762
Step 50, mean loss 0.044129504079302204
Step 75, mean loss 0.054793212535899624
Step 100, mean loss 0.0688141885637836
Step 125, mean loss 0.10261192860847831
Step 150, mean loss 0.0865604520207866
Step 175, mean loss 0.10406510258272894
Step 200, mean loss 0.1303739229957246
Step 225, mean loss 0.18105555505127863
Unrolled forward losses 2.330802792358863
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 6:28:08.446486 

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.11627796315727
Training Loss (progress: 0.10): 0.10901407120397863
Training Loss (progress: 0.20): 0.11948085150015045
Training Loss (progress: 0.30): 0.11787015693431258
Training Loss (progress: 0.40): 0.11418563518789294
Training Loss (progress: 0.50): 0.11445431624117755
Training Loss (progress: 0.60): 0.12523107939270456
Training Loss (progress: 0.70): 0.11501142552553907
Training Loss (progress: 0.80): 0.11216262913482072
Training Loss (progress: 0.90): 0.12026749858912845
Evaluation on validation dataset:
Step 25, mean loss 0.05189923567597485
Step 50, mean loss 0.054124358305506035
Step 75, mean loss 0.05577082819001611
Step 100, mean loss 0.06340819125504601
Step 125, mean loss 0.06496351882789331
Step 150, mean loss 0.08345471245005615
Step 175, mean loss 0.1578424843410185
Step 200, mean loss 0.19208368197112463
Step 225, mean loss 0.15612829352723773
Unrolled forward losses 1.9037229969109268
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.050766303601893395
Step 50, mean loss 0.04372573458017076
Step 75, mean loss 0.053402577869706355
Step 100, mean loss 0.06837168812913316
Step 125, mean loss 0.10171581036177474
Step 150, mean loss 0.08527227516277266
Step 175, mean loss 0.10126422146700406
Step 200, mean loss 0.12726648301581805
Step 225, mean loss 0.1801395189608065
Unrolled forward losses 2.311090244812607
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 8:14:52.610045 

Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.12384736499115266
Training Loss (progress: 0.10): 0.11756287110388638
Training Loss (progress: 0.20): 0.11091475506489612
Training Loss (progress: 0.30): 0.11455110938850359
Training Loss (progress: 0.40): 0.11640548819937101
Training Loss (progress: 0.50): 0.11259428939767953
Training Loss (progress: 0.60): 0.11051518086920623
Training Loss (progress: 0.70): 0.11813731514332543
Training Loss (progress: 0.80): 0.11407097776761518
Training Loss (progress: 0.90): 0.11818583127813069
Evaluation on validation dataset:
Step 25, mean loss 0.0513296773871609
Step 50, mean loss 0.052167064792991984
Step 75, mean loss 0.0564538163016787
Step 100, mean loss 0.06367464794636732
Step 125, mean loss 0.06453906832124828
Step 150, mean loss 0.0851259087046683
Step 175, mean loss 0.15827530641326643
Step 200, mean loss 0.18836392373743438
Step 225, mean loss 0.15629380019810135
Unrolled forward losses 1.906902300720943
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.12339214407806666
Training Loss (progress: 0.10): 0.12204437096677472
Training Loss (progress: 0.20): 0.1142562963819163
Training Loss (progress: 0.30): 0.11234547844576029
Training Loss (progress: 0.40): 0.11039676464708936
Training Loss (progress: 0.50): 0.11404914874764284
Training Loss (progress: 0.60): 0.11752851500524572
Training Loss (progress: 0.70): 0.11711430587769983
Training Loss (progress: 0.80): 0.11595509251366513
Training Loss (progress: 0.90): 0.1200247130257173
Evaluation on validation dataset:
Step 25, mean loss 0.05174617097895122
Step 50, mean loss 0.053217996052383844
Step 75, mean loss 0.05579167191507516
Step 100, mean loss 0.06360283194658038
Step 125, mean loss 0.06628989931595058
Step 150, mean loss 0.08615743395434503
Step 175, mean loss 0.15942131081542513
Step 200, mean loss 0.19185586946447658
Step 225, mean loss 0.1550249746114738
Unrolled forward losses 1.9536822461598757
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.11092234409614908
Training Loss (progress: 0.10): 0.11367650524667894
Training Loss (progress: 0.20): 0.11861468401042972
Training Loss (progress: 0.30): 0.10725976287522569
Training Loss (progress: 0.40): 0.12547346530690562
Training Loss (progress: 0.50): 0.11195704568891408
Training Loss (progress: 0.60): 0.12807498854262583
Training Loss (progress: 0.70): 0.1131623055575297
Training Loss (progress: 0.80): 0.10917211521662187
Training Loss (progress: 0.90): 0.1130535133658609
Evaluation on validation dataset:
Step 25, mean loss 0.050993774529074894
Step 50, mean loss 0.04938059966033735
Step 75, mean loss 0.055861279573941276
Step 100, mean loss 0.06309325008933833
Step 125, mean loss 0.06479896550743601
Step 150, mean loss 0.08259158229659867
Step 175, mean loss 0.15635433881410793
Step 200, mean loss 0.18979463297732094
Step 225, mean loss 0.1552329238171538
Unrolled forward losses 1.9576968357952944
Unrolled forward base losses 2.927822615141285
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.12227604822097195
Training Loss (progress: 0.10): 0.11822278846169755
Training Loss (progress: 0.20): 0.11223236809192572
Training Loss (progress: 0.30): 0.10520730432230002
Training Loss (progress: 0.40): 0.10574559979207648
Training Loss (progress: 0.50): 0.11823510061900055
Training Loss (progress: 0.60): 0.11144617709661249
Training Loss (progress: 0.70): 0.1089047109627596
Training Loss (progress: 0.80): 0.10962999517254537
Training Loss (progress: 0.90): 0.10714312150903049
Evaluation on validation dataset:
Step 25, mean loss 0.05124723271276039
Step 50, mean loss 0.05280224679572182
Step 75, mean loss 0.055406585966346705
Step 100, mean loss 0.0626249313607798
Step 125, mean loss 0.06450900428436582
Step 150, mean loss 0.0823845461306717
Step 175, mean loss 0.15254519372206965
Step 200, mean loss 0.1868056571145591
Step 225, mean loss 0.15320106991079133
Unrolled forward losses 1.8823980075670579
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04916510693992152
Step 50, mean loss 0.04214352138434685
Step 75, mean loss 0.053108217825593086
Step 100, mean loss 0.06620917520254377
Step 125, mean loss 0.10227877234657246
Step 150, mean loss 0.08366123441843298
Step 175, mean loss 0.10077727560721969
Step 200, mean loss 0.12437286670222134
Step 225, mean loss 0.1814220339313138
Unrolled forward losses 2.211204624645987
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 15:24:45.969659 

Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.11832844881851881
Training Loss (progress: 0.10): 0.10860064390111344
Training Loss (progress: 0.20): 0.10970841963290058
Training Loss (progress: 0.30): 0.11071650648080672
Training Loss (progress: 0.40): 0.1131174470969535
Training Loss (progress: 0.50): 0.12092362105038844
Training Loss (progress: 0.60): 0.10346235381422865
Training Loss (progress: 0.70): 0.1185809719739358
Training Loss (progress: 0.80): 0.11327323606961467
Training Loss (progress: 0.90): 0.11181509955775158
Evaluation on validation dataset:
Step 25, mean loss 0.05112135369533049
Step 50, mean loss 0.051426325892205554
Step 75, mean loss 0.05604101515299215
Step 100, mean loss 0.062147503606158255
Step 125, mean loss 0.06381735928222765
Step 150, mean loss 0.08306594120991542
Step 175, mean loss 0.15599602129841908
Step 200, mean loss 0.18836060731439114
Step 225, mean loss 0.15401613786057824
Unrolled forward losses 1.9316685339001105
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.11970346267092058
Training Loss (progress: 0.10): 0.11973253463150617
Training Loss (progress: 0.20): 0.10756776130230293
Training Loss (progress: 0.30): 0.10912234944659822
Training Loss (progress: 0.40): 0.10984240389896045
Training Loss (progress: 0.50): 0.12150406391083439
Training Loss (progress: 0.60): 0.10516553126670491
Training Loss (progress: 0.70): 0.11586694421405021
Training Loss (progress: 0.80): 0.11635877905007996
Training Loss (progress: 0.90): 0.10954986797320786
Evaluation on validation dataset:
Step 25, mean loss 0.04961609549320602
Step 50, mean loss 0.053082793777152144
Step 75, mean loss 0.05362199586374142
Step 100, mean loss 0.06188457606884777
Step 125, mean loss 0.06309552286054203
Step 150, mean loss 0.08183320956094907
Step 175, mean loss 0.1499916637771297
Step 200, mean loss 0.1846765543861037
Step 225, mean loss 0.15304889050672532
Unrolled forward losses 1.8391452286289085
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.048051970171702124
Step 50, mean loss 0.042086214447546
Step 75, mean loss 0.051752824677802525
Step 100, mean loss 0.06588139605014855
Step 125, mean loss 0.10072140206648961
Step 150, mean loss 0.08719631658646848
Step 175, mean loss 0.10230958085605385
Step 200, mean loss 0.12667601587922306
Step 225, mean loss 0.18022391827115508
Unrolled forward losses 2.2346744090072788
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11142050.pt
Training time:  1 day, 19:01:14.838250 

Test loss: 2.2346744090072788
Training time (until epoch 24):  {datetime.timedelta(days=1, seconds=68474, microseconds=838250)}
