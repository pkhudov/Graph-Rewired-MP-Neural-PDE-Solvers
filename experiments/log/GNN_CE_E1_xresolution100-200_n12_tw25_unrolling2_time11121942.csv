Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Number of parameters: 1031645
Training started at: 2024-11-12 19:42:24
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.3301659423684924
Training Loss (progress: 0.10): 0.32646178473823906
Training Loss (progress: 0.20): 0.24567821494944692
Training Loss (progress: 0.30): 0.20812577812974736
Training Loss (progress: 0.40): 0.16780400003095883
Training Loss (progress: 0.50): 0.1549850671286875
Training Loss (progress: 0.60): 0.14490984951956673
Training Loss (progress: 0.70): 0.1290137775062475
Training Loss (progress: 0.80): 0.12190957755192787
Training Loss (progress: 0.90): 0.10928327849233735
Evaluation on validation dataset:
Step 25, mean loss 0.11024868453464252
Step 50, mean loss 0.1675637697410678
Step 75, mean loss 0.13750846537137634
Step 100, mean loss 0.15590759833617035
Step 125, mean loss 0.16409873471521852
Step 150, mean loss 0.18619413736006868
Step 175, mean loss 0.2756840953810402
Step 200, mean loss 0.26966484855073075
Step 225, mean loss 0.32408590624225053
Unrolled forward losses 15.239285991461182
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10846343009061732
Step 50, mean loss 0.188611039133102
Step 75, mean loss 0.1625033845651797
Step 100, mean loss 0.18591934417112504
Step 125, mean loss 0.18625740365858084
Step 150, mean loss 0.19045511918813746
Step 175, mean loss 0.20051402070025431
Step 200, mean loss 0.2681744214055068
Step 225, mean loss 0.3913999455818987
Unrolled forward losses 15.092850293538259
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  1:16:04.431979 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.24000826825321914
Training Loss (progress: 0.10): 0.22054441315878862
Training Loss (progress: 0.20): 0.21101988577033895
Training Loss (progress: 0.30): 0.20447462953379428
Training Loss (progress: 0.40): 0.1950979097391097
Training Loss (progress: 0.50): 0.189276583619139
Training Loss (progress: 0.60): 0.17365752063772846
Training Loss (progress: 0.70): 0.18971380291545029
Training Loss (progress: 0.80): 0.16000074451840998
Training Loss (progress: 0.90): 0.1583513910989648
Evaluation on validation dataset:
Step 25, mean loss 0.1559850530269183
Step 50, mean loss 0.11208469438576127
Step 75, mean loss 0.14368509117068995
Step 100, mean loss 0.16818779409728496
Step 125, mean loss 0.1865048292739923
Step 150, mean loss 0.2048868584627087
Step 175, mean loss 0.23969413513088486
Step 200, mean loss 0.26581922515257866
Step 225, mean loss 0.34594731841332016
Unrolled forward losses 5.1087080070585245
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.15236648065215302
Step 50, mean loss 0.11591571636208883
Step 75, mean loss 0.1659989250409625
Step 100, mean loss 0.18901148397217027
Step 125, mean loss 0.20815701991425328
Step 150, mean loss 0.20819181666631847
Step 175, mean loss 0.21540282765296226
Step 200, mean loss 0.26778432443441086
Step 225, mean loss 0.3333766021364694
Unrolled forward losses 5.738422710424215
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  2:36:55.347087 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.26912254047804085
Training Loss (progress: 0.10): 0.22494200473566872
Training Loss (progress: 0.20): 0.20689582442800317
Training Loss (progress: 0.30): 0.217343061974403
Training Loss (progress: 0.40): 0.21060068299339071
Training Loss (progress: 0.50): 0.20438369217725044
Training Loss (progress: 0.60): 0.20322664524092668
Training Loss (progress: 0.70): 0.19001309103993116
Training Loss (progress: 0.80): 0.2151625116844313
Training Loss (progress: 0.90): 0.18994732495922312
Evaluation on validation dataset:
Step 25, mean loss 0.09375533632306982
Step 50, mean loss 0.06538817382523623
Step 75, mean loss 0.06345611416439827
Step 100, mean loss 0.07938387538376848
Step 125, mean loss 0.07353487046777468
Step 150, mean loss 0.09656080458047903
Step 175, mean loss 0.11202493915270924
Step 200, mean loss 0.14895809864509651
Step 225, mean loss 0.18410439553567864
Unrolled forward losses 3.253776170893126
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10540317962133046
Step 50, mean loss 0.06868334365881124
Step 75, mean loss 0.08583181443756427
Step 100, mean loss 0.08844742317782932
Step 125, mean loss 0.09170721367755719
Step 150, mean loss 0.0955438244966866
Step 175, mean loss 0.10160330567293199
Step 200, mean loss 0.14184584827959307
Step 225, mean loss 0.21397261892715264
Unrolled forward losses 4.029268488278701
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  4:02:52.158408 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.1927665962921618
Training Loss (progress: 0.10): 0.19060843679851575
Training Loss (progress: 0.20): 0.17609736497273218
Training Loss (progress: 0.30): 0.19308555620759843
Training Loss (progress: 0.40): 0.18478007159126417
Training Loss (progress: 0.50): 0.17682270064752706
Training Loss (progress: 0.60): 0.17871650374846623
Training Loss (progress: 0.70): 0.18314460381116293
Training Loss (progress: 0.80): 0.20201204015062632
Training Loss (progress: 0.90): 0.16494148682735868
Evaluation on validation dataset:
Step 25, mean loss 0.07923550764122
Step 50, mean loss 0.053629492138171926
Step 75, mean loss 0.05667191506912028
Step 100, mean loss 0.066343852008579
Step 125, mean loss 0.06782817758354315
Step 150, mean loss 0.09202914542806709
Step 175, mean loss 0.10688397822028803
Step 200, mean loss 0.13898958862860156
Step 225, mean loss 0.16082331360277077
Unrolled forward losses 2.2451568344746144
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08826278753570511
Step 50, mean loss 0.05857907098976456
Step 75, mean loss 0.06407769118559417
Step 100, mean loss 0.07777240782890997
Step 125, mean loss 0.08687284419065494
Step 150, mean loss 0.08278699144561874
Step 175, mean loss 0.08672537518861728
Step 200, mean loss 0.12876382972938746
Step 225, mean loss 0.19037140951172266
Unrolled forward losses 2.894063114808614
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  5:29:41.752302 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.16067570284466
Training Loss (progress: 0.10): 0.17551698403875743
Training Loss (progress: 0.20): 0.17191155708869407
Training Loss (progress: 0.30): 0.17317781812927568
Training Loss (progress: 0.40): 0.17403844239404578
Training Loss (progress: 0.50): 0.16409793775123338
Training Loss (progress: 0.60): 0.17710533535463133
Training Loss (progress: 0.70): 0.17032263784131157
Training Loss (progress: 0.80): 0.1468427681257241
Training Loss (progress: 0.90): 0.15758001451772707
Evaluation on validation dataset:
Step 25, mean loss 0.08389184989174742
Step 50, mean loss 0.062493528540489354
Step 75, mean loss 0.045004615916150556
Step 100, mean loss 0.056901519362023464
Step 125, mean loss 0.05577636527076699
Step 150, mean loss 0.07418623564877033
Step 175, mean loss 0.08999003324361382
Step 200, mean loss 0.11410572392542587
Step 225, mean loss 0.13938451734721286
Unrolled forward losses 1.881842185157364
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08594194115635953
Step 50, mean loss 0.05850031659442025
Step 75, mean loss 0.06053272861806677
Step 100, mean loss 0.07082689193449493
Step 125, mean loss 0.0723727946044947
Step 150, mean loss 0.07458891426898136
Step 175, mean loss 0.0804535565204913
Step 200, mean loss 0.11000247163438943
Step 225, mean loss 0.17870983945802876
Unrolled forward losses 2.6360746841606923
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  6:56:53.303509 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.15143496409815288
Training Loss (progress: 0.10): 0.14010421783162805
Training Loss (progress: 0.20): 0.15050839004402747
Training Loss (progress: 0.30): 0.13174754045658482
Training Loss (progress: 0.40): 0.14154484065035564
Training Loss (progress: 0.50): 0.13771140910918406
Training Loss (progress: 0.60): 0.1393092189054721
Training Loss (progress: 0.70): 0.13161325132916932
Training Loss (progress: 0.80): 0.12776410859873938
Training Loss (progress: 0.90): 0.14110983337228006
Evaluation on validation dataset:
Step 25, mean loss 0.06461139786738943
Step 50, mean loss 0.04385850689941967
Step 75, mean loss 0.04770874542985086
Step 100, mean loss 0.05358037763148159
Step 125, mean loss 0.05076415492948169
Step 150, mean loss 0.07348535079448479
Step 175, mean loss 0.08467599450897828
Step 200, mean loss 0.10724854615761567
Step 225, mean loss 0.13144314719565137
Unrolled forward losses 1.9591827055401092
Unrolled forward base losses 2.927822615141285
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.13444324728352838
Training Loss (progress: 0.10): 0.12953382371621303
Training Loss (progress: 0.20): 0.14238271212627399
Training Loss (progress: 0.30): 0.1443929694706943
Training Loss (progress: 0.40): 0.13250670390144698
Training Loss (progress: 0.50): 0.15281831100704682
Training Loss (progress: 0.60): 0.14322174076895328
Training Loss (progress: 0.70): 0.12251794966542508
Training Loss (progress: 0.80): 0.137532885622928
Training Loss (progress: 0.90): 0.13501121128879562
Evaluation on validation dataset:
Step 25, mean loss 0.0580672632720558
Step 50, mean loss 0.041486736715152836
Step 75, mean loss 0.03868809883606074
Step 100, mean loss 0.04733207240041627
Step 125, mean loss 0.045885130054547946
Step 150, mean loss 0.06642541120552678
Step 175, mean loss 0.0767538573180237
Step 200, mean loss 0.1017041991557895
Step 225, mean loss 0.12180466129478557
Unrolled forward losses 1.6106816325742717
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06652053785980765
Step 50, mean loss 0.04154465742557157
Step 75, mean loss 0.044756006340928675
Step 100, mean loss 0.05807297670290874
Step 125, mean loss 0.06287859213651936
Step 150, mean loss 0.06157969140405238
Step 175, mean loss 0.06847809580497982
Step 200, mean loss 0.09234204205160851
Step 225, mean loss 0.14170144497860715
Unrolled forward losses 2.0872945714955704
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  9:52:24.678401 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.13101274839763205
Training Loss (progress: 0.10): 0.13534387256868638
Training Loss (progress: 0.20): 0.11883800917286193
Training Loss (progress: 0.30): 0.14587393794687561
Training Loss (progress: 0.40): 0.13179242161514726
Training Loss (progress: 0.50): 0.12024798369417379
Training Loss (progress: 0.60): 0.11111698905797861
Training Loss (progress: 0.70): 0.13776015939699326
Training Loss (progress: 0.80): 0.1282800490886364
Training Loss (progress: 0.90): 0.12751178373572694
Evaluation on validation dataset:
Step 25, mean loss 0.05372205806165123
Step 50, mean loss 0.040738828117564914
Step 75, mean loss 0.04002988688744122
Step 100, mean loss 0.05384567907446794
Step 125, mean loss 0.04449845226254936
Step 150, mean loss 0.0630438080949273
Step 175, mean loss 0.07635336274730406
Step 200, mean loss 0.09630654554190432
Step 225, mean loss 0.12163513339653795
Unrolled forward losses 1.6953985458960115
Unrolled forward base losses 2.927822615141285
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.13614925307382642
Training Loss (progress: 0.10): 0.12947837478100563
Training Loss (progress: 0.20): 0.1388234287908881
Training Loss (progress: 0.30): 0.12580489776860435
Training Loss (progress: 0.40): 0.13408521768909917
Training Loss (progress: 0.50): 0.12593999112733223
Training Loss (progress: 0.60): 0.12608155921411068
Training Loss (progress: 0.70): 0.12555480548744186
Training Loss (progress: 0.80): 0.12842933785421934
Training Loss (progress: 0.90): 0.11657915774928373
Evaluation on validation dataset:
Step 25, mean loss 0.051185004230907535
Step 50, mean loss 0.037092259241093814
Step 75, mean loss 0.034341077429948366
Step 100, mean loss 0.044238783949663886
Step 125, mean loss 0.04162717627957118
Step 150, mean loss 0.061795200514798
Step 175, mean loss 0.07819747098522918
Step 200, mean loss 0.09644712236889351
Step 225, mean loss 0.11494484116319903
Unrolled forward losses 1.4950693576031935
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05871172369979011
Step 50, mean loss 0.03685847106654069
Step 75, mean loss 0.04309858927550507
Step 100, mean loss 0.053437898026094964
Step 125, mean loss 0.06040160309127006
Step 150, mean loss 0.06115028052737406
Step 175, mean loss 0.06496617735695517
Step 200, mean loss 0.0870394886994718
Step 225, mean loss 0.13916257243206365
Unrolled forward losses 2.0506327841736915
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  12:49:34.361361 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.12761776765899366
Training Loss (progress: 0.10): 0.1227311613887837
Training Loss (progress: 0.20): 0.12098907257355163
Training Loss (progress: 0.30): 0.1299511355967047
Training Loss (progress: 0.40): 0.11197802467357172
Training Loss (progress: 0.50): 0.11941505505738466
Training Loss (progress: 0.60): 0.12007075340824482
Training Loss (progress: 0.70): 0.12843747985137086
Training Loss (progress: 0.80): 0.12195237457794394
Training Loss (progress: 0.90): 0.11901207580821124
Evaluation on validation dataset:
Step 25, mean loss 0.04831075086870812
Step 50, mean loss 0.03777930567287971
Step 75, mean loss 0.033987211355363756
Step 100, mean loss 0.04322246687461481
Step 125, mean loss 0.042179347527437114
Step 150, mean loss 0.0590854799780127
Step 175, mean loss 0.07379380098632576
Step 200, mean loss 0.08648561967275425
Step 225, mean loss 0.11231972277475208
Unrolled forward losses 1.4892456244063743
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.053011136672491514
Step 50, mean loss 0.03753766674887361
Step 75, mean loss 0.040542295351416756
Step 100, mean loss 0.056903775039750894
Step 125, mean loss 0.0625171868279979
Step 150, mean loss 0.06054928893119198
Step 175, mean loss 0.06542437439745223
Step 200, mean loss 0.08336076946991386
Step 225, mean loss 0.14063575119689242
Unrolled forward losses 1.9016041546098341
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  14:18:15.047772 

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.11981834521830312
Training Loss (progress: 0.10): 0.11726583302436837
Training Loss (progress: 0.20): 0.11398211933909114
Training Loss (progress: 0.30): 0.119631674392941
Training Loss (progress: 0.40): 0.10943297023500936
Training Loss (progress: 0.50): 0.1172266508756815
Training Loss (progress: 0.60): 0.11126565820406921
Training Loss (progress: 0.70): 0.10544293310505069
Training Loss (progress: 0.80): 0.10173092813358856
Training Loss (progress: 0.90): 0.11287111616178608
Evaluation on validation dataset:
Step 25, mean loss 0.048251896193764625
Step 50, mean loss 0.03796756497371075
Step 75, mean loss 0.03160982743731161
Step 100, mean loss 0.04086889807971453
Step 125, mean loss 0.038820473768831965
Step 150, mean loss 0.05880677416754596
Step 175, mean loss 0.06603760353812548
Step 200, mean loss 0.08464420368138231
Step 225, mean loss 0.10837586024445528
Unrolled forward losses 1.427319986649377
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.052592264001062095
Step 50, mean loss 0.03682776392288405
Step 75, mean loss 0.0402276799265541
Step 100, mean loss 0.05017981502328267
Step 125, mean loss 0.05658914072923033
Step 150, mean loss 0.05404068466393208
Step 175, mean loss 0.06069398419476673
Step 200, mean loss 0.07719259978757158
Step 225, mean loss 0.13152193791743494
Unrolled forward losses 1.844000298885656
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  15:47:09.114358 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.10433840738129944
Training Loss (progress: 0.10): 0.11346949020477351
Training Loss (progress: 0.20): 0.10463710696252174
Training Loss (progress: 0.30): 0.11549568037389359
Training Loss (progress: 0.40): 0.1179126605297372
Training Loss (progress: 0.50): 0.1102590372029588
Training Loss (progress: 0.60): 0.10244434863312567
Training Loss (progress: 0.70): 0.10916197863363601
Training Loss (progress: 0.80): 0.1041137540528604
Training Loss (progress: 0.90): 0.10134711522894779
Evaluation on validation dataset:
Step 25, mean loss 0.04499584391213795
Step 50, mean loss 0.037872069480837586
Step 75, mean loss 0.03124411984735031
Step 100, mean loss 0.04015023673539206
Step 125, mean loss 0.03759944282975374
Step 150, mean loss 0.05521977557095646
Step 175, mean loss 0.06437269844086761
Step 200, mean loss 0.08295393890817811
Step 225, mean loss 0.10426403291970843
Unrolled forward losses 1.4542003649679955
Unrolled forward base losses 2.927822615141285
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.09953187551732298
Training Loss (progress: 0.10): 0.10976525788175559
Training Loss (progress: 0.20): 0.10719172287143545
Training Loss (progress: 0.30): 0.12270744778422997
Training Loss (progress: 0.40): 0.10184073468112174
Training Loss (progress: 0.50): 0.1141832381004223
Training Loss (progress: 0.60): 0.11259281116832931
Training Loss (progress: 0.70): 0.11235533975476153
Training Loss (progress: 0.80): 0.10602861689369693
Training Loss (progress: 0.90): 0.10646343859332474
Evaluation on validation dataset:
Step 25, mean loss 0.045039334941173605
Step 50, mean loss 0.03778289903789377
Step 75, mean loss 0.029531310176668865
Step 100, mean loss 0.03925236716341884
Step 125, mean loss 0.03719851780587709
Step 150, mean loss 0.058567378533632974
Step 175, mean loss 0.06629623272337082
Step 200, mean loss 0.08424959746681807
Step 225, mean loss 0.10249286236655997
Unrolled forward losses 1.4218067993343957
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04944359181360179
Step 50, mean loss 0.035125343948784
Step 75, mean loss 0.03771167100349497
Step 100, mean loss 0.04983436245672773
Step 125, mean loss 0.055312093355555994
Step 150, mean loss 0.0536068498511148
Step 175, mean loss 0.05809019015271631
Step 200, mean loss 0.07538939072211762
Step 225, mean loss 0.12656764129009668
Unrolled forward losses 1.9163965856215595
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  18:45:30.874721 

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.10921790960957138
Training Loss (progress: 0.10): 0.10938660395116846
Training Loss (progress: 0.20): 0.10770479583005921
Training Loss (progress: 0.30): 0.09620440962162519
Training Loss (progress: 0.40): 0.1016025773718147
Training Loss (progress: 0.50): 0.1107177639706543
Training Loss (progress: 0.60): 0.10302563478371213
Training Loss (progress: 0.70): 0.10770273088868702
Training Loss (progress: 0.80): 0.10802737635877056
Training Loss (progress: 0.90): 0.10568827798397908
Evaluation on validation dataset:
Step 25, mean loss 0.04218641190457212
Step 50, mean loss 0.03516514678449643
Step 75, mean loss 0.030703821716141853
Step 100, mean loss 0.040349763257263166
Step 125, mean loss 0.03743844443488467
Step 150, mean loss 0.05683280465286154
Step 175, mean loss 0.06354415275405519
Step 200, mean loss 0.08157808372165712
Step 225, mean loss 0.10089619925022342
Unrolled forward losses 1.4894215601772745
Unrolled forward base losses 2.927822615141285
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.11174126556164797
Training Loss (progress: 0.10): 0.10806190852129334
Training Loss (progress: 0.20): 0.10447592836012216
Training Loss (progress: 0.30): 0.10783139955542723
Training Loss (progress: 0.40): 0.1075024268451485
Training Loss (progress: 0.50): 0.10030564597141386
Training Loss (progress: 0.60): 0.10289571478779264
Training Loss (progress: 0.70): 0.10490435417125381
Training Loss (progress: 0.80): 0.1089554898679038
Training Loss (progress: 0.90): 0.1016865948834801
Evaluation on validation dataset:
Step 25, mean loss 0.04243490187739671
Step 50, mean loss 0.03457359236494993
Step 75, mean loss 0.028667027313332122
Step 100, mean loss 0.03784820276738334
Step 125, mean loss 0.036084533916562474
Step 150, mean loss 0.052896207200132175
Step 175, mean loss 0.06404807315309982
Step 200, mean loss 0.07959674210733805
Step 225, mean loss 0.100768489011165
Unrolled forward losses 1.362180029257933
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04795002050032744
Step 50, mean loss 0.033221215686140504
Step 75, mean loss 0.03494244680769137
Step 100, mean loss 0.047893011516895165
Step 125, mean loss 0.054786244178887056
Step 150, mean loss 0.05318381349356513
Step 175, mean loss 0.05724265231283595
Step 200, mean loss 0.07420018014180996
Step 225, mean loss 0.12451710987436776
Unrolled forward losses 1.8334669237427632
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  21:44:33.134884 

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.10450482760192986
Training Loss (progress: 0.10): 0.10240903500757471
Training Loss (progress: 0.20): 0.10840812644972798
Training Loss (progress: 0.30): 0.1050166305338716
Training Loss (progress: 0.40): 0.09843410091991132
Training Loss (progress: 0.50): 0.10216535053738929
Training Loss (progress: 0.60): 0.10741874812694925
Training Loss (progress: 0.70): 0.09727706472607253
Training Loss (progress: 0.80): 0.0958062794987909
Training Loss (progress: 0.90): 0.09879930404856684
Evaluation on validation dataset:
Step 25, mean loss 0.043405285265466054
Step 50, mean loss 0.03438261409750897
Step 75, mean loss 0.028928000743904884
Step 100, mean loss 0.03840534603433369
Step 125, mean loss 0.03579687333312082
Step 150, mean loss 0.05339398035181209
Step 175, mean loss 0.06202468561982169
Step 200, mean loss 0.07886430008432008
Step 225, mean loss 0.09782889018990444
Unrolled forward losses 1.4079038183631458
Unrolled forward base losses 2.927822615141285
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.10503613531055074
Training Loss (progress: 0.10): 0.11019465806704773
Training Loss (progress: 0.20): 0.10660121820091288
Training Loss (progress: 0.30): 0.09816968515300463
Training Loss (progress: 0.40): 0.10128352232249452
Training Loss (progress: 0.50): 0.09579294640105321
Training Loss (progress: 0.60): 0.09836898686244996
Training Loss (progress: 0.70): 0.09992244841773457
Training Loss (progress: 0.80): 0.10049498298876396
Training Loss (progress: 0.90): 0.10656930340233751
Evaluation on validation dataset:
Step 25, mean loss 0.042015080917441563
Step 50, mean loss 0.032979231281576614
Step 75, mean loss 0.029360786786665406
Step 100, mean loss 0.038250737296067185
Step 125, mean loss 0.035790002591259557
Step 150, mean loss 0.05376528452691101
Step 175, mean loss 0.062242909092027725
Step 200, mean loss 0.07892344223602481
Step 225, mean loss 0.09765023561878701
Unrolled forward losses 1.3751878432603366
Unrolled forward base losses 2.927822615141285
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.09468653534292694
Training Loss (progress: 0.10): 0.1012448350781628
Training Loss (progress: 0.20): 0.10927039268130358
Training Loss (progress: 0.30): 0.09382105733813143
Training Loss (progress: 0.40): 0.1135518588874947
Training Loss (progress: 0.50): 0.09793550284019412
Training Loss (progress: 0.60): 0.10264795259758625
Training Loss (progress: 0.70): 0.09536910753726685
Training Loss (progress: 0.80): 0.10793879837219258
Training Loss (progress: 0.90): 0.09954103096151527
Evaluation on validation dataset:
Step 25, mean loss 0.041250038755458435
Step 50, mean loss 0.033228461892233066
Step 75, mean loss 0.029719229569006106
Step 100, mean loss 0.038466700298153904
Step 125, mean loss 0.03520341387264552
Step 150, mean loss 0.05365505886266332
Step 175, mean loss 0.06117393290796026
Step 200, mean loss 0.07801902903991764
Step 225, mean loss 0.09905556270588353
Unrolled forward losses 1.338908772396778
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.045545790243029946
Step 50, mean loss 0.03359416510469558
Step 75, mean loss 0.03526739699660017
Step 100, mean loss 0.04657615525750917
Step 125, mean loss 0.05321699157403258
Step 150, mean loss 0.05097978849619402
Step 175, mean loss 0.056485192714625584
Step 200, mean loss 0.07130631519883739
Step 225, mean loss 0.11879755970534012
Unrolled forward losses 1.8163721615569917
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  1 day, 2:14:35.044463 

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.09971713300962778
Training Loss (progress: 0.10): 0.09774648508726493
Training Loss (progress: 0.20): 0.10500181064573544
Training Loss (progress: 0.30): 0.09301267644672212
Training Loss (progress: 0.40): 0.10361593382808318
Training Loss (progress: 0.50): 0.09977880696370912
Training Loss (progress: 0.60): 0.10315848238953883
Training Loss (progress: 0.70): 0.09762690077873745
Training Loss (progress: 0.80): 0.1019289054996805
Training Loss (progress: 0.90): 0.10550522163268003
Evaluation on validation dataset:
Step 25, mean loss 0.04133528584363657
Step 50, mean loss 0.03326270913335598
Step 75, mean loss 0.02932328036943165
Step 100, mean loss 0.03771365206364255
Step 125, mean loss 0.0350963273808128
Step 150, mean loss 0.05277564237794795
Step 175, mean loss 0.062163484614301434
Step 200, mean loss 0.07772980933374134
Step 225, mean loss 0.09802418645819093
Unrolled forward losses 1.346798583492005
Unrolled forward base losses 2.927822615141285
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.09660220764630016
Training Loss (progress: 0.10): 0.09942347071506147
Training Loss (progress: 0.20): 0.09867168924395239
Training Loss (progress: 0.30): 0.09828985312824315
Training Loss (progress: 0.40): 0.0897253026663283
Training Loss (progress: 0.50): 0.10335977465620012
Training Loss (progress: 0.60): 0.10503092021745963
Training Loss (progress: 0.70): 0.09488362797128758
Training Loss (progress: 0.80): 0.09761289674054405
Training Loss (progress: 0.90): 0.1023008515276478
Evaluation on validation dataset:
Step 25, mean loss 0.04073971630204256
Step 50, mean loss 0.03463048410335198
Step 75, mean loss 0.029195330978958524
Step 100, mean loss 0.03779990605747817
Step 125, mean loss 0.035291596999502836
Step 150, mean loss 0.05284581883581599
Step 175, mean loss 0.060964999925195884
Step 200, mean loss 0.0779285686798398
Step 225, mean loss 0.09690487678419377
Unrolled forward losses 1.3612622152960592
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.10187470497032428
Training Loss (progress: 0.10): 0.09164788307887704
Training Loss (progress: 0.20): 0.09629687309321339
Training Loss (progress: 0.30): 0.10178248971037064
Training Loss (progress: 0.40): 0.10042289916680312
Training Loss (progress: 0.50): 0.10071695243001494
Training Loss (progress: 0.60): 0.10022799254537339
Training Loss (progress: 0.70): 0.09533279655103775
Training Loss (progress: 0.80): 0.09336649980468906
Training Loss (progress: 0.90): 0.09923932678608165
Evaluation on validation dataset:
Step 25, mean loss 0.040228819646238645
Step 50, mean loss 0.03292631187109744
Step 75, mean loss 0.029516194073209316
Step 100, mean loss 0.037650496042126946
Step 125, mean loss 0.03490783749059265
Step 150, mean loss 0.05260535123775422
Step 175, mean loss 0.059970129112898105
Step 200, mean loss 0.07706360204415902
Step 225, mean loss 0.09677140496351748
Unrolled forward losses 1.360033066105613
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.09621683431413794
Training Loss (progress: 0.10): 0.10237537820963326
Training Loss (progress: 0.20): 0.10733353312070554
Training Loss (progress: 0.30): 0.10159735337447019
Training Loss (progress: 0.40): 0.10183810698434065
Training Loss (progress: 0.50): 0.09982488239719033
Training Loss (progress: 0.60): 0.10293077663368976
Training Loss (progress: 0.70): 0.09926002268203941
Training Loss (progress: 0.80): 0.10234462552290671
Training Loss (progress: 0.90): 0.09044929969179133
Evaluation on validation dataset:
Step 25, mean loss 0.03991365704662258
Step 50, mean loss 0.03411800423753466
Step 75, mean loss 0.02814412205787341
Step 100, mean loss 0.037413008171365045
Step 125, mean loss 0.034800496257935784
Step 150, mean loss 0.052226854455216215
Step 175, mean loss 0.061183998724404255
Step 200, mean loss 0.07521202574895378
Step 225, mean loss 0.09431331517547525
Unrolled forward losses 1.3527179623034162
Unrolled forward base losses 2.927822615141285
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.0994981193249669
Training Loss (progress: 0.10): 0.09872970524395178
Training Loss (progress: 0.20): 0.10279650953370012
Training Loss (progress: 0.30): 0.10300394639959158
Training Loss (progress: 0.40): 0.10273019127345712
Training Loss (progress: 0.50): 0.09793931979404573
Training Loss (progress: 0.60): 0.09872996027443537
Training Loss (progress: 0.70): 0.09430157158465383
Training Loss (progress: 0.80): 0.10448488878556814
Training Loss (progress: 0.90): 0.1056901605059239
Evaluation on validation dataset:
Step 25, mean loss 0.0391903848647199
Step 50, mean loss 0.03222005025619362
Step 75, mean loss 0.02954549318891598
Step 100, mean loss 0.037782523940485736
Step 125, mean loss 0.03487540755172322
Step 150, mean loss 0.05212509611815664
Step 175, mean loss 0.06060071872929843
Step 200, mean loss 0.07575221820276787
Step 225, mean loss 0.09701734436173136
Unrolled forward losses 1.3619157735299434
Unrolled forward base losses 2.927822615141285
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.10181920859658765
Training Loss (progress: 0.10): 0.09706125912367272
Training Loss (progress: 0.20): 0.09786968070582219
Training Loss (progress: 0.30): 0.10404535475172137
Training Loss (progress: 0.40): 0.10000862332016124
Training Loss (progress: 0.50): 0.10275805488381226
Training Loss (progress: 0.60): 0.09193969931798404
Training Loss (progress: 0.70): 0.09775091483209175
Training Loss (progress: 0.80): 0.10466232259017338
Training Loss (progress: 0.90): 0.09422563436997533
Evaluation on validation dataset:
Step 25, mean loss 0.04001111559355966
Step 50, mean loss 0.0331547753796156
Step 75, mean loss 0.027150524685677822
Step 100, mean loss 0.03669578376323436
Step 125, mean loss 0.03458426547540275
Step 150, mean loss 0.05187652230494655
Step 175, mean loss 0.06119035538285387
Step 200, mean loss 0.0760355434942635
Step 225, mean loss 0.09474308423998641
Unrolled forward losses 1.3319927976999861
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04286985579818493
Step 50, mean loss 0.03223075590014515
Step 75, mean loss 0.03378149193519295
Step 100, mean loss 0.044552652174358914
Step 125, mean loss 0.05260945385803774
Step 150, mean loss 0.05104704313096815
Step 175, mean loss 0.054786527856208446
Step 200, mean loss 0.06899001035138086
Step 225, mean loss 0.11771204293834032
Unrolled forward losses 1.7553606328464124
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11121942.pt
Training time:  1 day, 12:58:31.483145 

Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.10499048445009371
Training Loss (progress: 0.10): 0.10658494634589413
Training Loss (progress: 0.20): 0.0975422064699208
Training Loss (progress: 0.30): 0.09944937086134657
Training Loss (progress: 0.40): 0.10064195392422838
Training Loss (progress: 0.50): 0.10131341186553011
Training Loss (progress: 0.60): 0.10276013491451993
Training Loss (progress: 0.70): 0.0967944704591057
Training Loss (progress: 0.80): 0.10040932965114222
Training Loss (progress: 0.90): 0.09866595970385762
Evaluation on validation dataset:
Step 25, mean loss 0.03917298275006428
Step 50, mean loss 0.033965534943414276
Step 75, mean loss 0.028484102097649268
Step 100, mean loss 0.036717765637101246
Step 125, mean loss 0.0343301720437168
Step 150, mean loss 0.052050604014242205
Step 175, mean loss 0.06096710271867983
Step 200, mean loss 0.07439723868311635
Step 225, mean loss 0.09395942005588213
Unrolled forward losses 1.3510575696566223
Unrolled forward base losses 2.927822615141285
Test loss: 1.7553606328464124
Training time (until epoch 23):  {datetime.timedelta(days=1, seconds=46711, microseconds=483145)}
