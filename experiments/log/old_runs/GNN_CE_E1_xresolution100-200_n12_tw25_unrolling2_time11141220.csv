Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Number of parameters: 1031645
Training started at: 2024-11-14 12:20:44
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.4078223908759664
Training Loss (progress: 0.10): 0.3431852682768671
Training Loss (progress: 0.20): 0.2534205658616996
Training Loss (progress: 0.30): 0.2128498208188524
Training Loss (progress: 0.40): 0.17760324161773658
Training Loss (progress: 0.50): 0.16301770601157922
Training Loss (progress: 0.60): 0.14809215216186902
Training Loss (progress: 0.70): 0.13560178428211314
Training Loss (progress: 0.80): 0.11809357420295362
Training Loss (progress: 0.90): 0.11057879291458472
Evaluation on validation dataset:
Step 25, mean loss 0.09904361440525264
Step 50, mean loss 0.1662870471944592
Step 75, mean loss 0.1265054924025928
Step 100, mean loss 0.1586278663549116
Step 125, mean loss 0.16456993036700224
Step 150, mean loss 0.18816730012877292
Step 175, mean loss 0.26553363570967425
Step 200, mean loss 0.3217742906201533
Step 225, mean loss 0.4109208379977291
Unrolled forward losses 13.978213894410489
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.11161973715818134
Step 50, mean loss 0.14831268679928816
Step 75, mean loss 0.1557913095157919
Step 100, mean loss 0.17329726308558918
Step 125, mean loss 0.18392047143112125
Step 150, mean loss 0.19043306931124793
Step 175, mean loss 0.2097512929388138
Step 200, mean loss 0.2894123388142098
Step 225, mean loss 0.36138735153212176
Unrolled forward losses 15.676888239692506
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  1:25:45.881489 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.2500906477733653
Training Loss (progress: 0.10): 0.23354399961943614
Training Loss (progress: 0.20): 0.2115173569829028
Training Loss (progress: 0.30): 0.21431866875497127
Training Loss (progress: 0.40): 0.20176746876877658
Training Loss (progress: 0.50): 0.16350976619936217
Training Loss (progress: 0.60): 0.18128083797658276
Training Loss (progress: 0.70): 0.18861820707923954
Training Loss (progress: 0.80): 0.17033578432584487
Training Loss (progress: 0.90): 0.16813145017574754
Evaluation on validation dataset:
Step 25, mean loss 0.11557605839609279
Step 50, mean loss 0.12204530200358164
Step 75, mean loss 0.1036138292585789
Step 100, mean loss 0.11021063309525397
Step 125, mean loss 0.12680011274947794
Step 150, mean loss 0.1368692521169177
Step 175, mean loss 0.18191853123701912
Step 200, mean loss 0.2523044909631048
Step 225, mean loss 0.310414600543753
Unrolled forward losses 3.7359702353323456
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.12192727577969184
Step 50, mean loss 0.08933781172828259
Step 75, mean loss 0.10748287100123143
Step 100, mean loss 0.11578190664009384
Step 125, mean loss 0.13569256852557138
Step 150, mean loss 0.13351630165834666
Step 175, mean loss 0.14940409116723363
Step 200, mean loss 0.18595795903591128
Step 225, mean loss 0.26912898621828685
Unrolled forward losses 4.424868896122884
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  2:59:00.136108 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.2281079453117595
Training Loss (progress: 0.10): 0.23864687633982487
Training Loss (progress: 0.20): 0.21680631395197245
Training Loss (progress: 0.30): 0.2044177626256877
Training Loss (progress: 0.40): 0.20770837683844737
Training Loss (progress: 0.50): 0.20812206346620615
Training Loss (progress: 0.60): 0.2088693952612388
Training Loss (progress: 0.70): 0.20973009010090465
Training Loss (progress: 0.80): 0.20268733327371763
Training Loss (progress: 0.90): 0.19975425477610556
Evaluation on validation dataset:
Step 25, mean loss 0.09981489643633701
Step 50, mean loss 0.08249529611042747
Step 75, mean loss 0.07485876964639372
Step 100, mean loss 0.07634452417999049
Step 125, mean loss 0.07375312854324093
Step 150, mean loss 0.1019974337673861
Step 175, mean loss 0.12426029095768405
Step 200, mean loss 0.17371668286048642
Step 225, mean loss 0.25289562845724445
Unrolled forward losses 2.615262589517819
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09681123176639657
Step 50, mean loss 0.07649448532862468
Step 75, mean loss 0.0769677016646797
Step 100, mean loss 0.08834965005156495
Step 125, mean loss 0.0920987439737492
Step 150, mean loss 0.10171277201327697
Step 175, mean loss 0.11544413841603682
Step 200, mean loss 0.13199216793131582
Step 225, mean loss 0.19726848703766678
Unrolled forward losses 2.90512649469776
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  4:37:25.317581 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.19795480542370303
Training Loss (progress: 0.10): 0.1944780277531231
Training Loss (progress: 0.20): 0.18906529477004824
Training Loss (progress: 0.30): 0.19923580862133392
Training Loss (progress: 0.40): 0.18228612476783734
Training Loss (progress: 0.50): 0.17679932018139968
Training Loss (progress: 0.60): 0.19468788099130627
Training Loss (progress: 0.70): 0.1801042495893299
Training Loss (progress: 0.80): 0.19706731132005062
Training Loss (progress: 0.90): 0.20059642540535977
Evaluation on validation dataset:
Step 25, mean loss 0.08568623857824875
Step 50, mean loss 0.08875340282118295
Step 75, mean loss 0.061561637207304704
Step 100, mean loss 0.0730156729448909
Step 125, mean loss 0.07728703647484436
Step 150, mean loss 0.1002922173794842
Step 175, mean loss 0.10995397884631421
Step 200, mean loss 0.16033394658337313
Step 225, mean loss 0.23436549694142772
Unrolled forward losses 2.4191885557939434
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09033866020029577
Step 50, mean loss 0.073017080384914
Step 75, mean loss 0.07104014265817374
Step 100, mean loss 0.08192719424198955
Step 125, mean loss 0.08606237371065006
Step 150, mean loss 0.09413461977686634
Step 175, mean loss 0.111272792717799
Step 200, mean loss 0.13155383688253514
Step 225, mean loss 0.19121103413079793
Unrolled forward losses 2.751513726835804
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  6:16:49.363987 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.18052763592801768
Training Loss (progress: 0.10): 0.17527896881015748
Training Loss (progress: 0.20): 0.17909942463784473
Training Loss (progress: 0.30): 0.17717665740702307
Training Loss (progress: 0.40): 0.1719814427835971
Training Loss (progress: 0.50): 0.16859079955844367
Training Loss (progress: 0.60): 0.1734625305179523
Training Loss (progress: 0.70): 0.16131485968005385
Training Loss (progress: 0.80): 0.16729456968560039
Training Loss (progress: 0.90): 0.1723308589024711
Evaluation on validation dataset:
Step 25, mean loss 0.07319543465042788
Step 50, mean loss 0.08439666588488408
Step 75, mean loss 0.06411017935584339
Step 100, mean loss 0.0716005699087432
Step 125, mean loss 0.07769924423798363
Step 150, mean loss 0.09789501924304912
Step 175, mean loss 0.11625549525341344
Step 200, mean loss 0.15429956256174976
Step 225, mean loss 0.25665694354487534
Unrolled forward losses 2.4346428832472036
Unrolled forward base losses 2.927822615141285
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.1594149845614529
Training Loss (progress: 0.10): 0.1429304774674412
Training Loss (progress: 0.20): 0.14710796866624812
Training Loss (progress: 0.30): 0.1508349588158468
Training Loss (progress: 0.40): 0.14237873333843534
Training Loss (progress: 0.50): 0.13194040128058226
Training Loss (progress: 0.60): 0.14121211292810112
Training Loss (progress: 0.70): 0.1487180095089861
Training Loss (progress: 0.80): 0.1363122823377685
Training Loss (progress: 0.90): 0.15794547928742528
Evaluation on validation dataset:
Step 25, mean loss 0.05984574735599736
Step 50, mean loss 0.05934332165583971
Step 75, mean loss 0.05030891542266016
Step 100, mean loss 0.05316757894685441
Step 125, mean loss 0.05583252061351672
Step 150, mean loss 0.07454512218046136
Step 175, mean loss 0.09152359133729229
Step 200, mean loss 0.11676170567671407
Step 225, mean loss 0.2118201719182632
Unrolled forward losses 1.7590216925643265
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0667624919610336
Step 50, mean loss 0.050472161736189014
Step 75, mean loss 0.05436113768665028
Step 100, mean loss 0.06118004025658469
Step 125, mean loss 0.06227750780693614
Step 150, mean loss 0.065029054028361
Step 175, mean loss 0.08192634654666023
Step 200, mean loss 0.09883881444298517
Step 225, mean loss 0.15012732461497477
Unrolled forward losses 2.393371321761121
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  9:37:45.470226 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.14934228945098474
Training Loss (progress: 0.10): 0.14711876312511485
Training Loss (progress: 0.20): 0.1452644158929393
Training Loss (progress: 0.30): 0.13002550184525002
Training Loss (progress: 0.40): 0.13272388450527245
Training Loss (progress: 0.50): 0.13724804138041918
Training Loss (progress: 0.60): 0.1327580353267738
Training Loss (progress: 0.70): 0.13166225503217102
Training Loss (progress: 0.80): 0.13495647585946524
Training Loss (progress: 0.90): 0.14465341099454052
Evaluation on validation dataset:
Step 25, mean loss 0.05397226000633701
Step 50, mean loss 0.056214980053282106
Step 75, mean loss 0.041507175209752105
Step 100, mean loss 0.049105575048052505
Step 125, mean loss 0.05352997774367482
Step 150, mean loss 0.07300393622018855
Step 175, mean loss 0.08368580445538869
Step 200, mean loss 0.12226983598482699
Step 225, mean loss 0.20551943885482585
Unrolled forward losses 1.6226720792552443
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.057655340818155855
Step 50, mean loss 0.04769006065199372
Step 75, mean loss 0.047491847077627054
Step 100, mean loss 0.057928941245012584
Step 125, mean loss 0.057429045042169974
Step 150, mean loss 0.06374330809122489
Step 175, mean loss 0.08059167066079054
Step 200, mean loss 0.09812631080003409
Step 225, mean loss 0.15221185482614208
Unrolled forward losses 2.2450693569183433
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  11:20:02.811468 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.13412475002060972
Training Loss (progress: 0.10): 0.1430431875542151
Training Loss (progress: 0.20): 0.14023174903590457
Training Loss (progress: 0.30): 0.13457537489556998
Training Loss (progress: 0.40): 0.13860849135938072
Training Loss (progress: 0.50): 0.13161000729238856
Training Loss (progress: 0.60): 0.1345205680392957
Training Loss (progress: 0.70): 0.14880073063145152
Training Loss (progress: 0.80): 0.12611462796756404
Training Loss (progress: 0.90): 0.13525550190865446
Evaluation on validation dataset:
Step 25, mean loss 0.05284206240208902
Step 50, mean loss 0.055688832029339164
Step 75, mean loss 0.03944139056257223
Step 100, mean loss 0.047348610553256607
Step 125, mean loss 0.050579495473094455
Step 150, mean loss 0.06593137414037528
Step 175, mean loss 0.07930254614412333
Step 200, mean loss 0.1108803365419177
Step 225, mean loss 0.19996468445279364
Unrolled forward losses 1.56546260042243
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.059630215915311785
Step 50, mean loss 0.047338674810314854
Step 75, mean loss 0.04662488010112058
Step 100, mean loss 0.05392246152204799
Step 125, mean loss 0.055031721333847046
Step 150, mean loss 0.06616192145339939
Step 175, mean loss 0.08233274643310784
Step 200, mean loss 0.09643574772295924
Step 225, mean loss 0.1469076687057096
Unrolled forward losses 2.2432344888426825
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  13:02:20.248589 

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.12390467981268771
Training Loss (progress: 0.10): 0.13236075711732292
Training Loss (progress: 0.20): 0.12719393793492037
Training Loss (progress: 0.30): 0.13355390211748733
Training Loss (progress: 0.40): 0.11796833880522849
Training Loss (progress: 0.50): 0.1253877926485568
Training Loss (progress: 0.60): 0.1365184811478368
Training Loss (progress: 0.70): 0.12604138671512824
Training Loss (progress: 0.80): 0.11418304146810204
Training Loss (progress: 0.90): 0.129435403839883
Evaluation on validation dataset:
Step 25, mean loss 0.045364266693026935
Step 50, mean loss 0.052713531108912026
Step 75, mean loss 0.0385141069142382
Step 100, mean loss 0.04588132853209713
Step 125, mean loss 0.049787449514930804
Step 150, mean loss 0.06732647967102715
Step 175, mean loss 0.07726877367308478
Step 200, mean loss 0.10746328907991971
Step 225, mean loss 0.1940303157819476
Unrolled forward losses 1.5414556885347648
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.052065965021768315
Step 50, mean loss 0.04088068802143356
Step 75, mean loss 0.04761280920961487
Step 100, mean loss 0.05443157904778928
Step 125, mean loss 0.054784057042009365
Step 150, mean loss 0.06238748012008501
Step 175, mean loss 0.07555756559401808
Step 200, mean loss 0.09258827379986266
Step 225, mean loss 0.14393347867260559
Unrolled forward losses 2.034060046242807
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  14:44:49.832887 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.13465408556194064
Training Loss (progress: 0.10): 0.11787137400782854
Training Loss (progress: 0.20): 0.1354726149664036
Training Loss (progress: 0.30): 0.11809170204715046
Training Loss (progress: 0.40): 0.12244436956912018
Training Loss (progress: 0.50): 0.12215991141072982
Training Loss (progress: 0.60): 0.1284716488072375
Training Loss (progress: 0.70): 0.12406542093533936
Training Loss (progress: 0.80): 0.12516825085250702
Training Loss (progress: 0.90): 0.121055039781653
Evaluation on validation dataset:
Step 25, mean loss 0.044427109437022605
Step 50, mean loss 0.05749463945293211
Step 75, mean loss 0.03963306590622236
Step 100, mean loss 0.04691343218747439
Step 125, mean loss 0.05023569563261018
Step 150, mean loss 0.06477303497376669
Step 175, mean loss 0.07399478264494191
Step 200, mean loss 0.10845586149443585
Step 225, mean loss 0.18577304854642473
Unrolled forward losses 1.5480703526921296
Unrolled forward base losses 2.927822615141285
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.12383435434476656
Training Loss (progress: 0.10): 0.11691765635637515
Training Loss (progress: 0.20): 0.10994199109429002
Training Loss (progress: 0.30): 0.11224597417286523
Training Loss (progress: 0.40): 0.10437143469063333
Training Loss (progress: 0.50): 0.1052412285907072
Training Loss (progress: 0.60): 0.11929204023746591
Training Loss (progress: 0.70): 0.11194041354006469
Training Loss (progress: 0.80): 0.10754255079762795
Training Loss (progress: 0.90): 0.1230025642006541
Evaluation on validation dataset:
Step 25, mean loss 0.03993363264735564
Step 50, mean loss 0.046098058639087953
Step 75, mean loss 0.03586454628504742
Step 100, mean loss 0.042929517820158455
Step 125, mean loss 0.0465018447102684
Step 150, mean loss 0.06235229479458741
Step 175, mean loss 0.07087697838547094
Step 200, mean loss 0.10302711659405758
Step 225, mean loss 0.17615617240075462
Unrolled forward losses 1.3904945547746919
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.046026851134239585
Step 50, mean loss 0.036808824570553254
Step 75, mean loss 0.04137843103386865
Step 100, mean loss 0.04929617243569469
Step 125, mean loss 0.049369260353493157
Step 150, mean loss 0.057272335626634426
Step 175, mean loss 0.07007998277635649
Step 200, mean loss 0.09016992797305079
Step 225, mean loss 0.13428242065442741
Unrolled forward losses 2.011332529352435
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  18:10:41.502287 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.12017915713075872
Training Loss (progress: 0.10): 0.1193418394403141
Training Loss (progress: 0.20): 0.11153351897638827
Training Loss (progress: 0.30): 0.1077279988722901
Training Loss (progress: 0.40): 0.10865317847632958
Training Loss (progress: 0.50): 0.10170719255051364
Training Loss (progress: 0.60): 0.11527220201007078
Training Loss (progress: 0.70): 0.11168694928879921
Training Loss (progress: 0.80): 0.11202181989556798
Training Loss (progress: 0.90): 0.11448535649631308
Evaluation on validation dataset:
Step 25, mean loss 0.03911771968409067
Step 50, mean loss 0.05224093921384207
Step 75, mean loss 0.03514066373068059
Step 100, mean loss 0.04103286201582616
Step 125, mean loss 0.04442823332618277
Step 150, mean loss 0.06123168610887575
Step 175, mean loss 0.06971138622899578
Step 200, mean loss 0.09759471209623061
Step 225, mean loss 0.16997590496763126
Unrolled forward losses 1.3942404027049897
Unrolled forward base losses 2.927822615141285
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.11081045793581809
Training Loss (progress: 0.10): 0.11104708774477223
Training Loss (progress: 0.20): 0.10665782668162271
Training Loss (progress: 0.30): 0.10724741287138694
Training Loss (progress: 0.40): 0.1084214738120415
Training Loss (progress: 0.50): 0.0994716330160539
Training Loss (progress: 0.60): 0.12125162953801827
Training Loss (progress: 0.70): 0.09724260217582716
Training Loss (progress: 0.80): 0.10908649883481553
Training Loss (progress: 0.90): 0.10479515071744362
Evaluation on validation dataset:
Step 25, mean loss 0.038524275952364476
Step 50, mean loss 0.045839938317733316
Step 75, mean loss 0.033984117931651875
Step 100, mean loss 0.03991113067031158
Step 125, mean loss 0.044257995949995924
Step 150, mean loss 0.06134105027708378
Step 175, mean loss 0.06942376993587825
Step 200, mean loss 0.10061663818840452
Step 225, mean loss 0.17146683213542807
Unrolled forward losses 1.404274916996526
Unrolled forward base losses 2.927822615141285
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.11535541906262736
Training Loss (progress: 0.10): 0.10339381994469589
Training Loss (progress: 0.20): 0.10474352829221911
Training Loss (progress: 0.30): 0.10845406250775262
Training Loss (progress: 0.40): 0.1100344861752052
Training Loss (progress: 0.50): 0.10416640110023054
Training Loss (progress: 0.60): 0.10555744467170908
Training Loss (progress: 0.70): 0.1106903794835545
Training Loss (progress: 0.80): 0.11345875507548067
Training Loss (progress: 0.90): 0.10220211670050156
Evaluation on validation dataset:
Step 25, mean loss 0.03799824617908723
Step 50, mean loss 0.04770584519395804
Step 75, mean loss 0.03406348321662825
Step 100, mean loss 0.040571015870426864
Step 125, mean loss 0.04478160401213526
Step 150, mean loss 0.06223844203199293
Step 175, mean loss 0.06879318721827654
Step 200, mean loss 0.10036246776772453
Step 225, mean loss 0.16764565323115016
Unrolled forward losses 1.3724343882967245
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.043555858835884184
Step 50, mean loss 0.03696810161476294
Step 75, mean loss 0.04044024190710635
Step 100, mean loss 0.04794452792565945
Step 125, mean loss 0.047848271007215865
Step 150, mean loss 0.05455587807237909
Step 175, mean loss 0.066660385044811
Step 200, mean loss 0.08581825290025598
Step 225, mean loss 0.12618679679996536
Unrolled forward losses 1.999652430278306
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  23:22:39.699761 

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.11765040818886476
Training Loss (progress: 0.10): 0.11032648879893275
Training Loss (progress: 0.20): 0.11686482064010752
Training Loss (progress: 0.30): 0.10524929822414515
Training Loss (progress: 0.40): 0.11327536881149408
Training Loss (progress: 0.50): 0.10229213087136207
Training Loss (progress: 0.60): 0.11166840365639724
Training Loss (progress: 0.70): 0.11290139167960672
Training Loss (progress: 0.80): 0.10642976666502939
Training Loss (progress: 0.90): 0.10371392073745318
Evaluation on validation dataset:
Step 25, mean loss 0.03549559231439022
Step 50, mean loss 0.042293577859519704
Step 75, mean loss 0.03377069716646078
Step 100, mean loss 0.038972829260647324
Step 125, mean loss 0.04393258327531552
Step 150, mean loss 0.06127165182636371
Step 175, mean loss 0.06931011720750094
Step 200, mean loss 0.10006728518680784
Step 225, mean loss 0.1644481437674681
Unrolled forward losses 1.378175495100068
Unrolled forward base losses 2.927822615141285
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.10755804381052188
Training Loss (progress: 0.10): 0.09577675170139555
Training Loss (progress: 0.20): 0.09936983156970328
Training Loss (progress: 0.30): 0.11524343349211362
Training Loss (progress: 0.40): 0.10013747651426669
Training Loss (progress: 0.50): 0.1099695066791106
Training Loss (progress: 0.60): 0.11254917454989717
Training Loss (progress: 0.70): 0.11399224948014064
Training Loss (progress: 0.80): 0.10252103543382371
Training Loss (progress: 0.90): 0.09468833905472392
Evaluation on validation dataset:
Step 25, mean loss 0.035848545581537855
Step 50, mean loss 0.04520589653161723
Step 75, mean loss 0.03316502198062714
Step 100, mean loss 0.03920534686857701
Step 125, mean loss 0.043104616279481374
Step 150, mean loss 0.05976634508382295
Step 175, mean loss 0.06704881432976664
Step 200, mean loss 0.09394859955658315
Step 225, mean loss 0.16150241849481056
Unrolled forward losses 1.3272488839797907
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.041550761531691766
Step 50, mean loss 0.035020138452380806
Step 75, mean loss 0.03851266629053409
Step 100, mean loss 0.04589033896585848
Step 125, mean loss 0.045823321279626586
Step 150, mean loss 0.05467294765217014
Step 175, mean loss 0.06590975271728425
Step 200, mean loss 0.08454097279647203
Step 225, mean loss 0.1244844211320251
Unrolled forward losses 1.8231727428679725
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  1 day, 2:52:20.112003 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.10705909434091304
Training Loss (progress: 0.10): 0.09817600526773634
Training Loss (progress: 0.20): 0.09915872279139436
Training Loss (progress: 0.30): 0.10925337366528143
Training Loss (progress: 0.40): 0.09941774172919274
Training Loss (progress: 0.50): 0.0950207676962678
Training Loss (progress: 0.60): 0.09690274191643497
Training Loss (progress: 0.70): 0.10790176907463211
Training Loss (progress: 0.80): 0.1021748858677074
Training Loss (progress: 0.90): 0.1060052065723971
Evaluation on validation dataset:
Step 25, mean loss 0.03434090572199268
Step 50, mean loss 0.04175766460493863
Step 75, mean loss 0.03181475691684642
Step 100, mean loss 0.038755525393492085
Step 125, mean loss 0.043282654087301746
Step 150, mean loss 0.05827110906310161
Step 175, mean loss 0.0649521568365512
Step 200, mean loss 0.09339638168297348
Step 225, mean loss 0.15595751704200767
Unrolled forward losses 1.3236219337650617
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.040151657058987
Step 50, mean loss 0.03389690944741477
Step 75, mean loss 0.03731053381106727
Step 100, mean loss 0.04592420268200163
Step 125, mean loss 0.045982599920915426
Step 150, mean loss 0.05545555918282397
Step 175, mean loss 0.06628069430837946
Step 200, mean loss 0.08594053044044483
Step 225, mean loss 0.1244405203749912
Unrolled forward losses 1.877227985103127
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  1 day, 4:37:09.574925 

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.09569964073907357
Training Loss (progress: 0.10): 0.10123259517350283
Training Loss (progress: 0.20): 0.09906047548859456
Training Loss (progress: 0.30): 0.10865811908431812
Training Loss (progress: 0.40): 0.10066989451993888
Training Loss (progress: 0.50): 0.10274456661861205
Training Loss (progress: 0.60): 0.10809521747857559
Training Loss (progress: 0.70): 0.10281069932898945
Training Loss (progress: 0.80): 0.09536552966281411
Training Loss (progress: 0.90): 0.09660277736249806
Evaluation on validation dataset:
Step 25, mean loss 0.03484698818734473
Step 50, mean loss 0.04374208142952621
Step 75, mean loss 0.0319909610470821
Step 100, mean loss 0.03868212527123598
Step 125, mean loss 0.04401469646323623
Step 150, mean loss 0.0595266108297727
Step 175, mean loss 0.06644251098860081
Step 200, mean loss 0.09406068506782436
Step 225, mean loss 0.15904524093594918
Unrolled forward losses 1.3108912488080144
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04071678342507457
Step 50, mean loss 0.034908635016579995
Step 75, mean loss 0.03755927760023679
Step 100, mean loss 0.04636012019759366
Step 125, mean loss 0.04503430757084241
Step 150, mean loss 0.05454041190500194
Step 175, mean loss 0.06560130383934296
Step 200, mean loss 0.0847167704327374
Step 225, mean loss 0.12363034289403184
Unrolled forward losses 1.881345009037556
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  1 day, 6:22:17.799889 

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.09632514620448157
Training Loss (progress: 0.10): 0.1036410081439827
Training Loss (progress: 0.20): 0.09650197938600871
Training Loss (progress: 0.30): 0.11140559090687399
Training Loss (progress: 0.40): 0.10244851644769827
Training Loss (progress: 0.50): 0.10051300454084278
Training Loss (progress: 0.60): 0.1043742797509352
Training Loss (progress: 0.70): 0.09775973101009883
Training Loss (progress: 0.80): 0.10009647005121833
Training Loss (progress: 0.90): 0.1091693505311775
Evaluation on validation dataset:
Step 25, mean loss 0.034202795207975686
Step 50, mean loss 0.04413398750062936
Step 75, mean loss 0.033904148604043914
Step 100, mean loss 0.03927432348034762
Step 125, mean loss 0.044279772301861434
Step 150, mean loss 0.06209649152362205
Step 175, mean loss 0.06680571380874109
Step 200, mean loss 0.09358179136009831
Step 225, mean loss 0.1578743968013952
Unrolled forward losses 1.3984338023777831
Unrolled forward base losses 2.927822615141285
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.0991708117635566
Training Loss (progress: 0.10): 0.1049478944220513
Training Loss (progress: 0.20): 0.10763245291944094
Training Loss (progress: 0.30): 0.09953443459587479
Training Loss (progress: 0.40): 0.0976176295743947
Training Loss (progress: 0.50): 0.10294870815227339
Training Loss (progress: 0.60): 0.10469589914089866
Training Loss (progress: 0.70): 0.11603523618901324
Training Loss (progress: 0.80): 0.09732535891530865
Training Loss (progress: 0.90): 0.09847572371095019
Evaluation on validation dataset:
Step 25, mean loss 0.03393358017467006
Step 50, mean loss 0.04657335708542201
Step 75, mean loss 0.03148431984894487
Step 100, mean loss 0.037064520476007265
Step 125, mean loss 0.04251077713035163
Step 150, mean loss 0.05979974154182573
Step 175, mean loss 0.065511476054069
Step 200, mean loss 0.09310807408697583
Step 225, mean loss 0.1549237708890327
Unrolled forward losses 1.3530067587303618
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.10313617666527893
Training Loss (progress: 0.10): 0.10479862568993768
Training Loss (progress: 0.20): 0.10452350623351045
Training Loss (progress: 0.30): 0.09573283340302635
Training Loss (progress: 0.40): 0.10477154486145825
Training Loss (progress: 0.50): 0.09742925601780174
Training Loss (progress: 0.60): 0.10143752507527404
Training Loss (progress: 0.70): 0.10923803665086583
Training Loss (progress: 0.80): 0.10291564008783409
Training Loss (progress: 0.90): 0.10131817644449641
Evaluation on validation dataset:
Step 25, mean loss 0.03303761931531089
Step 50, mean loss 0.044740493601055815
Step 75, mean loss 0.03201899346843571
Step 100, mean loss 0.0372853668387973
Step 125, mean loss 0.041522378636677834
Step 150, mean loss 0.05733572406720208
Step 175, mean loss 0.06534120808421495
Step 200, mean loss 0.09412446441429882
Step 225, mean loss 0.15991178275405754
Unrolled forward losses 1.3277642415235824
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.0994648254150666
Training Loss (progress: 0.10): 0.10797970209446259
Training Loss (progress: 0.20): 0.10261599057628806
Training Loss (progress: 0.30): 0.1070796981891034
Training Loss (progress: 0.40): 0.09590997034569913
Training Loss (progress: 0.50): 0.09757305945580097
Training Loss (progress: 0.60): 0.10274224048532252
Training Loss (progress: 0.70): 0.10697524919120227
Training Loss (progress: 0.80): 0.10411002751912281
Training Loss (progress: 0.90): 0.09549362203695183
Evaluation on validation dataset:
Step 25, mean loss 0.03339310892279756
Step 50, mean loss 0.04445480029438691
Step 75, mean loss 0.032145532395897694
Step 100, mean loss 0.03650305953300992
Step 125, mean loss 0.04134036649007444
Step 150, mean loss 0.05710258172066207
Step 175, mean loss 0.06437733282323732
Step 200, mean loss 0.09024604525888125
Step 225, mean loss 0.1527822162111553
Unrolled forward losses 1.3166456097322945
Unrolled forward base losses 2.927822615141285
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.10968584452777624
Training Loss (progress: 0.10): 0.09543968989963196
Training Loss (progress: 0.20): 0.09965284945962297
Training Loss (progress: 0.30): 0.09099957668281174
Training Loss (progress: 0.40): 0.10560195964125534
Training Loss (progress: 0.50): 0.10237592395265548
Training Loss (progress: 0.60): 0.09123230272093392
Training Loss (progress: 0.70): 0.09955712174301841
Training Loss (progress: 0.80): 0.10180371025453133
Training Loss (progress: 0.90): 0.10199693012350597
Evaluation on validation dataset:
Step 25, mean loss 0.032934020353132504
Step 50, mean loss 0.04076282792720627
Step 75, mean loss 0.03108790571519221
Step 100, mean loss 0.03705771186274999
Step 125, mean loss 0.04252266114582726
Step 150, mean loss 0.05757979933723826
Step 175, mean loss 0.06370924714620699
Step 200, mean loss 0.09199834083900768
Step 225, mean loss 0.1526135290428833
Unrolled forward losses 1.2805849790454022
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.038702993978052366
Step 50, mean loss 0.033478159313053715
Step 75, mean loss 0.03685032611313883
Step 100, mean loss 0.04461258743389196
Step 125, mean loss 0.04450877000945512
Step 150, mean loss 0.05418398671991349
Step 175, mean loss 0.06475423877036138
Step 200, mean loss 0.08564912703403048
Step 225, mean loss 0.12200316377376072
Unrolled forward losses 1.8765903442032834
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n12_tw25_unrolling2_time11141220.pt
Training time:  1 day, 15:11:17.078361 

Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.09655826710583315
Training Loss (progress: 0.10): 0.10616930489109101
Training Loss (progress: 0.20): 0.0994952806679617
Training Loss (progress: 0.30): 0.10073176489321359
Training Loss (progress: 0.40): 0.09311455106343113
Training Loss (progress: 0.50): 0.10143055314367114
Training Loss (progress: 0.60): 0.10232769449046498
Training Loss (progress: 0.70): 0.10180737417905593
Training Loss (progress: 0.80): 0.10641275007541219
Training Loss (progress: 0.90): 0.0944753926467185
Evaluation on validation dataset:
Step 25, mean loss 0.03383682922225943
Step 50, mean loss 0.04139693661192778
Step 75, mean loss 0.03183627502183309
Step 100, mean loss 0.037165804556110335
Step 125, mean loss 0.04169528934479301
Step 150, mean loss 0.05716025000604728
Step 175, mean loss 0.06477260235854682
Step 200, mean loss 0.09138557231413247
Step 225, mean loss 0.15581510426593997
Unrolled forward losses 1.284653088677329
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.09457998177288976
Training Loss (progress: 0.10): 0.08588561336114817
Training Loss (progress: 0.20): 0.1004252020639415
Training Loss (progress: 0.30): 0.10056591585028267
Training Loss (progress: 0.40): 0.09894255029189018
Training Loss (progress: 0.50): 0.09985811978156915
Training Loss (progress: 0.60): 0.09483569824014805
Training Loss (progress: 0.70): 0.10123876670894826
Training Loss (progress: 0.80): 0.09961321865795426
Training Loss (progress: 0.90): 0.1075195447849371
Evaluation on validation dataset:
Step 25, mean loss 0.03250976368562011
Step 50, mean loss 0.041685092778815325
Step 75, mean loss 0.0317470483529881
Step 100, mean loss 0.0379435509099743
Step 125, mean loss 0.041715587193450594
Step 150, mean loss 0.05752533846932352
Step 175, mean loss 0.06519155588631027
Step 200, mean loss 0.09153048876636849
Step 225, mean loss 0.15375487179848193
Unrolled forward losses 1.3361889157467677
Unrolled forward base losses 2.927822615141285
Test loss: 1.8765903442032834
Training time (until epoch 22):  {datetime.timedelta(days=1, seconds=54677, microseconds=78361)}
