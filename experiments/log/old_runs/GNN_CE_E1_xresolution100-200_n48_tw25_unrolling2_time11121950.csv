Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Number of parameters: 1031645
Training started at: 2024-11-12 19:50:01
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.2997937370063726
Training Loss (progress: 0.10): 0.5733056729623044
Training Loss (progress: 0.20): 0.41674797124229646
Training Loss (progress: 0.30): 0.3177192766349473
Training Loss (progress: 0.40): 0.25794403822336004
Training Loss (progress: 0.50): 0.22348217071413315
Training Loss (progress: 0.60): 0.186317168165691
Training Loss (progress: 0.70): 0.1774919421899407
Training Loss (progress: 0.80): 0.16016708727051573
Training Loss (progress: 0.90): 0.15399422810568428
Evaluation on validation dataset:
Step 25, mean loss 0.14641163498101178
Step 50, mean loss 0.19800479955167954
Step 75, mean loss 0.2122887300011357
Step 100, mean loss 0.30010002005497544
Step 125, mean loss 0.2734179156123532
Step 150, mean loss 0.3335322367756067
Step 175, mean loss 0.5111730010808009
Step 200, mean loss 0.5031526006013346
Step 225, mean loss 0.4330091154550263
Unrolled forward losses 34.78977770806975
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.16067367582857242
Step 50, mean loss 0.23001509140581505
Step 75, mean loss 0.2551604584434531
Step 100, mean loss 0.33859324765029497
Step 125, mean loss 0.37244100642542477
Step 150, mean loss 0.3315798929473941
Step 175, mean loss 0.31786764571965376
Step 200, mean loss 0.5907158285692333
Step 225, mean loss 0.574835114455515
Unrolled forward losses 39.89889488832169
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  1:29:10.193010 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.3222811912845203
Training Loss (progress: 0.10): 0.3193673415100314
Training Loss (progress: 0.20): 0.3005910127672752
Training Loss (progress: 0.30): 0.26810507988488824
Training Loss (progress: 0.40): 0.24643858209540476
Training Loss (progress: 0.50): 0.264244456019589
Training Loss (progress: 0.60): 0.2442561179118569
Training Loss (progress: 0.70): 0.21967411328644199
Training Loss (progress: 0.80): 0.21537899417091422
Training Loss (progress: 0.90): 0.21428634963176668
Evaluation on validation dataset:
Step 25, mean loss 0.16137176674176135
Step 50, mean loss 0.16727943357758657
Step 75, mean loss 0.1516183121920196
Step 100, mean loss 0.17938186571589623
Step 125, mean loss 0.20219100278099955
Step 150, mean loss 0.24113339803815206
Step 175, mean loss 0.2788783303145961
Step 200, mean loss 0.293722704531936
Step 225, mean loss 0.356703535945632
Unrolled forward losses 6.453809862407319
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.16850293313839523
Step 50, mean loss 0.1632896520817069
Step 75, mean loss 0.17858234910544823
Step 100, mean loss 0.2763654367205278
Step 125, mean loss 0.27323772762694565
Step 150, mean loss 0.23386178038020036
Step 175, mean loss 0.24242915971411794
Step 200, mean loss 0.3228676605155316
Step 225, mean loss 0.42806955927359547
Unrolled forward losses 8.382986312427972
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  3:07:14.197080 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.3042305047555792
Training Loss (progress: 0.10): 0.2711153229751685
Training Loss (progress: 0.20): 0.27871165706585466
Training Loss (progress: 0.30): 0.2950282816392966
Training Loss (progress: 0.40): 0.2572710670870224
Training Loss (progress: 0.50): 0.2416975375231117
Training Loss (progress: 0.60): 0.2623474560481163
Training Loss (progress: 0.70): 0.24659356493346862
Training Loss (progress: 0.80): 0.2455461383492172
Training Loss (progress: 0.90): 0.26251032842208394
Evaluation on validation dataset:
Step 25, mean loss 0.15478812001414127
Step 50, mean loss 0.13508104457757025
Step 75, mean loss 0.12524771172031016
Step 100, mean loss 0.141037147789764
Step 125, mean loss 0.16790704527137412
Step 150, mean loss 0.17771039460001947
Step 175, mean loss 0.2148151260596264
Step 200, mean loss 0.24521794827565901
Step 225, mean loss 0.2703521796500863
Unrolled forward losses 3.9659598932077884
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.16416490216336327
Step 50, mean loss 0.13105544923708798
Step 75, mean loss 0.14347269207332303
Step 100, mean loss 0.21325016897017307
Step 125, mean loss 0.21425587759529816
Step 150, mean loss 0.19231727504398963
Step 175, mean loss 0.2278953940641081
Step 200, mean loss 0.25752869896806685
Step 225, mean loss 0.3236302446627105
Unrolled forward losses 5.660299519879601
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  4:52:13.388803 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.26090561694680175
Training Loss (progress: 0.10): 0.23784052078641532
Training Loss (progress: 0.20): 0.2495251283061648
Training Loss (progress: 0.30): 0.22449559797661892
Training Loss (progress: 0.40): 0.22188260780273586
Training Loss (progress: 0.50): 0.21759227039144657
Training Loss (progress: 0.60): 0.22411635488866574
Training Loss (progress: 0.70): 0.20812261755529635
Training Loss (progress: 0.80): 0.2191862301971053
Training Loss (progress: 0.90): 0.2158436601151388
Evaluation on validation dataset:
Step 25, mean loss 0.12461907525157627
Step 50, mean loss 0.11163284833036438
Step 75, mean loss 0.1034816515030087
Step 100, mean loss 0.1210438322675258
Step 125, mean loss 0.15916579126530134
Step 150, mean loss 0.16139579278300775
Step 175, mean loss 0.1906466154390673
Step 200, mean loss 0.22607435522554997
Step 225, mean loss 0.2622070698576309
Unrolled forward losses 3.2684500371860263
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.1377599282625701
Step 50, mean loss 0.10499463148056648
Step 75, mean loss 0.11514049666226187
Step 100, mean loss 0.1835905589474422
Step 125, mean loss 0.20556748570872357
Step 150, mean loss 0.1852392388049207
Step 175, mean loss 0.21283109862773603
Step 200, mean loss 0.23562237370243228
Step 225, mean loss 0.2809408113667398
Unrolled forward losses 5.044760143516286
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  6:38:25.808911 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.20771559009765403
Training Loss (progress: 0.10): 0.20255358413012325
Training Loss (progress: 0.20): 0.22021231657560328
Training Loss (progress: 0.30): 0.2174503836184289
Training Loss (progress: 0.40): 0.21710550310978993
Training Loss (progress: 0.50): 0.21303677949989774
Training Loss (progress: 0.60): 0.20616824164313488
Training Loss (progress: 0.70): 0.20395285016964487
Training Loss (progress: 0.80): 0.21024663356113904
Training Loss (progress: 0.90): 0.19862549664740306
Evaluation on validation dataset:
Step 25, mean loss 0.10753862318880289
Step 50, mean loss 0.09201835719496364
Step 75, mean loss 0.09708785895200325
Step 100, mean loss 0.10348499695856572
Step 125, mean loss 0.11546726384508986
Step 150, mean loss 0.1327017315482342
Step 175, mean loss 0.205398393497859
Step 200, mean loss 0.20607519268691424
Step 225, mean loss 0.22965646945122448
Unrolled forward losses 3.1152853807470855
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.12176077015731325
Step 50, mean loss 0.08681026494544095
Step 75, mean loss 0.10469157285284467
Step 100, mean loss 0.14815117339918932
Step 125, mean loss 0.1723802632960359
Step 150, mean loss 0.15430974409501264
Step 175, mean loss 0.20099757800806564
Step 200, mean loss 0.21358982025738263
Step 225, mean loss 0.28858411929908984
Unrolled forward losses 4.498610670869814
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  8:24:57.026216 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.17709029853105374
Training Loss (progress: 0.10): 0.170963621515352
Training Loss (progress: 0.20): 0.17588578413412428
Training Loss (progress: 0.30): 0.18950553930602082
Training Loss (progress: 0.40): 0.17840111255632884
Training Loss (progress: 0.50): 0.1835808712989351
Training Loss (progress: 0.60): 0.1667897212849454
Training Loss (progress: 0.70): 0.1647608779247974
Training Loss (progress: 0.80): 0.17727306043985722
Training Loss (progress: 0.90): 0.1675889835084011
Evaluation on validation dataset:
Step 25, mean loss 0.08906109354676103
Step 50, mean loss 0.08586812263397264
Step 75, mean loss 0.07687695312455806
Step 100, mean loss 0.08557932329354936
Step 125, mean loss 0.1071936547922543
Step 150, mean loss 0.12145220919923536
Step 175, mean loss 0.15528002053299228
Step 200, mean loss 0.18791285332749044
Step 225, mean loss 0.19536967949359685
Unrolled forward losses 2.59432978166472
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09707828453006873
Step 50, mean loss 0.07612805834118062
Step 75, mean loss 0.0894245034602187
Step 100, mean loss 0.1437332630938503
Step 125, mean loss 0.1566875403685105
Step 150, mean loss 0.15170391813434617
Step 175, mean loss 0.17671461881397724
Step 200, mean loss 0.1996778546238166
Step 225, mean loss 0.2659080194672645
Unrolled forward losses 3.8029597941372772
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  10:12:22.086928 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.15903620623664563
Training Loss (progress: 0.10): 0.16628871460366837
Training Loss (progress: 0.20): 0.1623980074899692
Training Loss (progress: 0.30): 0.15685873713376355
Training Loss (progress: 0.40): 0.1638026095955189
Training Loss (progress: 0.50): 0.1643423586658118
Training Loss (progress: 0.60): 0.16098516369878013
Training Loss (progress: 0.70): 0.1596040941862852
Training Loss (progress: 0.80): 0.158923899778733
Training Loss (progress: 0.90): 0.16048809638718683
Evaluation on validation dataset:
Step 25, mean loss 0.08428760968359622
Step 50, mean loss 0.0801678945838166
Step 75, mean loss 0.07508346604211637
Step 100, mean loss 0.08125590586350884
Step 125, mean loss 0.09746341580744315
Step 150, mean loss 0.1170303366823802
Step 175, mean loss 0.1533937006000518
Step 200, mean loss 0.20098761423690742
Step 225, mean loss 0.19309341836354899
Unrolled forward losses 2.399608181355415
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09564226172391371
Step 50, mean loss 0.07356860116848585
Step 75, mean loss 0.08585379821886027
Step 100, mean loss 0.12631699712510286
Step 125, mean loss 0.1483270421801524
Step 150, mean loss 0.13558059791803095
Step 175, mean loss 0.16548615338904654
Step 200, mean loss 0.19141108551674899
Step 225, mean loss 0.24249566036270823
Unrolled forward losses 3.5276027768217193
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  11:59:17.260516 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.15399987575833557
Training Loss (progress: 0.10): 0.16541696522585242
Training Loss (progress: 0.20): 0.17239394037657393
Training Loss (progress: 0.30): 0.15682508028798958
Training Loss (progress: 0.40): 0.15550339436306426
Training Loss (progress: 0.50): 0.15511965636266736
Training Loss (progress: 0.60): 0.15863075094670787
Training Loss (progress: 0.70): 0.16112242034931068
Training Loss (progress: 0.80): 0.16830758257164255
Training Loss (progress: 0.90): 0.14627899167653105
Evaluation on validation dataset:
Step 25, mean loss 0.07775820051939342
Step 50, mean loss 0.07073675640148
Step 75, mean loss 0.07741006525374909
Step 100, mean loss 0.080264770247881
Step 125, mean loss 0.09452248445344075
Step 150, mean loss 0.11564838576422296
Step 175, mean loss 0.15027698262154734
Step 200, mean loss 0.1890548638738912
Step 225, mean loss 0.19098248830389034
Unrolled forward losses 2.4193608498316856
Unrolled forward base losses 2.927822615141285
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.1551837473572336
Training Loss (progress: 0.10): 0.15334113904988061
Training Loss (progress: 0.20): 0.16667660803971449
Training Loss (progress: 0.30): 0.1611620342929532
Training Loss (progress: 0.40): 0.14567374716774711
Training Loss (progress: 0.50): 0.15098308025291382
Training Loss (progress: 0.60): 0.1507689109390783
Training Loss (progress: 0.70): 0.1646463251958933
Training Loss (progress: 0.80): 0.13163508321793058
Training Loss (progress: 0.90): 0.15249394871839045
Evaluation on validation dataset:
Step 25, mean loss 0.08063303385253613
Step 50, mean loss 0.07447971339145767
Step 75, mean loss 0.07302986539755962
Step 100, mean loss 0.07959828236013372
Step 125, mean loss 0.09177639201061741
Step 150, mean loss 0.11325977489152213
Step 175, mean loss 0.15335175775083226
Step 200, mean loss 0.19073257281319989
Step 225, mean loss 0.1796748104842523
Unrolled forward losses 2.427980137796608
Unrolled forward base losses 2.927822615141285
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.15199496950378974
Training Loss (progress: 0.10): 0.14727006166118042
Training Loss (progress: 0.20): 0.14456009850866738
Training Loss (progress: 0.30): 0.1479428289666024
Training Loss (progress: 0.40): 0.15341582662597894
Training Loss (progress: 0.50): 0.1462689634093286
Training Loss (progress: 0.60): 0.14994284212056389
Training Loss (progress: 0.70): 0.1395027451787744
Training Loss (progress: 0.80): 0.13702951759478488
Training Loss (progress: 0.90): 0.13881334148847915
Evaluation on validation dataset:
Step 25, mean loss 0.06728966367319894
Step 50, mean loss 0.06738930999249947
Step 75, mean loss 0.08000218922083502
Step 100, mean loss 0.07618589282792586
Step 125, mean loss 0.09225918061540997
Step 150, mean loss 0.10793789542460902
Step 175, mean loss 0.14835536221403822
Step 200, mean loss 0.20166699991097908
Step 225, mean loss 0.19058469878306153
Unrolled forward losses 2.5248672526803255
Unrolled forward base losses 2.927822615141285
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.1351848396173574
Training Loss (progress: 0.10): 0.14518055802325863
Training Loss (progress: 0.20): 0.14522420471039688
Training Loss (progress: 0.30): 0.13289910332384025
Training Loss (progress: 0.40): 0.14243894652125022
Training Loss (progress: 0.50): 0.14285965278429405
Training Loss (progress: 0.60): 0.13294709069485564
Training Loss (progress: 0.70): 0.14108420812920253
Training Loss (progress: 0.80): 0.1413995113354445
Training Loss (progress: 0.90): 0.13743117925220105
Evaluation on validation dataset:
Step 25, mean loss 0.06437315550886444
Step 50, mean loss 0.06456568725265349
Step 75, mean loss 0.06824484051061355
Step 100, mean loss 0.06922865095844609
Step 125, mean loss 0.0803222765280995
Step 150, mean loss 0.1001851851632387
Step 175, mean loss 0.14184214880587584
Step 200, mean loss 0.17507712320263447
Step 225, mean loss 0.17799179897639283
Unrolled forward losses 2.219775866330371
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07671953564447509
Step 50, mean loss 0.06166330240697129
Step 75, mean loss 0.07374794487491494
Step 100, mean loss 0.11593892976664727
Step 125, mean loss 0.14546736627503154
Step 150, mean loss 0.12119938293945245
Step 175, mean loss 0.1404237458752821
Step 200, mean loss 0.17839791514666564
Step 225, mean loss 0.21335054158267536
Unrolled forward losses 3.0564204372011137
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  19:10:24.681399 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.14080484846624264
Training Loss (progress: 0.10): 0.13419540872607785
Training Loss (progress: 0.20): 0.1333926477866587
Training Loss (progress: 0.30): 0.14092231288634127
Training Loss (progress: 0.40): 0.12371068428418114
Training Loss (progress: 0.50): 0.12805617339528333
Training Loss (progress: 0.60): 0.13112180326444858
Training Loss (progress: 0.70): 0.13776145045983434
Training Loss (progress: 0.80): 0.12946877118166172
Training Loss (progress: 0.90): 0.1342234666651756
Evaluation on validation dataset:
Step 25, mean loss 0.06386879239998722
Step 50, mean loss 0.06310690334358783
Step 75, mean loss 0.0708115391334765
Step 100, mean loss 0.07261460066832404
Step 125, mean loss 0.08340474427549648
Step 150, mean loss 0.10109686739846473
Step 175, mean loss 0.13647864245485367
Step 200, mean loss 0.17439147466266022
Step 225, mean loss 0.1778303466273899
Unrolled forward losses 2.306266564243419
Unrolled forward base losses 2.927822615141285
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.1384435159593096
Training Loss (progress: 0.10): 0.12931409223152554
Training Loss (progress: 0.20): 0.13689892670695453
Training Loss (progress: 0.30): 0.14298530201895257
Training Loss (progress: 0.40): 0.13265578135024225
Training Loss (progress: 0.50): 0.13836611213252423
Training Loss (progress: 0.60): 0.14036928306099333
Training Loss (progress: 0.70): 0.12384464049532691
Training Loss (progress: 0.80): 0.1245164875497435
Training Loss (progress: 0.90): 0.13070654245715946
Evaluation on validation dataset:
Step 25, mean loss 0.061899209894611264
Step 50, mean loss 0.0654973164329491
Step 75, mean loss 0.06436476713513051
Step 100, mean loss 0.06763560728659032
Step 125, mean loss 0.07621489055271727
Step 150, mean loss 0.10076830879533594
Step 175, mean loss 0.13970140231271877
Step 200, mean loss 0.1687488133177592
Step 225, mean loss 0.1749202131429207
Unrolled forward losses 2.0628306400653185
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07248811101401198
Step 50, mean loss 0.058685502950156704
Step 75, mean loss 0.07266339952269152
Step 100, mean loss 0.10621260265835727
Step 125, mean loss 0.14302801067498086
Step 150, mean loss 0.11719540764418215
Step 175, mean loss 0.13894564642912424
Step 200, mean loss 0.17260897479662934
Step 225, mean loss 0.22035161605442577
Unrolled forward losses 2.8904483738709548
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  22:43:23.466733 

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.13283563689318661
Training Loss (progress: 0.10): 0.12545885044904
Training Loss (progress: 0.20): 0.12213967592809519
Training Loss (progress: 0.30): 0.13512813859955863
Training Loss (progress: 0.40): 0.12966471657515682
Training Loss (progress: 0.50): 0.13467692089451447
Training Loss (progress: 0.60): 0.12350267113768303
Training Loss (progress: 0.70): 0.1322521951875318
Training Loss (progress: 0.80): 0.1252822080978908
Training Loss (progress: 0.90): 0.12218858524083226
Evaluation on validation dataset:
Step 25, mean loss 0.06095767004512263
Step 50, mean loss 0.06311625306178384
Step 75, mean loss 0.06319231156387356
Step 100, mean loss 0.06761189918098255
Step 125, mean loss 0.07647874779824593
Step 150, mean loss 0.09772567929286083
Step 175, mean loss 0.133418397227207
Step 200, mean loss 0.1661650187658973
Step 225, mean loss 0.17025014211753386
Unrolled forward losses 2.11834896501916
Unrolled forward base losses 2.927822615141285
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.1273128734139799
Training Loss (progress: 0.10): 0.12676386719887242
Training Loss (progress: 0.20): 0.131488369888146
Training Loss (progress: 0.30): 0.13368591864538393
Training Loss (progress: 0.40): 0.12532280886027963
Training Loss (progress: 0.50): 0.1326660816233516
Training Loss (progress: 0.60): 0.12551595699958273
Training Loss (progress: 0.70): 0.13987698445555585
Training Loss (progress: 0.80): 0.12867914672423814
Training Loss (progress: 0.90): 0.13203951679240858
Evaluation on validation dataset:
Step 25, mean loss 0.059502923157352366
Step 50, mean loss 0.0626225662293414
Step 75, mean loss 0.06455368629275987
Step 100, mean loss 0.0654793162706459
Step 125, mean loss 0.07745073552209442
Step 150, mean loss 0.09778689218128936
Step 175, mean loss 0.13631242088446605
Step 200, mean loss 0.16266791451031687
Step 225, mean loss 0.16805335917922198
Unrolled forward losses 2.142182951155566
Unrolled forward base losses 2.927822615141285
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.12561296581447084
Training Loss (progress: 0.10): 0.12120507689471419
Training Loss (progress: 0.20): 0.12545949312789742
Training Loss (progress: 0.30): 0.12564715149228162
Training Loss (progress: 0.40): 0.12874858616518514
Training Loss (progress: 0.50): 0.11819439454311709
Training Loss (progress: 0.60): 0.12336832909701759
Training Loss (progress: 0.70): 0.12671044710585472
Training Loss (progress: 0.80): 0.11626190757969701
Training Loss (progress: 0.90): 0.11933259477821376
Evaluation on validation dataset:
Step 25, mean loss 0.05667372336530262
Step 50, mean loss 0.057889753232006375
Step 75, mean loss 0.06254602566244488
Step 100, mean loss 0.06295077016458306
Step 125, mean loss 0.07345744001070348
Step 150, mean loss 0.09634419979685738
Step 175, mean loss 0.12500709092601764
Step 200, mean loss 0.16090843734150712
Step 225, mean loss 0.16737815704409262
Unrolled forward losses 2.0626984935196964
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06790975128713207
Step 50, mean loss 0.0567125238393034
Step 75, mean loss 0.0680211322469211
Step 100, mean loss 0.107609538584654
Step 125, mean loss 0.14062742852984939
Step 150, mean loss 0.11263446363307601
Step 175, mean loss 0.13483543617430915
Step 200, mean loss 0.17367919272833
Step 225, mean loss 0.2029792936267576
Unrolled forward losses 2.847410231511435
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  1 day, 5:39:03.810802 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.12334252436192211
Training Loss (progress: 0.10): 0.12298517689631334
Training Loss (progress: 0.20): 0.12812652223070142
Training Loss (progress: 0.30): 0.12302041918103152
Training Loss (progress: 0.40): 0.11558262449344951
Training Loss (progress: 0.50): 0.11904841154072074
Training Loss (progress: 0.60): 0.12590981372451018
Training Loss (progress: 0.70): 0.12505828064447438
Training Loss (progress: 0.80): 0.11450117882162614
Training Loss (progress: 0.90): 0.12642415011310731
Evaluation on validation dataset:
Step 25, mean loss 0.055949169376442634
Step 50, mean loss 0.05776306917537763
Step 75, mean loss 0.06434856729091405
Step 100, mean loss 0.06401271747161427
Step 125, mean loss 0.07237178623140521
Step 150, mean loss 0.09551238326949048
Step 175, mean loss 0.13114867164197241
Step 200, mean loss 0.15965298303216047
Step 225, mean loss 0.16891170666761662
Unrolled forward losses 2.04500273999097
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06760743570702313
Step 50, mean loss 0.056301382951326945
Step 75, mean loss 0.06657626095057001
Step 100, mean loss 0.10630425824043344
Step 125, mean loss 0.1416838681551008
Step 150, mean loss 0.11439970754469181
Step 175, mean loss 0.13711974092837004
Step 200, mean loss 0.17280836259839033
Step 225, mean loss 0.2076298285808213
Unrolled forward losses 2.8542015496896904
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  1 day, 7:26:19.010752 

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.12848382647011908
Training Loss (progress: 0.10): 0.11972799173762921
Training Loss (progress: 0.20): 0.11811042684435552
Training Loss (progress: 0.30): 0.12591723266827673
Training Loss (progress: 0.40): 0.13210273516984833
Training Loss (progress: 0.50): 0.11379141118747528
Training Loss (progress: 0.60): 0.12409477334592123
Training Loss (progress: 0.70): 0.126719779358844
Training Loss (progress: 0.80): 0.12433164838248423
Training Loss (progress: 0.90): 0.12235713207216467
Evaluation on validation dataset:
Step 25, mean loss 0.05551077254945494
Step 50, mean loss 0.057409105891995355
Step 75, mean loss 0.06385867878623759
Step 100, mean loss 0.06276231620066264
Step 125, mean loss 0.07247257708650487
Step 150, mean loss 0.09415901199760265
Step 175, mean loss 0.12771294198041833
Step 200, mean loss 0.15864132656482496
Step 225, mean loss 0.16827813373335443
Unrolled forward losses 2.053993047930581
Unrolled forward base losses 2.927822615141285
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.11895882508004901
Training Loss (progress: 0.10): 0.11538579711333054
Training Loss (progress: 0.20): 0.12943371951666963
Training Loss (progress: 0.30): 0.11822497845088854
Training Loss (progress: 0.40): 0.11485034468040796
Training Loss (progress: 0.50): 0.11376246389948362
Training Loss (progress: 0.60): 0.1208095845440534
Training Loss (progress: 0.70): 0.12320888290396965
Training Loss (progress: 0.80): 0.11708219616379419
Training Loss (progress: 0.90): 0.13163446552433192
Evaluation on validation dataset:
Step 25, mean loss 0.0545702690653484
Step 50, mean loss 0.05723598115191868
Step 75, mean loss 0.06414867251823597
Step 100, mean loss 0.06331137002553833
Step 125, mean loss 0.07354328597133508
Step 150, mean loss 0.09565514656988332
Step 175, mean loss 0.12649480148060988
Step 200, mean loss 0.15788394522470567
Step 225, mean loss 0.16862443084746387
Unrolled forward losses 2.094245171527823
Unrolled forward base losses 2.927822615141285
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.10839266833620935
Training Loss (progress: 0.10): 0.13504241295240632
Training Loss (progress: 0.20): 0.11545941231624346
Training Loss (progress: 0.30): 0.12071298139528254
Training Loss (progress: 0.40): 0.11223374846029895
Training Loss (progress: 0.50): 0.12239360121124364
Training Loss (progress: 0.60): 0.12110618842482981
Training Loss (progress: 0.70): 0.1078451972727195
Training Loss (progress: 0.80): 0.1262015862407265
Training Loss (progress: 0.90): 0.11985942452148474
Evaluation on validation dataset:
Step 25, mean loss 0.05483613315788023
Step 50, mean loss 0.05694367498091582
Step 75, mean loss 0.06315324885356013
Step 100, mean loss 0.06259967259811289
Step 125, mean loss 0.07290122548795196
Step 150, mean loss 0.09441984720370694
Step 175, mean loss 0.12661795379635854
Step 200, mean loss 0.156935596343445
Step 225, mean loss 0.16550578034232993
Unrolled forward losses 2.095515532546614
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.12492093066420555
Training Loss (progress: 0.10): 0.12426256878757164
Training Loss (progress: 0.20): 0.12181097183066689
Training Loss (progress: 0.30): 0.12200430712648659
Training Loss (progress: 0.40): 0.11209807494691672
Training Loss (progress: 0.50): 0.11350889838881859
Training Loss (progress: 0.60): 0.10836153902321244
Training Loss (progress: 0.70): 0.11938097181204939
Training Loss (progress: 0.80): 0.12021862730230759
Training Loss (progress: 0.90): 0.11912678482601188
Evaluation on validation dataset:
Step 25, mean loss 0.05410100286958621
Step 50, mean loss 0.05597452055855519
Step 75, mean loss 0.06165119101053748
Step 100, mean loss 0.06289237694752672
Step 125, mean loss 0.07264355003608351
Step 150, mean loss 0.09519081302441501
Step 175, mean loss 0.12670558216261135
Step 200, mean loss 0.15481910708584207
Step 225, mean loss 0.16443337924665014
Unrolled forward losses 2.078778627227525
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.11868174813836603
Training Loss (progress: 0.10): 0.12430139960100271
Training Loss (progress: 0.20): 0.12761333807387387
Training Loss (progress: 0.30): 0.11646016040713984
Training Loss (progress: 0.40): 0.11968038722335314
Training Loss (progress: 0.50): 0.1204027722396108
Training Loss (progress: 0.60): 0.11891329670262647
Training Loss (progress: 0.70): 0.11505389415105882
Training Loss (progress: 0.80): 0.12245567872804242
Training Loss (progress: 0.90): 0.11401050828743413
Evaluation on validation dataset:
Step 25, mean loss 0.05287009286269682
Step 50, mean loss 0.05423919412818132
Step 75, mean loss 0.06034461786338209
Step 100, mean loss 0.06152917675333702
Step 125, mean loss 0.07058225019825423
Step 150, mean loss 0.09506084950902374
Step 175, mean loss 0.12575424697636983
Step 200, mean loss 0.15442308657683942
Step 225, mean loss 0.16683329320007928
Unrolled forward losses 2.0214519226679504
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06456781672880108
Step 50, mean loss 0.055756997110039556
Step 75, mean loss 0.0655568338693196
Step 100, mean loss 0.10308024284678016
Step 125, mean loss 0.14006381201763432
Step 150, mean loss 0.11312260007948367
Step 175, mean loss 0.13432999156675202
Step 200, mean loss 0.1737236580858111
Step 225, mean loss 0.20740297992227094
Unrolled forward losses 2.8146352786748716
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  1 day, 16:26:08.500868 

Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.12540246919651343
Training Loss (progress: 0.10): 0.11934401848475215
Training Loss (progress: 0.20): 0.11895747611240481
Training Loss (progress: 0.30): 0.10478793606995442
Training Loss (progress: 0.40): 0.11134260262909745
Training Loss (progress: 0.50): 0.11829834202060499
Training Loss (progress: 0.60): 0.1146229011062735
Training Loss (progress: 0.70): 0.11965987789635538
Training Loss (progress: 0.80): 0.12020533809423954
Training Loss (progress: 0.90): 0.12406894339609469
Evaluation on validation dataset:
Step 25, mean loss 0.052619716330172164
Step 50, mean loss 0.056616791820179896
Step 75, mean loss 0.062149853979875845
Step 100, mean loss 0.06201811837433283
Step 125, mean loss 0.07157120946865606
Step 150, mean loss 0.09295230739492646
Step 175, mean loss 0.12738452155745197
Step 200, mean loss 0.1535910722664055
Step 225, mean loss 0.16525212428839467
Unrolled forward losses 2.055733076686394
Unrolled forward base losses 2.927822615141285
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.11857645778571313
Training Loss (progress: 0.10): 0.11274946850896414
Training Loss (progress: 0.20): 0.10944545847195751
Training Loss (progress: 0.30): 0.1210277423425233
Training Loss (progress: 0.40): 0.11317494283373933
Training Loss (progress: 0.50): 0.11992224912397785
Training Loss (progress: 0.60): 0.1289824074884048
Training Loss (progress: 0.70): 0.11792951257658217
Training Loss (progress: 0.80): 0.11575295644044088
Training Loss (progress: 0.90): 0.12217106289978132
Evaluation on validation dataset:
Step 25, mean loss 0.052224594483656475
Step 50, mean loss 0.05658277825433304
Step 75, mean loss 0.059412753701157166
Step 100, mean loss 0.06125015590781427
Step 125, mean loss 0.07101826305133378
Step 150, mean loss 0.09214254504635944
Step 175, mean loss 0.12660982797185993
Step 200, mean loss 0.15442124879435087
Step 225, mean loss 0.1615807547608474
Unrolled forward losses 2.0034609891014585
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06497958254179448
Step 50, mean loss 0.05574979418768809
Step 75, mean loss 0.06548272205700695
Step 100, mean loss 0.10408729149075935
Step 125, mean loss 0.1421774540766852
Step 150, mean loss 0.11527363677459504
Step 175, mean loss 0.13251672493019917
Step 200, mean loss 0.1724979233386818
Step 225, mean loss 0.2046779398387139
Unrolled forward losses 2.9199605603124485
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n48_tw25_unrolling2_time11121950.pt
Training time:  1 day, 20:04:25.135737 

Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.12065690192784831
Training Loss (progress: 0.10): 0.11197255788599135
Training Loss (progress: 0.20): 0.1263823449682468
Training Loss (progress: 0.30): 0.1192107735340812
Training Loss (progress: 0.40): 0.12211199326991454
Training Loss (progress: 0.50): 0.12215379247009514
Training Loss (progress: 0.60): 0.12114366209635306
Training Loss (progress: 0.70): 0.11432889544977615
Training Loss (progress: 0.80): 0.1184511907671846
Training Loss (progress: 0.90): 0.10904437277821571
Evaluation on validation dataset:
Step 25, mean loss 0.051982543629129435
Step 50, mean loss 0.056309228381789755
Step 75, mean loss 0.05992509199054842
Step 100, mean loss 0.06141884303369816
Step 125, mean loss 0.07223546002826124
Step 150, mean loss 0.0928128864606292
Step 175, mean loss 0.12461757732345179
Step 200, mean loss 0.15339563404957507
Step 225, mean loss 0.16281029372385494
Unrolled forward losses 2.0324048678030375
Unrolled forward base losses 2.927822615141285
Test loss: 2.9199605603124485
Training time (until epoch 23):  {datetime.timedelta(days=1, seconds=72265, microseconds=135737)}
