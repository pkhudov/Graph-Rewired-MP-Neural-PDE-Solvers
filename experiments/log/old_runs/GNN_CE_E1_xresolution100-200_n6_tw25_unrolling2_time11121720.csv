Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Number of parameters: 1031645
Training started at: 2024-11-12 17:20:22
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.2884264032736312
Training Loss (progress: 0.10): 0.2682885494378164
Training Loss (progress: 0.20): 0.2093577516257442
Training Loss (progress: 0.30): 0.17548685379442094
Training Loss (progress: 0.40): 0.1602516623546538
Training Loss (progress: 0.50): 0.1537186155065572
Training Loss (progress: 0.60): 0.13026115382351078
Training Loss (progress: 0.70): 0.1255639879546284
Training Loss (progress: 0.80): 0.11622772306439201
Training Loss (progress: 0.90): 0.11112283025099316
Evaluation on validation dataset:
Step 25, mean loss 0.11140686448667822
Step 50, mean loss 0.1386191431207544
Step 75, mean loss 0.11270998594232692
Step 100, mean loss 0.15940486479456764
Step 125, mean loss 0.16136409925098974
Step 150, mean loss 0.2578979410761757
Step 175, mean loss 0.20520071006586377
Step 200, mean loss 0.3086214193706518
Step 225, mean loss 0.25969005035466575
Unrolled forward losses 13.209985814974832
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0989145269572303
Step 50, mean loss 0.21372085071999247
Step 75, mean loss 0.19643915879947535
Step 100, mean loss 0.16750544474944767
Step 125, mean loss 0.19795244068607767
Step 150, mean loss 0.17100957171165698
Step 175, mean loss 0.18881726724065187
Step 200, mean loss 0.23028619713945314
Step 225, mean loss 0.3616681590811107
Unrolled forward losses 12.471792485651832
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  1:26:50.115040 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.22848061441823939
Training Loss (progress: 0.10): 0.21367135078781926
Training Loss (progress: 0.20): 0.18894074602944164
Training Loss (progress: 0.30): 0.17760180908272982
Training Loss (progress: 0.40): 0.18687160956600843
Training Loss (progress: 0.50): 0.17634088967459208
Training Loss (progress: 0.60): 0.1799999191960868
Training Loss (progress: 0.70): 0.17930427653511227
Training Loss (progress: 0.80): 0.16156369495892192
Training Loss (progress: 0.90): 0.15537790055000614
Evaluation on validation dataset:
Step 25, mean loss 0.10151082321679017
Step 50, mean loss 0.12057651853860868
Step 75, mean loss 0.0808682581186905
Step 100, mean loss 0.08635899722203837
Step 125, mean loss 0.09227004100193634
Step 150, mean loss 0.10569727908572574
Step 175, mean loss 0.13440956521109915
Step 200, mean loss 0.18378894387474315
Step 225, mean loss 0.19902980007558932
Unrolled forward losses 3.6855282197885995
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10903145737437739
Step 50, mean loss 0.1154483548258323
Step 75, mean loss 0.08892793883646077
Step 100, mean loss 0.09289939477524055
Step 125, mean loss 0.12077179728260432
Step 150, mean loss 0.1074311475078415
Step 175, mean loss 0.13110918360830248
Step 200, mean loss 0.15740448413775338
Step 225, mean loss 0.2220129180395175
Unrolled forward losses 4.546688686692601
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  3:00:23.055393 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.21964259245254067
Training Loss (progress: 0.10): 0.20624077793154405
Training Loss (progress: 0.20): 0.20950915758863115
Training Loss (progress: 0.30): 0.21178201668151453
Training Loss (progress: 0.40): 0.20555702847764531
Training Loss (progress: 0.50): 0.20022990855138598
Training Loss (progress: 0.60): 0.19205058911143388
Training Loss (progress: 0.70): 0.2128025998284307
Training Loss (progress: 0.80): 0.1888053277103387
Training Loss (progress: 0.90): 0.2049623154685001
Evaluation on validation dataset:
Step 25, mean loss 0.08998152628417533
Step 50, mean loss 0.0854010792187123
Step 75, mean loss 0.06458159531824167
Step 100, mean loss 0.07762223779691535
Step 125, mean loss 0.07580865868947101
Step 150, mean loss 0.10362664201656459
Step 175, mean loss 0.1116874609651904
Step 200, mean loss 0.13773116172504435
Step 225, mean loss 0.15272781755041703
Unrolled forward losses 3.4757349267279025
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09998313330651784
Step 50, mean loss 0.08058905935844701
Step 75, mean loss 0.06778326316188009
Step 100, mean loss 0.07428697846776183
Step 125, mean loss 0.09205715400137096
Step 150, mean loss 0.08848926987981212
Step 175, mean loss 0.10650573002925151
Step 200, mean loss 0.12029388752596062
Step 225, mean loss 0.1673748932254582
Unrolled forward losses 3.486762034684885
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  4:38:02.582186 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.19761866788502336
Training Loss (progress: 0.10): 0.19666908791219384
Training Loss (progress: 0.20): 0.1920283498976363
Training Loss (progress: 0.30): 0.16652383213355507
Training Loss (progress: 0.40): 0.1808831903699166
Training Loss (progress: 0.50): 0.17577948124122347
Training Loss (progress: 0.60): 0.18010561346141205
Training Loss (progress: 0.70): 0.1846342635801351
Training Loss (progress: 0.80): 0.16255490163257436
Training Loss (progress: 0.90): 0.17701017168642835
Evaluation on validation dataset:
Step 25, mean loss 0.07677866177221826
Step 50, mean loss 0.09227134667937498
Step 75, mean loss 0.057178762841151254
Step 100, mean loss 0.06332046654525106
Step 125, mean loss 0.062411250491321575
Step 150, mean loss 0.08342712045698718
Step 175, mean loss 0.0921914764442146
Step 200, mean loss 0.11036632514314554
Step 225, mean loss 0.12296847376152525
Unrolled forward losses 2.6477339085710456
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08736462030353737
Step 50, mean loss 0.06871609147120908
Step 75, mean loss 0.057702479402511636
Step 100, mean loss 0.057972685198815876
Step 125, mean loss 0.07283411075811805
Step 150, mean loss 0.07602264352810399
Step 175, mean loss 0.09096701190416305
Step 200, mean loss 0.09459947340493571
Step 225, mean loss 0.1426484028037387
Unrolled forward losses 2.8769284005535676
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  6:16:15.131686 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.17235700275062352
Training Loss (progress: 0.10): 0.17784663431379893
Training Loss (progress: 0.20): 0.17121188973466017
Training Loss (progress: 0.30): 0.1606221605344375
Training Loss (progress: 0.40): 0.159135936965794
Training Loss (progress: 0.50): 0.17755822358474127
Training Loss (progress: 0.60): 0.15159473401357107
Training Loss (progress: 0.70): 0.15496112584634958
Training Loss (progress: 0.80): 0.16713425102213803
Training Loss (progress: 0.90): 0.15840279784935032
Evaluation on validation dataset:
Step 25, mean loss 0.0751949612714376
Step 50, mean loss 0.08455576920052812
Step 75, mean loss 0.055349036861203814
Step 100, mean loss 0.06429788250861646
Step 125, mean loss 0.07461599709626805
Step 150, mean loss 0.08676717642027613
Step 175, mean loss 0.10375124251860204
Step 200, mean loss 0.11077800373281044
Step 225, mean loss 0.138554843378287
Unrolled forward losses 2.451790146233866
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08777034003517595
Step 50, mean loss 0.07364497578750928
Step 75, mean loss 0.056224412758652254
Step 100, mean loss 0.06296041758167675
Step 125, mean loss 0.08086982327244269
Step 150, mean loss 0.08033709389863601
Step 175, mean loss 0.1077559231245307
Step 200, mean loss 0.11651926565879916
Step 225, mean loss 0.15609886338814416
Unrolled forward losses 2.6927212426946636
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  7:55:05.460785 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.15406477077657665
Training Loss (progress: 0.10): 0.1449964957754714
Training Loss (progress: 0.20): 0.1429802810070525
Training Loss (progress: 0.30): 0.14627650383054625
Training Loss (progress: 0.40): 0.15190866511746784
Training Loss (progress: 0.50): 0.14033736505886907
Training Loss (progress: 0.60): 0.14389934075681948
Training Loss (progress: 0.70): 0.13406821188560195
Training Loss (progress: 0.80): 0.14490084289756322
Training Loss (progress: 0.90): 0.14282717995898878
Evaluation on validation dataset:
Step 25, mean loss 0.0639535295726176
Step 50, mean loss 0.08562095577454897
Step 75, mean loss 0.04346113800440306
Step 100, mean loss 0.04622363406669429
Step 125, mean loss 0.04643013699072639
Step 150, mean loss 0.06245767756415298
Step 175, mean loss 0.07480673825045878
Step 200, mean loss 0.08321748774446679
Step 225, mean loss 0.10331307550107525
Unrolled forward losses 1.907238708387438
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06671541115031138
Step 50, mean loss 0.056086474805795414
Step 75, mean loss 0.04245600457163742
Step 100, mean loss 0.04530273786597473
Step 125, mean loss 0.051965755706228293
Step 150, mean loss 0.05548427225113052
Step 175, mean loss 0.07263527914311081
Step 200, mean loss 0.07633109602337641
Step 225, mean loss 0.12156790027627187
Unrolled forward losses 2.068900260309583
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  9:34:33.685235 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.13577935103792046
Training Loss (progress: 0.10): 0.12717477291883167
Training Loss (progress: 0.20): 0.13430447282876856
Training Loss (progress: 0.30): 0.134501383930798
Training Loss (progress: 0.40): 0.13251553202494523
Training Loss (progress: 0.50): 0.13377637937116196
Training Loss (progress: 0.60): 0.1405384529142439
Training Loss (progress: 0.70): 0.13273559681148428
Training Loss (progress: 0.80): 0.12532261122302027
Training Loss (progress: 0.90): 0.12868116317799916
Evaluation on validation dataset:
Step 25, mean loss 0.05740983283526248
Step 50, mean loss 0.07482043731509308
Step 75, mean loss 0.0370781725535068
Step 100, mean loss 0.04130998165358846
Step 125, mean loss 0.040474269128707406
Step 150, mean loss 0.057998472561574255
Step 175, mean loss 0.06611931063146818
Step 200, mean loss 0.07972784393039205
Step 225, mean loss 0.09467947239329313
Unrolled forward losses 1.7518490284185846
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.061688929714509254
Step 50, mean loss 0.050744754823404736
Step 75, mean loss 0.03956559233597717
Step 100, mean loss 0.04091322450788403
Step 125, mean loss 0.049952870316202644
Step 150, mean loss 0.05390573438031557
Step 175, mean loss 0.07248087693939832
Step 200, mean loss 0.07355724591764097
Step 225, mean loss 0.11330871374322854
Unrolled forward losses 1.984744126836607
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  11:13:52.524209 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.1320232940508907
Training Loss (progress: 0.10): 0.12692743520474029
Training Loss (progress: 0.20): 0.12875459123235566
Training Loss (progress: 0.30): 0.13346767623803982
Training Loss (progress: 0.40): 0.13437763064873795
Training Loss (progress: 0.50): 0.12698617580154598
Training Loss (progress: 0.60): 0.12782807194267498
Training Loss (progress: 0.70): 0.13008859926252536
Training Loss (progress: 0.80): 0.13167418386775911
Training Loss (progress: 0.90): 0.12844545460843762
Evaluation on validation dataset:
Step 25, mean loss 0.05435171574304348
Step 50, mean loss 0.07964029417555805
Step 75, mean loss 0.03616622243150807
Step 100, mean loss 0.039319906285027004
Step 125, mean loss 0.04075485838764667
Step 150, mean loss 0.06004673748262632
Step 175, mean loss 0.06234262379301625
Step 200, mean loss 0.07386743436208545
Step 225, mean loss 0.0920148129594161
Unrolled forward losses 1.6743383776894
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05787099950953067
Step 50, mean loss 0.05039150363125405
Step 75, mean loss 0.03828641055832184
Step 100, mean loss 0.03871480509675479
Step 125, mean loss 0.046294702772231425
Step 150, mean loss 0.05251435857554604
Step 175, mean loss 0.06928010889604458
Step 200, mean loss 0.07346331695125803
Step 225, mean loss 0.11075235997273322
Unrolled forward losses 1.93115341475866
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  12:54:02.511519 

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.13950315948753417
Training Loss (progress: 0.10): 0.12861869346000732
Training Loss (progress: 0.20): 0.13232864230934974
Training Loss (progress: 0.30): 0.12577154875619995
Training Loss (progress: 0.40): 0.13034079496484657
Training Loss (progress: 0.50): 0.1260514636581701
Training Loss (progress: 0.60): 0.12968568994398405
Training Loss (progress: 0.70): 0.12952973473097187
Training Loss (progress: 0.80): 0.13047550257988647
Training Loss (progress: 0.90): 0.11985623879932267
Evaluation on validation dataset:
Step 25, mean loss 0.05793914371966269
Step 50, mean loss 0.07107738729753818
Step 75, mean loss 0.0344633520982812
Step 100, mean loss 0.03626168685642088
Step 125, mean loss 0.03914023233552953
Step 150, mean loss 0.05719946950342741
Step 175, mean loss 0.06189390858433353
Step 200, mean loss 0.0753544581837948
Step 225, mean loss 0.09106594962519904
Unrolled forward losses 1.7169016716794463
Unrolled forward base losses 2.927822615141285
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.12680286645027936
Training Loss (progress: 0.10): 0.11821387764978962
Training Loss (progress: 0.20): 0.1289150693638874
Training Loss (progress: 0.30): 0.12302431252703654
Training Loss (progress: 0.40): 0.12587486432212577
Training Loss (progress: 0.50): 0.13150319051990683
Training Loss (progress: 0.60): 0.1246696868924108
Training Loss (progress: 0.70): 0.1282878148271323
Training Loss (progress: 0.80): 0.12881129876388195
Training Loss (progress: 0.90): 0.11438163817456794
Evaluation on validation dataset:
Step 25, mean loss 0.04807952953157635
Step 50, mean loss 0.08204838860368083
Step 75, mean loss 0.03369381850597021
Step 100, mean loss 0.03847662030406121
Step 125, mean loss 0.03969026216179944
Step 150, mean loss 0.0518347390201783
Step 175, mean loss 0.06042959364053478
Step 200, mean loss 0.07160957808066272
Step 225, mean loss 0.09167909326128298
Unrolled forward losses 1.6867849805907176
Unrolled forward base losses 2.927822615141285
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.12126925335970457
Training Loss (progress: 0.10): 0.11093368270830666
Training Loss (progress: 0.20): 0.10740656530307346
Training Loss (progress: 0.30): 0.11538261850216125
Training Loss (progress: 0.40): 0.12055876978727956
Training Loss (progress: 0.50): 0.12372840486678695
Training Loss (progress: 0.60): 0.11968842571860519
Training Loss (progress: 0.70): 0.0976114866883739
Training Loss (progress: 0.80): 0.11630537108676638
Training Loss (progress: 0.90): 0.1200236977497147
Evaluation on validation dataset:
Step 25, mean loss 0.05199892636517363
Step 50, mean loss 0.06734001500682021
Step 75, mean loss 0.03248583558161424
Step 100, mean loss 0.034388698928646884
Step 125, mean loss 0.03705699877970005
Step 150, mean loss 0.05186497827337233
Step 175, mean loss 0.05953200253047011
Step 200, mean loss 0.06707640978741292
Step 225, mean loss 0.08520360359782145
Unrolled forward losses 1.572294950080868
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.05381592726935495
Step 50, mean loss 0.0436241038423406
Step 75, mean loss 0.0360166062297845
Step 100, mean loss 0.036303757819807304
Step 125, mean loss 0.04302414878636328
Step 150, mean loss 0.047610133806959956
Step 175, mean loss 0.06397669806124637
Step 200, mean loss 0.068524270630213
Step 225, mean loss 0.1014528658982437
Unrolled forward losses 1.917491318267934
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  17:53:58.113739 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.11205876907211958
Training Loss (progress: 0.10): 0.10979540859463063
Training Loss (progress: 0.20): 0.11685794152880617
Training Loss (progress: 0.30): 0.10722908592406628
Training Loss (progress: 0.40): 0.11341988679786148
Training Loss (progress: 0.50): 0.11682701766915894
Training Loss (progress: 0.60): 0.118571649016231
Training Loss (progress: 0.70): 0.1137670247148864
Training Loss (progress: 0.80): 0.11991275164982773
Training Loss (progress: 0.90): 0.12124751688882941
Evaluation on validation dataset:
Step 25, mean loss 0.044747282879645425
Step 50, mean loss 0.059560686282619395
Step 75, mean loss 0.03051448918031359
Step 100, mean loss 0.03392078240068824
Step 125, mean loss 0.03566758628673074
Step 150, mean loss 0.051127989055833316
Step 175, mean loss 0.055718261641333956
Step 200, mean loss 0.06501973280353518
Step 225, mean loss 0.08190301301068836
Unrolled forward losses 1.473305023133348
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.049646992093718215
Step 50, mean loss 0.040172196151518305
Step 75, mean loss 0.0319949647169748
Step 100, mean loss 0.03488615951290264
Step 125, mean loss 0.041269730578039364
Step 150, mean loss 0.04651768551501747
Step 175, mean loss 0.05951948941604486
Step 200, mean loss 0.06264904706453707
Step 225, mean loss 0.10006325521277318
Unrolled forward losses 1.7705003074307746
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  19:34:33.535074 

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.11473389262189551
Training Loss (progress: 0.10): 0.10991534141040621
Training Loss (progress: 0.20): 0.11231629469855753
Training Loss (progress: 0.30): 0.1132926478029973
Training Loss (progress: 0.40): 0.10526767631820654
Training Loss (progress: 0.50): 0.1071619225191103
Training Loss (progress: 0.60): 0.1164484358774043
Training Loss (progress: 0.70): 0.10409512815034093
Training Loss (progress: 0.80): 0.10229720309454911
Training Loss (progress: 0.90): 0.12158320266456864
Evaluation on validation dataset:
Step 25, mean loss 0.04589151879503844
Step 50, mean loss 0.06095439049077987
Step 75, mean loss 0.030172827994495822
Step 100, mean loss 0.031882604800518195
Step 125, mean loss 0.03540329906125022
Step 150, mean loss 0.049909497491182286
Step 175, mean loss 0.05383707265232644
Step 200, mean loss 0.06517939834682299
Step 225, mean loss 0.08151003439875223
Unrolled forward losses 1.4648954591883427
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04691310092215921
Step 50, mean loss 0.0397957263619251
Step 75, mean loss 0.03075773328977107
Step 100, mean loss 0.033862658005853905
Step 125, mean loss 0.03943610161569092
Step 150, mean loss 0.04384869393145506
Step 175, mean loss 0.056691376147224026
Step 200, mean loss 0.06274225652580015
Step 225, mean loss 0.0946104094866932
Unrolled forward losses 1.6807130322651205
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  21:15:18.292534 

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.11678836658941691
Training Loss (progress: 0.10): 0.11223885456966458
Training Loss (progress: 0.20): 0.1105710684680148
Training Loss (progress: 0.30): 0.10364874004925972
Training Loss (progress: 0.40): 0.11548792153093135
Training Loss (progress: 0.50): 0.10155275774071482
Training Loss (progress: 0.60): 0.11273303717990513
Training Loss (progress: 0.70): 0.09850051318094859
Training Loss (progress: 0.80): 0.10826125713632598
Training Loss (progress: 0.90): 0.09658327085755074
Evaluation on validation dataset:
Step 25, mean loss 0.044289127132960904
Step 50, mean loss 0.06457165885495002
Step 75, mean loss 0.031208564635988985
Step 100, mean loss 0.03322236430494949
Step 125, mean loss 0.033496166859770735
Step 150, mean loss 0.049904161591545856
Step 175, mean loss 0.054552898504193065
Step 200, mean loss 0.0641481127408268
Step 225, mean loss 0.08192876882023997
Unrolled forward losses 1.54522893877904
Unrolled forward base losses 2.927822615141285
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.11403700473697068
Training Loss (progress: 0.10): 0.10970960490256486
Training Loss (progress: 0.20): 0.10508003886876054
Training Loss (progress: 0.30): 0.10386590889870136
Training Loss (progress: 0.40): 0.10933958350908922
Training Loss (progress: 0.50): 0.11736817490170108
Training Loss (progress: 0.60): 0.11157599342174422
Training Loss (progress: 0.70): 0.111001285926169
Training Loss (progress: 0.80): 0.11037923157341964
Training Loss (progress: 0.90): 0.10901666220710607
Evaluation on validation dataset:
Step 25, mean loss 0.043438542675464736
Step 50, mean loss 0.06567113784076234
Step 75, mean loss 0.03032028246572517
Step 100, mean loss 0.0319576820374635
Step 125, mean loss 0.03528330736155194
Step 150, mean loss 0.04873923276811999
Step 175, mean loss 0.05443452866036948
Step 200, mean loss 0.06220822781577347
Step 225, mean loss 0.08273831130648102
Unrolled forward losses 1.4812789403906028
Unrolled forward base losses 2.927822615141285
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.10236317096169004
Training Loss (progress: 0.10): 0.09933323997304408
Training Loss (progress: 0.20): 0.097822933222351
Training Loss (progress: 0.30): 0.10906943038963528
Training Loss (progress: 0.40): 0.10064568818227586
Training Loss (progress: 0.50): 0.10272619645044145
Training Loss (progress: 0.60): 0.11016623269069621
Training Loss (progress: 0.70): 0.09575820384781954
Training Loss (progress: 0.80): 0.10250462134174776
Training Loss (progress: 0.90): 0.11710755966779988
Evaluation on validation dataset:
Step 25, mean loss 0.043349815715037855
Step 50, mean loss 0.06420949664097192
Step 75, mean loss 0.028941372165617107
Step 100, mean loss 0.031872188701753935
Step 125, mean loss 0.03327344789283755
Step 150, mean loss 0.04766400817544348
Step 175, mean loss 0.052251245466258915
Step 200, mean loss 0.061589494423466035
Step 225, mean loss 0.08009897606511324
Unrolled forward losses 1.4133888763266655
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04398672742176797
Step 50, mean loss 0.03761027739796703
Step 75, mean loss 0.030017386097641714
Step 100, mean loss 0.03305613949286719
Step 125, mean loss 0.03822369925925323
Step 150, mean loss 0.04260232298737579
Step 175, mean loss 0.054344311318600416
Step 200, mean loss 0.05897799874996347
Step 225, mean loss 0.09155355616564366
Unrolled forward losses 1.624809882703682
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  1 day, 2:11:59.912056 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.0957720449799038
Training Loss (progress: 0.10): 0.08969698276302239
Training Loss (progress: 0.20): 0.10076432142015115
Training Loss (progress: 0.30): 0.09993410981275588
Training Loss (progress: 0.40): 0.10088296940191666
Training Loss (progress: 0.50): 0.10161406778859251
Training Loss (progress: 0.60): 0.09979506509163338
Training Loss (progress: 0.70): 0.10721314631083621
Training Loss (progress: 0.80): 0.10471662062730122
Training Loss (progress: 0.90): 0.10294219105150682
Evaluation on validation dataset:
Step 25, mean loss 0.043229178695945114
Step 50, mean loss 0.05951407031007641
Step 75, mean loss 0.029030173648756406
Step 100, mean loss 0.031857710035302016
Step 125, mean loss 0.033196156514927876
Step 150, mean loss 0.04847557747256596
Step 175, mean loss 0.052104776700552566
Step 200, mean loss 0.06271599087622723
Step 225, mean loss 0.08109822739012122
Unrolled forward losses 1.4389231619114284
Unrolled forward base losses 2.927822615141285
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.09382226862335523
Training Loss (progress: 0.10): 0.09979449700377864
Training Loss (progress: 0.20): 0.10246010828975484
Training Loss (progress: 0.30): 0.10310574979299475
Training Loss (progress: 0.40): 0.10507022640833023
Training Loss (progress: 0.50): 0.10114363765445875
Training Loss (progress: 0.60): 0.10908629007636561
Training Loss (progress: 0.70): 0.10638798217059259
Training Loss (progress: 0.80): 0.10538879952021891
Training Loss (progress: 0.90): 0.10220265386714891
Evaluation on validation dataset:
Step 25, mean loss 0.04256914729316144
Step 50, mean loss 0.060298549915187676
Step 75, mean loss 0.029064303528280835
Step 100, mean loss 0.030410137228508324
Step 125, mean loss 0.03314885329609539
Step 150, mean loss 0.047006311738288335
Step 175, mean loss 0.05194184315773519
Step 200, mean loss 0.06121746302137025
Step 225, mean loss 0.07808602900871606
Unrolled forward losses 1.4244735097937848
Unrolled forward base losses 2.927822615141285
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.11133458471584544
Training Loss (progress: 0.10): 0.1047431499152007
Training Loss (progress: 0.20): 0.10493235929992321
Training Loss (progress: 0.30): 0.10283576729680605
Training Loss (progress: 0.40): 0.10162200780705485
Training Loss (progress: 0.50): 0.09424621841302012
Training Loss (progress: 0.60): 0.10871405065798015
Training Loss (progress: 0.70): 0.09716968300322872
Training Loss (progress: 0.80): 0.09658285099339206
Training Loss (progress: 0.90): 0.1013308300781056
Evaluation on validation dataset:
Step 25, mean loss 0.04330147525071425
Step 50, mean loss 0.05644225066083193
Step 75, mean loss 0.028807981438691947
Step 100, mean loss 0.03010889232803502
Step 125, mean loss 0.03269054091355935
Step 150, mean loss 0.046802444333986816
Step 175, mean loss 0.05224296051577711
Step 200, mean loss 0.061804678611634106
Step 225, mean loss 0.07735576958545773
Unrolled forward losses 1.4015187973247423
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04422672525719086
Step 50, mean loss 0.03685311712589413
Step 75, mean loss 0.028681414683279664
Step 100, mean loss 0.03263624100101958
Step 125, mean loss 0.03792648073898679
Step 150, mean loss 0.042679870550410025
Step 175, mean loss 0.05468017803503151
Step 200, mean loss 0.05845095961770293
Step 225, mean loss 0.0916563182182375
Unrolled forward losses 1.7005081749498703
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  1 day, 8:47:47.045494 

Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.09715756890601103
Training Loss (progress: 0.10): 0.10752810625509412
Training Loss (progress: 0.20): 0.1054022245639849
Training Loss (progress: 0.30): 0.09925407301250769
Training Loss (progress: 0.40): 0.10487915089797457
Training Loss (progress: 0.50): 0.10512963753055514
Training Loss (progress: 0.60): 0.10204333320646661
Training Loss (progress: 0.70): 0.10061160337644821
Training Loss (progress: 0.80): 0.09883525084462261
Training Loss (progress: 0.90): 0.10441314617864282
Evaluation on validation dataset:
Step 25, mean loss 0.04046613456889299
Step 50, mean loss 0.060356798634179205
Step 75, mean loss 0.028717778881804035
Step 100, mean loss 0.03044460801706915
Step 125, mean loss 0.03310750043250049
Step 150, mean loss 0.04632959039162446
Step 175, mean loss 0.052187976590228294
Step 200, mean loss 0.06103045760314467
Step 225, mean loss 0.07834792751898423
Unrolled forward losses 1.491224202878327
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.10401988978312687
Training Loss (progress: 0.10): 0.1033242237203406
Training Loss (progress: 0.20): 0.09597074620598352
Training Loss (progress: 0.30): 0.10522927223154607
Training Loss (progress: 0.40): 0.10492787038448553
Training Loss (progress: 0.50): 0.09727329841716383
Training Loss (progress: 0.60): 0.09303985151309974
Training Loss (progress: 0.70): 0.10556637470847571
Training Loss (progress: 0.80): 0.10063410040805462
Training Loss (progress: 0.90): 0.10841177648107236
Evaluation on validation dataset:
Step 25, mean loss 0.0418783257469518
Step 50, mean loss 0.05699452466287576
Step 75, mean loss 0.02882679765852326
Step 100, mean loss 0.030688271422496107
Step 125, mean loss 0.03141020848343456
Step 150, mean loss 0.046345344033607364
Step 175, mean loss 0.04978181149592262
Step 200, mean loss 0.06024390511385666
Step 225, mean loss 0.07772561973381795
Unrolled forward losses 1.4122171598090874
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.10003494026165649
Training Loss (progress: 0.10): 0.09983694821161285
Training Loss (progress: 0.20): 0.10164164337521626
Training Loss (progress: 0.30): 0.09650785430438032
Training Loss (progress: 0.40): 0.09249356768713272
Training Loss (progress: 0.50): 0.09916317658108594
Training Loss (progress: 0.60): 0.11282343532661433
Training Loss (progress: 0.70): 0.10214333293139337
Training Loss (progress: 0.80): 0.11119645494508876
Training Loss (progress: 0.90): 0.10593174790781462
Evaluation on validation dataset:
Step 25, mean loss 0.04102102715354691
Step 50, mean loss 0.05835975405417576
Step 75, mean loss 0.02805503923205751
Step 100, mean loss 0.03005977192546655
Step 125, mean loss 0.03204226437855452
Step 150, mean loss 0.045755411725254755
Step 175, mean loss 0.0503174107002867
Step 200, mean loss 0.059462442118880035
Step 225, mean loss 0.07770602525953922
Unrolled forward losses 1.3737703350649912
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.04121991403780443
Step 50, mean loss 0.03641473329624004
Step 75, mean loss 0.028772642706070287
Step 100, mean loss 0.031507504804635905
Step 125, mean loss 0.0369769972719732
Step 150, mean loss 0.041514587091567565
Step 175, mean loss 0.052960425517580775
Step 200, mean loss 0.05759466196172762
Step 225, mean loss 0.08872556625972684
Unrolled forward losses 1.644769528319289
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n6_tw25_unrolling2_time11121720.pt
Training time:  1 day, 13:49:05.702806 

Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.0951582498180435
Training Loss (progress: 0.10): 0.09894467579508262
Training Loss (progress: 0.20): 0.10307636167887282
Training Loss (progress: 0.30): 0.10374463647453025
Training Loss (progress: 0.40): 0.10032678309466599
Training Loss (progress: 0.50): 0.10488640107948846
Training Loss (progress: 0.60): 0.10348605028627385
Training Loss (progress: 0.70): 0.10453811271099592
Training Loss (progress: 0.80): 0.10188811774988284
Training Loss (progress: 0.90): 0.09966681674602218
Evaluation on validation dataset:
Step 25, mean loss 0.04031058650583132
Step 50, mean loss 0.05493037288562484
Step 75, mean loss 0.0280894096351279
Step 100, mean loss 0.0294703142698289
Step 125, mean loss 0.031713391914138654
Step 150, mean loss 0.04595667078959808
Step 175, mean loss 0.050483052373800436
Step 200, mean loss 0.05998776771335201
Step 225, mean loss 0.07876522284689179
Unrolled forward losses 1.433180367310724
Unrolled forward base losses 2.927822615141285
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.08883670714489772
Training Loss (progress: 0.10): 0.10120768191225156
Training Loss (progress: 0.20): 0.09970963932550433
Training Loss (progress: 0.30): 0.09619623161465005
Training Loss (progress: 0.40): 0.0921406336958954
Training Loss (progress: 0.50): 0.10703927983399993
Training Loss (progress: 0.60): 0.10673578796786244
Training Loss (progress: 0.70): 0.10130175061923875
Training Loss (progress: 0.80): 0.10546108348859147
Training Loss (progress: 0.90): 0.0981052200203982
Evaluation on validation dataset:
Step 25, mean loss 0.03914110710271465
Step 50, mean loss 0.06046219029924191
Step 75, mean loss 0.02759947015517169
Step 100, mean loss 0.0291264378077934
Step 125, mean loss 0.031246955116551865
Step 150, mean loss 0.045756851632229825
Step 175, mean loss 0.05000672604496262
Step 200, mean loss 0.06016937337458042
Step 225, mean loss 0.07761707099218287
Unrolled forward losses 1.3956101897401847
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.09916698109113964
Training Loss (progress: 0.10): 0.10167543030223446
Training Loss (progress: 0.20): 0.10014676417483086
Training Loss (progress: 0.30): 0.09200310873221645
Training Loss (progress: 0.40): 0.09987667893337289
Training Loss (progress: 0.50): 0.10522614747625342
Training Loss (progress: 0.60): 0.09120982265790264
Training Loss (progress: 0.70): 0.09558022443282344
Training Loss (progress: 0.80): 0.10153659318275433
Training Loss (progress: 0.90): 0.10021225900829878
Evaluation on validation dataset:
Step 25, mean loss 0.038921027847533804
Step 50, mean loss 0.058492630805762655
Step 75, mean loss 0.02774468326837027
Step 100, mean loss 0.028913075489787714
Step 125, mean loss 0.031598580933673334
Step 150, mean loss 0.04530699386181182
Step 175, mean loss 0.04933286264696314
Step 200, mean loss 0.058698096540046256
Step 225, mean loss 0.07636794634703231
Unrolled forward losses 1.4120341353755796
Unrolled forward base losses 2.927822615141285
Test loss: 1.644769528319289
Training time (until epoch 21):  {datetime.timedelta(days=1, seconds=49745, microseconds=702806)}
