Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Number of parameters: 1031645
Training started at: 2024-11-12 19:42:48
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.3881494665587109
Training Loss (progress: 0.10): 0.5202255103471655
Training Loss (progress: 0.20): 0.38722967498378663
Training Loss (progress: 0.30): 0.2929577349714476
Training Loss (progress: 0.40): 0.24687659792496908
Training Loss (progress: 0.50): 0.2096384277234861
Training Loss (progress: 0.60): 0.1853109727126291
Training Loss (progress: 0.70): 0.16829618059178542
Training Loss (progress: 0.80): 0.15870025353992162
Training Loss (progress: 0.90): 0.1410261367493452
Evaluation on validation dataset:
Step 25, mean loss 0.18618441388049817
Step 50, mean loss 0.2649814621916087
Step 75, mean loss 0.21722528221980303
Step 100, mean loss 0.3013846310413357
Step 125, mean loss 0.285738738423722
Step 150, mean loss 0.3367799567778852
Step 175, mean loss 0.5204976525539164
Step 200, mean loss 0.6115460012742364
Step 225, mean loss 0.526076917029767
Unrolled forward losses 37.99651543515645
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.21549347016872838
Step 50, mean loss 0.29082733703662345
Step 75, mean loss 0.2979326834213052
Step 100, mean loss 0.3158303281850354
Step 125, mean loss 0.5140836463323815
Step 150, mean loss 0.3206351504092533
Step 175, mean loss 0.35282091428171425
Step 200, mean loss 0.4956888272288318
Step 225, mean loss 0.6583236071221981
Unrolled forward losses 37.60144497279953
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1:29:03.716800 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.33405045071634726
Training Loss (progress: 0.10): 0.2932083834457523
Training Loss (progress: 0.20): 0.2655992359597
Training Loss (progress: 0.30): 0.24952769383068477
Training Loss (progress: 0.40): 0.230842715471045
Training Loss (progress: 0.50): 0.2271109595565575
Training Loss (progress: 0.60): 0.21448628481199825
Training Loss (progress: 0.70): 0.20608733298191062
Training Loss (progress: 0.80): 0.2144123586560811
Training Loss (progress: 0.90): 0.20422003037072897
Evaluation on validation dataset:
Step 25, mean loss 0.1819256272809251
Step 50, mean loss 0.1990998358676133
Step 75, mean loss 0.16398331129327795
Step 100, mean loss 0.17640934674146763
Step 125, mean loss 0.19795516798602916
Step 150, mean loss 0.21644919885020664
Step 175, mean loss 0.3453942516030396
Step 200, mean loss 0.31707534064661275
Step 225, mean loss 0.3968634227333908
Unrolled forward losses 6.806906755702075
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.17927007865877692
Step 50, mean loss 0.16093638422262446
Step 75, mean loss 0.18057318810094772
Step 100, mean loss 0.21018358122157949
Step 125, mean loss 0.29999277122595935
Step 150, mean loss 0.21675859972227127
Step 175, mean loss 0.2449080684771032
Step 200, mean loss 0.3256744687364288
Step 225, mean loss 0.4052464411790784
Unrolled forward losses 7.559609690636405
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  3:06:50.943755 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.27767299069401985
Training Loss (progress: 0.10): 0.25934995885670425
Training Loss (progress: 0.20): 0.26597566336690615
Training Loss (progress: 0.30): 0.24027749886570673
Training Loss (progress: 0.40): 0.2368923710691196
Training Loss (progress: 0.50): 0.2732816592748487
Training Loss (progress: 0.60): 0.2581752340533116
Training Loss (progress: 0.70): 0.24690409344370984
Training Loss (progress: 0.80): 0.2310167659075118
Training Loss (progress: 0.90): 0.22899220291435668
Evaluation on validation dataset:
Step 25, mean loss 0.13479567557429417
Step 50, mean loss 0.17201928298063773
Step 75, mean loss 0.11390541869622184
Step 100, mean loss 0.12460625666765417
Step 125, mean loss 0.13205461291633408
Step 150, mean loss 0.15822506186703983
Step 175, mean loss 0.1962804271161007
Step 200, mean loss 0.23921763256096323
Step 225, mean loss 0.2951285211664425
Unrolled forward losses 4.223832534550538
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.12970469594525857
Step 50, mean loss 0.11939426964086497
Step 75, mean loss 0.12127321002423383
Step 100, mean loss 0.14553966766717544
Step 125, mean loss 0.22302740322047915
Step 150, mean loss 0.16274659687802992
Step 175, mean loss 0.17613014683992373
Step 200, mean loss 0.24832468342698566
Step 225, mean loss 0.3209401271280832
Unrolled forward losses 4.571680743122606
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  4:51:12.323722 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.21635765449755076
Training Loss (progress: 0.10): 0.2396594697140448
Training Loss (progress: 0.20): 0.20503608760512293
Training Loss (progress: 0.30): 0.2027605158904749
Training Loss (progress: 0.40): 0.2214091173584892
Training Loss (progress: 0.50): 0.20975264353212128
Training Loss (progress: 0.60): 0.23639438787046985
Training Loss (progress: 0.70): 0.21425750473277969
Training Loss (progress: 0.80): 0.1945032231913286
Training Loss (progress: 0.90): 0.19579700803629416
Evaluation on validation dataset:
Step 25, mean loss 0.12930514828394413
Step 50, mean loss 0.13595450677396495
Step 75, mean loss 0.09898052983142203
Step 100, mean loss 0.1073011681641989
Step 125, mean loss 0.11242793865817466
Step 150, mean loss 0.13798632987859277
Step 175, mean loss 0.1693636676446392
Step 200, mean loss 0.21417165094010399
Step 225, mean loss 0.2851253844072569
Unrolled forward losses 3.402431296423356
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.12944958325965006
Step 50, mean loss 0.09200768914653912
Step 75, mean loss 0.10454000788666751
Step 100, mean loss 0.11841750317676933
Step 125, mean loss 0.1984113822691149
Step 150, mean loss 0.1423816898987352
Step 175, mean loss 0.15782887593557782
Step 200, mean loss 0.2372120971154043
Step 225, mean loss 0.29095590860876624
Unrolled forward losses 3.8547217002336023
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  6:36:56.242117 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.20361742435661737
Training Loss (progress: 0.10): 0.18774920446161567
Training Loss (progress: 0.20): 0.20384823848455505
Training Loss (progress: 0.30): 0.2146418718688707
Training Loss (progress: 0.40): 0.20069077843939837
Training Loss (progress: 0.50): 0.20008439851740928
Training Loss (progress: 0.60): 0.19117600646451027
Training Loss (progress: 0.70): 0.17976754031793654
Training Loss (progress: 0.80): 0.19921279493105828
Training Loss (progress: 0.90): 0.18995070144106016
Evaluation on validation dataset:
Step 25, mean loss 0.10754954921078685
Step 50, mean loss 0.1473369699152134
Step 75, mean loss 0.09676583000159879
Step 100, mean loss 0.09040982881024257
Step 125, mean loss 0.10079018182868138
Step 150, mean loss 0.1271444222382062
Step 175, mean loss 0.145261603782177
Step 200, mean loss 0.18740350279319007
Step 225, mean loss 0.2515302285278484
Unrolled forward losses 3.2802537799294376
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.12029767686646305
Step 50, mean loss 0.10453637017442692
Step 75, mean loss 0.09731828533618045
Step 100, mean loss 0.11007920599045319
Step 125, mean loss 0.17109592493886042
Step 150, mean loss 0.12454538271606463
Step 175, mean loss 0.14415052616439805
Step 200, mean loss 0.21705700860207813
Step 225, mean loss 0.28121409524205976
Unrolled forward losses 4.0095546337415335
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  8:23:04.570616 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.17168903315249437
Training Loss (progress: 0.10): 0.173853429103023
Training Loss (progress: 0.20): 0.17111659856981312
Training Loss (progress: 0.30): 0.17982319097693927
Training Loss (progress: 0.40): 0.15792510313326336
Training Loss (progress: 0.50): 0.15639886755068205
Training Loss (progress: 0.60): 0.17797863782501078
Training Loss (progress: 0.70): 0.15637021485987163
Training Loss (progress: 0.80): 0.1610142917194525
Training Loss (progress: 0.90): 0.1597782533072415
Evaluation on validation dataset:
Step 25, mean loss 0.09215362223469523
Step 50, mean loss 0.13503526024714885
Step 75, mean loss 0.06807231068718828
Step 100, mean loss 0.07575615197462775
Step 125, mean loss 0.08208861090776377
Step 150, mean loss 0.11229830778418051
Step 175, mean loss 0.12584592106007259
Step 200, mean loss 0.1674524035119402
Step 225, mean loss 0.21656780382384883
Unrolled forward losses 2.629427591225255
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09736061169790389
Step 50, mean loss 0.08614604073012151
Step 75, mean loss 0.07905063773370602
Step 100, mean loss 0.09750789646475232
Step 125, mean loss 0.16191208664579299
Step 150, mean loss 0.11118331873057649
Step 175, mean loss 0.1182090807970646
Step 200, mean loss 0.18491882463783643
Step 225, mean loss 0.24317661616799502
Unrolled forward losses 2.9572522253449662
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  10:10:08.639548 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.16490644621518055
Training Loss (progress: 0.10): 0.14941059018703645
Training Loss (progress: 0.20): 0.15941463706238557
Training Loss (progress: 0.30): 0.16518683061121664
Training Loss (progress: 0.40): 0.1546514730257364
Training Loss (progress: 0.50): 0.14952497754403588
Training Loss (progress: 0.60): 0.14781821946100912
Training Loss (progress: 0.70): 0.15308836089064004
Training Loss (progress: 0.80): 0.1594640736118835
Training Loss (progress: 0.90): 0.16474340644124674
Evaluation on validation dataset:
Step 25, mean loss 0.0988895749073417
Step 50, mean loss 0.11208615840859969
Step 75, mean loss 0.06801176348622812
Step 100, mean loss 0.07756365851085117
Step 125, mean loss 0.07938686300777738
Step 150, mean loss 0.11571957624679839
Step 175, mean loss 0.1311459546571046
Step 200, mean loss 0.16294018164560053
Step 225, mean loss 0.20079958915306537
Unrolled forward losses 2.767413767174454
Unrolled forward base losses 2.927822615141285
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.14524692581181622
Training Loss (progress: 0.10): 0.15135379582913255
Training Loss (progress: 0.20): 0.15578015266339784
Training Loss (progress: 0.30): 0.13824340186610506
Training Loss (progress: 0.40): 0.1587379131529385
Training Loss (progress: 0.50): 0.1586334269097141
Training Loss (progress: 0.60): 0.15414597030388932
Training Loss (progress: 0.70): 0.15463563170777936
Training Loss (progress: 0.80): 0.15864806843524248
Training Loss (progress: 0.90): 0.15306422328502145
Evaluation on validation dataset:
Step 25, mean loss 0.07986910017876526
Step 50, mean loss 0.11147324040548307
Step 75, mean loss 0.06693685078981454
Step 100, mean loss 0.07363217901457308
Step 125, mean loss 0.08111563796540316
Step 150, mean loss 0.11018674982376996
Step 175, mean loss 0.1276270951146552
Step 200, mean loss 0.15620120137638863
Step 225, mean loss 0.2031253450187142
Unrolled forward losses 2.633960440605345
Unrolled forward base losses 2.927822615141285
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.15119506454690873
Training Loss (progress: 0.10): 0.14979902859783495
Training Loss (progress: 0.20): 0.15497436976972875
Training Loss (progress: 0.30): 0.1520370860181872
Training Loss (progress: 0.40): 0.1447640459425957
Training Loss (progress: 0.50): 0.16234197514706927
Training Loss (progress: 0.60): 0.1478183672406189
Training Loss (progress: 0.70): 0.14570212256123818
Training Loss (progress: 0.80): 0.15205735814893725
Training Loss (progress: 0.90): 0.14078012062288583
Evaluation on validation dataset:
Step 25, mean loss 0.07465833322812557
Step 50, mean loss 0.11789793301813296
Step 75, mean loss 0.05830807577876339
Step 100, mean loss 0.06665582429068975
Step 125, mean loss 0.07383198856139866
Step 150, mean loss 0.10578446880799716
Step 175, mean loss 0.11839462229794592
Step 200, mean loss 0.14452392144867449
Step 225, mean loss 0.20376596420156667
Unrolled forward losses 2.416497655611542
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08137722396090712
Step 50, mean loss 0.07309244147561714
Step 75, mean loss 0.07430741176338879
Step 100, mean loss 0.08220682601364074
Step 125, mean loss 0.13800270916066476
Step 150, mean loss 0.09792519155595626
Step 175, mean loss 0.10904921321775704
Step 200, mean loss 0.1654388289683134
Step 225, mean loss 0.21407561055882435
Unrolled forward losses 2.6929468283135325
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  15:31:01.836049 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.14226104206563148
Training Loss (progress: 0.10): 0.141963041445548
Training Loss (progress: 0.20): 0.14246424135363028
Training Loss (progress: 0.30): 0.14021053526527705
Training Loss (progress: 0.40): 0.13676672296234485
Training Loss (progress: 0.50): 0.15062614397501203
Training Loss (progress: 0.60): 0.12648534969783684
Training Loss (progress: 0.70): 0.15209592872299746
Training Loss (progress: 0.80): 0.1264141469411425
Training Loss (progress: 0.90): 0.14297347853169365
Evaluation on validation dataset:
Step 25, mean loss 0.0735471581940924
Step 50, mean loss 0.11605492532130875
Step 75, mean loss 0.0573672496758333
Step 100, mean loss 0.06457141091226057
Step 125, mean loss 0.07017537918864197
Step 150, mean loss 0.10085180275900975
Step 175, mean loss 0.11764016482808407
Step 200, mean loss 0.14246386364738706
Step 225, mean loss 0.18391006775577984
Unrolled forward losses 2.3519251226448805
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0777101186326983
Step 50, mean loss 0.06593150419927868
Step 75, mean loss 0.07056003409096745
Step 100, mean loss 0.07855407796752088
Step 125, mean loss 0.13772834466712952
Step 150, mean loss 0.09206011503316583
Step 175, mean loss 0.10608097845450278
Step 200, mean loss 0.15361250409468413
Step 225, mean loss 0.20667152318315524
Unrolled forward losses 2.706243711389881
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  17:18:44.501816 

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.13013739247627018
Training Loss (progress: 0.10): 0.1374043373480581
Training Loss (progress: 0.20): 0.13231531342955555
Training Loss (progress: 0.30): 0.1203085681537807
Training Loss (progress: 0.40): 0.1346332132518383
Training Loss (progress: 0.50): 0.13134021617478236
Training Loss (progress: 0.60): 0.13972579906555893
Training Loss (progress: 0.70): 0.1357278145912176
Training Loss (progress: 0.80): 0.11865202068764276
Training Loss (progress: 0.90): 0.12270355883486411
Evaluation on validation dataset:
Step 25, mean loss 0.06789699304273145
Step 50, mean loss 0.10303417630816852
Step 75, mean loss 0.0564169184000471
Step 100, mean loss 0.06396362041795574
Step 125, mean loss 0.06792443420348038
Step 150, mean loss 0.10126740995487837
Step 175, mean loss 0.11515562860804493
Step 200, mean loss 0.13933968695605614
Step 225, mean loss 0.17510924962078517
Unrolled forward losses 2.253296617325838
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07765079014969012
Step 50, mean loss 0.05578453821771119
Step 75, mean loss 0.06535838813545236
Step 100, mean loss 0.07710330093000481
Step 125, mean loss 0.13126754586606243
Step 150, mean loss 0.08700701375354128
Step 175, mean loss 0.09974260364150855
Step 200, mean loss 0.15522756119458406
Step 225, mean loss 0.2049273157872885
Unrolled forward losses 2.5811834039189194
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  19:06:32.940276 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.13007762007999396
Training Loss (progress: 0.10): 0.1321645265487254
Training Loss (progress: 0.20): 0.1254686474050904
Training Loss (progress: 0.30): 0.1281123636883835
Training Loss (progress: 0.40): 0.12764657843741883
Training Loss (progress: 0.50): 0.12499848102206529
Training Loss (progress: 0.60): 0.12558412360829027
Training Loss (progress: 0.70): 0.12073465945245822
Training Loss (progress: 0.80): 0.12902395436544142
Training Loss (progress: 0.90): 0.12612257419762019
Evaluation on validation dataset:
Step 25, mean loss 0.06857668106664519
Step 50, mean loss 0.10773539777911928
Step 75, mean loss 0.05534109954280041
Step 100, mean loss 0.060845513795607584
Step 125, mean loss 0.06725944345419646
Step 150, mean loss 0.0993054483227898
Step 175, mean loss 0.11516036917295894
Step 200, mean loss 0.1378557233930916
Step 225, mean loss 0.17837736253779357
Unrolled forward losses 2.077476564922791
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07430348430554498
Step 50, mean loss 0.05955826121493212
Step 75, mean loss 0.06410984875272946
Step 100, mean loss 0.07535865833978439
Step 125, mean loss 0.1343787295109339
Step 150, mean loss 0.08690901680714679
Step 175, mean loss 0.09793330510406342
Step 200, mean loss 0.1502095580387079
Step 225, mean loss 0.21090535781642378
Unrolled forward losses 2.523187307784898
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  20:53:44.050341 

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.12632295588931647
Training Loss (progress: 0.10): 0.1327821357954669
Training Loss (progress: 0.20): 0.12934628570441892
Training Loss (progress: 0.30): 0.13060471255161174
Training Loss (progress: 0.40): 0.12924941219347666
Training Loss (progress: 0.50): 0.1306098606214785
Training Loss (progress: 0.60): 0.13298263131037621
Training Loss (progress: 0.70): 0.12551834017022373
Training Loss (progress: 0.80): 0.11853188977105986
Training Loss (progress: 0.90): 0.13050425556140915
Evaluation on validation dataset:
Step 25, mean loss 0.06503080320624911
Step 50, mean loss 0.1024181678252459
Step 75, mean loss 0.055581435150383975
Step 100, mean loss 0.061276108833309015
Step 125, mean loss 0.06653625115338707
Step 150, mean loss 0.09947070351579135
Step 175, mean loss 0.11353664589567505
Step 200, mean loss 0.13410204352680766
Step 225, mean loss 0.16715489902445865
Unrolled forward losses 2.1151722613660047
Unrolled forward base losses 2.927822615141285
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.12747055378421418
Training Loss (progress: 0.10): 0.1179679108980905
Training Loss (progress: 0.20): 0.11737165196032284
Training Loss (progress: 0.30): 0.11863789114218558
Training Loss (progress: 0.40): 0.12788927878753936
Training Loss (progress: 0.50): 0.11869067610056033
Training Loss (progress: 0.60): 0.12273779094327321
Training Loss (progress: 0.70): 0.12340791020797412
Training Loss (progress: 0.80): 0.11947288199633291
Training Loss (progress: 0.90): 0.12459474134662282
Evaluation on validation dataset:
Step 25, mean loss 0.06826768741459432
Step 50, mean loss 0.09924345561654921
Step 75, mean loss 0.05365572909078854
Step 100, mean loss 0.05978857171634832
Step 125, mean loss 0.06807380798321833
Step 150, mean loss 0.09932751842022064
Step 175, mean loss 0.1142627814554085
Step 200, mean loss 0.13404916811182918
Step 225, mean loss 0.1720342423799946
Unrolled forward losses 2.0741344200748157
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07564299544951696
Step 50, mean loss 0.05451953055087773
Step 75, mean loss 0.060210919128853485
Step 100, mean loss 0.07415417440059217
Step 125, mean loss 0.1293124878358763
Step 150, mean loss 0.08346330293498563
Step 175, mean loss 0.09922158091418315
Step 200, mean loss 0.14914357728477454
Step 225, mean loss 0.20450448188642367
Unrolled forward losses 2.470134863722426
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 0:25:01.586041 

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.12348519470911021
Training Loss (progress: 0.10): 0.12441200918312575
Training Loss (progress: 0.20): 0.12275595753137356
Training Loss (progress: 0.30): 0.12282655462970257
Training Loss (progress: 0.40): 0.1231892487722067
Training Loss (progress: 0.50): 0.12987323827755354
Training Loss (progress: 0.60): 0.12404922719301996
Training Loss (progress: 0.70): 0.13659180154409262
Training Loss (progress: 0.80): 0.13295716448072278
Training Loss (progress: 0.90): 0.12582643031119653
Evaluation on validation dataset:
Step 25, mean loss 0.06465601185910239
Step 50, mean loss 0.09826037907473875
Step 75, mean loss 0.054762071719097055
Step 100, mean loss 0.06128824562453664
Step 125, mean loss 0.06751491333816975
Step 150, mean loss 0.09970528551675478
Step 175, mean loss 0.11497381411817573
Step 200, mean loss 0.1327279228857301
Step 225, mean loss 0.17185862419718834
Unrolled forward losses 2.0733264299040393
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07155001631419733
Step 50, mean loss 0.05448292586792044
Step 75, mean loss 0.0620679316213744
Step 100, mean loss 0.07430842975776325
Step 125, mean loss 0.13181535774444642
Step 150, mean loss 0.08636917473617156
Step 175, mean loss 0.09850087507371341
Step 200, mean loss 0.14507775260824268
Step 225, mean loss 0.2072500038358624
Unrolled forward losses 2.520341600554932
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 2:11:48.983871 

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.11715590186290752
Training Loss (progress: 0.10): 0.11653552994650966
Training Loss (progress: 0.20): 0.11549147529369706
Training Loss (progress: 0.30): 0.1199844641176453
Training Loss (progress: 0.40): 0.12333776255620914
Training Loss (progress: 0.50): 0.12030730154506808
Training Loss (progress: 0.60): 0.11210874651259908
Training Loss (progress: 0.70): 0.1131533849122562
Training Loss (progress: 0.80): 0.1154789905067949
Training Loss (progress: 0.90): 0.10913616208652781
Evaluation on validation dataset:
Step 25, mean loss 0.06589147054673883
Step 50, mean loss 0.1021712953453785
Step 75, mean loss 0.052581654442892936
Step 100, mean loss 0.058694703726042866
Step 125, mean loss 0.0651153278158419
Step 150, mean loss 0.09711036288052508
Step 175, mean loss 0.11307181730721494
Step 200, mean loss 0.13208059180668674
Step 225, mean loss 0.16685276332940197
Unrolled forward losses 2.0666178292043824
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0726860767439953
Step 50, mean loss 0.052023065849758306
Step 75, mean loss 0.0593382051199127
Step 100, mean loss 0.07030075247809583
Step 125, mean loss 0.1277460467390878
Step 150, mean loss 0.0833138362680318
Step 175, mean loss 0.09631328932098701
Step 200, mean loss 0.14500584304082542
Step 225, mean loss 0.20349635864544172
Unrolled forward losses 2.4835474150794568
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 5:35:04.427703 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.11532264799286883
Training Loss (progress: 0.10): 0.11726073432435472
Training Loss (progress: 0.20): 0.1172023960596304
Training Loss (progress: 0.30): 0.11433873337770785
Training Loss (progress: 0.40): 0.10634577093721521
Training Loss (progress: 0.50): 0.11195885994110051
Training Loss (progress: 0.60): 0.10800977961629625
Training Loss (progress: 0.70): 0.12518872408771767
Training Loss (progress: 0.80): 0.11093554833862289
Training Loss (progress: 0.90): 0.11416692248521987
Evaluation on validation dataset:
Step 25, mean loss 0.06417982321069798
Step 50, mean loss 0.09517573037811733
Step 75, mean loss 0.05395279242484915
Step 100, mean loss 0.05755264577759878
Step 125, mean loss 0.06609827891659373
Step 150, mean loss 0.09798366652310132
Step 175, mean loss 0.11230625864415311
Step 200, mean loss 0.12836551028096324
Step 225, mean loss 0.16886987346419968
Unrolled forward losses 2.049188058586251
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07042705738831678
Step 50, mean loss 0.053399050748261956
Step 75, mean loss 0.05905980140549142
Step 100, mean loss 0.07344467654778229
Step 125, mean loss 0.13126696084127018
Step 150, mean loss 0.08163939997450759
Step 175, mean loss 0.09628816451365106
Step 200, mean loss 0.1431981498343605
Step 225, mean loss 0.20896100611534926
Unrolled forward losses 2.4468140922021986
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 7:22:21.654509 

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.1208819884013501
Training Loss (progress: 0.10): 0.12076893282006423
Training Loss (progress: 0.20): 0.12336726516473204
Training Loss (progress: 0.30): 0.11521239080413824
Training Loss (progress: 0.40): 0.11163880158122706
Training Loss (progress: 0.50): 0.1197087327336794
Training Loss (progress: 0.60): 0.11966529206415502
Training Loss (progress: 0.70): 0.12068392313923158
Training Loss (progress: 0.80): 0.1220190700717414
Training Loss (progress: 0.90): 0.1094440351042174
Evaluation on validation dataset:
Step 25, mean loss 0.0639404226320919
Step 50, mean loss 0.09800107467430766
Step 75, mean loss 0.05177685434888342
Step 100, mean loss 0.05729705695911767
Step 125, mean loss 0.06553489354061912
Step 150, mean loss 0.09602782855679096
Step 175, mean loss 0.11217904932118661
Step 200, mean loss 0.12972113855337541
Step 225, mean loss 0.16549869282798907
Unrolled forward losses 2.0662473203915113
Unrolled forward base losses 2.927822615141285
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.10928607624357438
Training Loss (progress: 0.10): 0.11924335322023842
Training Loss (progress: 0.20): 0.12014899987892927
Training Loss (progress: 0.30): 0.12386930421589017
Training Loss (progress: 0.40): 0.11734091474158354
Training Loss (progress: 0.50): 0.11390571347372722
Training Loss (progress: 0.60): 0.1191041275720355
Training Loss (progress: 0.70): 0.11629532482031564
Training Loss (progress: 0.80): 0.1170506666763409
Training Loss (progress: 0.90): 0.11690713523248852
Evaluation on validation dataset:
Step 25, mean loss 0.0658640388645006
Step 50, mean loss 0.09606672319141529
Step 75, mean loss 0.051783076624629484
Step 100, mean loss 0.0566119232949399
Step 125, mean loss 0.06698357636810784
Step 150, mean loss 0.09768490978189184
Step 175, mean loss 0.1101755328766996
Step 200, mean loss 0.12964667274191397
Step 225, mean loss 0.16410203703183096
Unrolled forward losses 2.056186198463695
Unrolled forward base losses 2.927822615141285
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.1325160713498877
Training Loss (progress: 0.10): 0.12035821780046523
Training Loss (progress: 0.20): 0.11502178093548242
Training Loss (progress: 0.30): 0.11194632944074996
Training Loss (progress: 0.40): 0.11753834911953341
Training Loss (progress: 0.50): 0.11485627704237984
Training Loss (progress: 0.60): 0.13025194839289497
Training Loss (progress: 0.70): 0.12075953791312756
Training Loss (progress: 0.80): 0.1165538864349747
Training Loss (progress: 0.90): 0.11448516928484787
Evaluation on validation dataset:
Step 25, mean loss 0.06347994859608784
Step 50, mean loss 0.09915577826366298
Step 75, mean loss 0.05175702235825786
Step 100, mean loss 0.057348045908663624
Step 125, mean loss 0.06399256997179893
Step 150, mean loss 0.09591091906925185
Step 175, mean loss 0.11177000705475276
Step 200, mean loss 0.1293801040886712
Step 225, mean loss 0.16131025707423682
Unrolled forward losses 2.078279825389241
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.11201260038934974
Training Loss (progress: 0.10): 0.12181818771740484
Training Loss (progress: 0.20): 0.12177397666749654
Training Loss (progress: 0.30): 0.11998548468752321
Training Loss (progress: 0.40): 0.1241488403982041
Training Loss (progress: 0.50): 0.1172956202856901
Training Loss (progress: 0.60): 0.11416902310603286
Training Loss (progress: 0.70): 0.11391957742222289
Training Loss (progress: 0.80): 0.11586070516541014
Training Loss (progress: 0.90): 0.10890851110749593
Evaluation on validation dataset:
Step 25, mean loss 0.06135797360094118
Step 50, mean loss 0.10067252332646973
Step 75, mean loss 0.052299122516442746
Step 100, mean loss 0.05692746842730092
Step 125, mean loss 0.06434331963632806
Step 150, mean loss 0.09661217260460181
Step 175, mean loss 0.10887312884729287
Step 200, mean loss 0.12742019606028696
Step 225, mean loss 0.1612394004868237
Unrolled forward losses 2.0257122876613063
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0669454532238773
Step 50, mean loss 0.049065773486344486
Step 75, mean loss 0.057922028328090826
Step 100, mean loss 0.06990252740650868
Step 125, mean loss 0.12723170463011174
Step 150, mean loss 0.0798136950161831
Step 175, mean loss 0.09481616455029572
Step 200, mean loss 0.14115922058457997
Step 225, mean loss 0.20460931852649658
Unrolled forward losses 2.3668708128266625
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 14:34:01.469779 

Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.11305840780146043
Training Loss (progress: 0.10): 0.11626305010938852
Training Loss (progress: 0.20): 0.11191314441493767
Training Loss (progress: 0.30): 0.1056560628135599
Training Loss (progress: 0.40): 0.12853442028846734
Training Loss (progress: 0.50): 0.11203595426034338
Training Loss (progress: 0.60): 0.12146870761988648
Training Loss (progress: 0.70): 0.10973231443003947
Training Loss (progress: 0.80): 0.11351063965792052
Training Loss (progress: 0.90): 0.11777803147982636
Evaluation on validation dataset:
Step 25, mean loss 0.061450983608912775
Step 50, mean loss 0.09682268867023815
Step 75, mean loss 0.05017330142371603
Step 100, mean loss 0.05597348836247517
Step 125, mean loss 0.06458069778995656
Step 150, mean loss 0.09611680128777171
Step 175, mean loss 0.11080092498210234
Step 200, mean loss 0.12724098362950825
Step 225, mean loss 0.16096264238479024
Unrolled forward losses 1.995663565847114
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06623256181044315
Step 50, mean loss 0.04981712815314969
Step 75, mean loss 0.05806554995900748
Step 100, mean loss 0.06976312242183333
Step 125, mean loss 0.12612493152542742
Step 150, mean loss 0.08063818959334709
Step 175, mean loss 0.09440156239651722
Step 200, mean loss 0.14246702027874014
Step 225, mean loss 0.20099156675349505
Unrolled forward losses 2.35349428040547
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 16:22:05.620119 

Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.10520210472924732
Training Loss (progress: 0.10): 0.10939469277483596
Training Loss (progress: 0.20): 0.10876228827114247
Training Loss (progress: 0.30): 0.1163821196039834
Training Loss (progress: 0.40): 0.11693326485888722
Training Loss (progress: 0.50): 0.11632285026902275
Training Loss (progress: 0.60): 0.11662082230757087
Training Loss (progress: 0.70): 0.11003358874491413
Training Loss (progress: 0.80): 0.11526731376768934
Training Loss (progress: 0.90): 0.11313237375513537
Evaluation on validation dataset:
Step 25, mean loss 0.0608760703911135
Step 50, mean loss 0.09719308061001403
Step 75, mean loss 0.05076827841032974
Step 100, mean loss 0.05536234623552623
Step 125, mean loss 0.0646634030434976
Step 150, mean loss 0.09629737369915804
Step 175, mean loss 0.10937508386830705
Step 200, mean loss 0.12508452754704208
Step 225, mean loss 0.16131619139697256
Unrolled forward losses 2.0291502145821907
Unrolled forward base losses 2.927822615141285
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.12035305325514824
Training Loss (progress: 0.10): 0.12094379402628647
Training Loss (progress: 0.20): 0.11553387752306259
Training Loss (progress: 0.30): 0.10888170531844449
Training Loss (progress: 0.40): 0.1166848608354922
Training Loss (progress: 0.50): 0.12510084420524947
Training Loss (progress: 0.60): 0.11126511040404208
Training Loss (progress: 0.70): 0.11600393151798563
Training Loss (progress: 0.80): 0.10746322699149456
Training Loss (progress: 0.90): 0.11561643640784494
Evaluation on validation dataset:
Step 25, mean loss 0.05996415483669189
Step 50, mean loss 0.09224968879156825
Step 75, mean loss 0.050851211677544327
Step 100, mean loss 0.056622832960733546
Step 125, mean loss 0.06372000994249026
Step 150, mean loss 0.09569366251398148
Step 175, mean loss 0.10832915085693305
Step 200, mean loss 0.12671058722971368
Step 225, mean loss 0.15783823716839376
Unrolled forward losses 2.0497679779462423
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.11502164979291588
Training Loss (progress: 0.10): 0.11811529466391776
Training Loss (progress: 0.20): 0.10987675005309194
Training Loss (progress: 0.30): 0.11263269039900027
Training Loss (progress: 0.40): 0.11378924733029247
Training Loss (progress: 0.50): 0.10592443265473057
Training Loss (progress: 0.60): 0.1193151688518018
Training Loss (progress: 0.70): 0.11446011567214709
Training Loss (progress: 0.80): 0.10913283884583218
Training Loss (progress: 0.90): 0.1102683698337688
Evaluation on validation dataset:
Step 25, mean loss 0.06125010268377454
Step 50, mean loss 0.09771753689177287
Step 75, mean loss 0.050150641932479374
Step 100, mean loss 0.054919891305192606
Step 125, mean loss 0.0642195786386478
Step 150, mean loss 0.0956835869797524
Step 175, mean loss 0.10740724804813323
Step 200, mean loss 0.12313293957000872
Step 225, mean loss 0.15867610668492044
Unrolled forward losses 1.9889308602235767
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06412343399812742
Step 50, mean loss 0.048094068939888726
Step 75, mean loss 0.056069228582137275
Step 100, mean loss 0.06791535733846457
Step 125, mean loss 0.12164365777741747
Step 150, mean loss 0.07896130174466721
Step 175, mean loss 0.09487032738754662
Step 200, mean loss 0.1421160446206566
Step 225, mean loss 0.20532253798289968
Unrolled forward losses 2.3207588041979017
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n24_tw25_unrolling2_time11121942.pt
Training time:  1 day, 21:47:50.915821 

Test loss: 2.3207588041979017
Training time (until epoch 24):  {datetime.timedelta(days=1, seconds=78470, microseconds=915821)}
