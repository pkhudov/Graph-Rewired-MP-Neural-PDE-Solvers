Training on dataset data/fs_2d_pde_64_train_dataset.h5
cuda:0
models/GNN_FS_FS_resolution64_n16_tw5_unrolling2_time12111741.pt
Number of parameters: 619769
Training started at: 2024-12-11 17:41:58
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 6.645312853757955; Norm Grads: 26.052361332730495
Training Loss (progress: 0.10): 5.05071367245507; Norm Grads: 43.001425496892764
Training Loss (progress: 0.20): 4.796853529434889; Norm Grads: 48.0475819988825
Training Loss (progress: 0.30): 4.664313401231204; Norm Grads: 50.774621786601855
Training Loss (progress: 0.40): 4.456093199798799; Norm Grads: 58.7233958962472
Training Loss (progress: 0.50): 4.313840333928439; Norm Grads: 59.4733869725178
Training Loss (progress: 0.60): 4.206081620921743; Norm Grads: 57.98751939152653
Training Loss (progress: 0.70): 4.161714975342964; Norm Grads: 58.61896707235725
Training Loss (progress: 0.80): 4.080084066698392; Norm Grads: 53.870695003648606
Training Loss (progress: 0.90): 4.010368814969166; Norm Grads: 56.58526988242909
Evaluation on validation dataset:
Step 5, mean loss 22.020787155455526
Step 10, mean loss 44.07847590040963
Step 15, mean loss 78.4719744146011
Step 20, mean loss 77.99690590147941
Step 25, mean loss 73.40587623468075
Step 30, mean loss 75.53690500690035
Step 35, mean loss 72.69690868292092
Step 40, mean loss 69.27407450279254
Step 45, mean loss 69.24844336750256
Step 50, mean loss 68.91710462617093
Step 55, mean loss 61.343265535873996
Step 60, mean loss 62.14933704902181
Step 65, mean loss 59.36941655264958
Step 70, mean loss 61.3308974678331
Step 75, mean loss 65.97622354990703
Step 80, mean loss 71.6557159225448
Step 85, mean loss 75.42206404445875
Step 90, mean loss 77.90070158889961
Step 95, mean loss 79.43773233648062
Unrolled forward losses 0.6887261859439004
Evaluation on test dataset:
Step 5, mean loss 22.217217085517895
Step 10, mean loss 48.97457564851818
Step 15, mean loss 72.41390476659365
Step 20, mean loss 87.64870755590277
Step 25, mean loss 78.69224542866971
Step 30, mean loss 75.19746302375411
Step 35, mean loss 70.9503702981242
Step 40, mean loss 70.48786925339635
Step 45, mean loss 70.83686829667238
Step 50, mean loss 71.32073242058183
Step 55, mean loss 63.05672807060146
Step 60, mean loss 62.57906249213862
Step 65, mean loss 62.298350985742495
Step 70, mean loss 66.04625677406943
Step 75, mean loss 67.71632247129122
Step 80, mean loss 71.92038953656946
Step 85, mean loss 76.27328373940027
Step 90, mean loss 78.9158537350562
Step 95, mean loss 79.9001280129473
Unrolled forward losses 0.7652277445080966
Saved model at models/GNN_FS_FS_resolution64_n16_tw5_unrolling2_time12111741.pt

Training time:  6:52:15.714609
Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 5.6415810578439505; Norm Grads: 40.4170948072533
Training Loss (progress: 0.10): 5.622669130148304; Norm Grads: 36.74801206498986
Training Loss (progress: 0.20): 5.626724195788373; Norm Grads: 37.5120404792174
Training Loss (progress: 0.30): 5.546743046907977; Norm Grads: 36.326652852081395
Training Loss (progress: 0.40): 5.561470382264767; Norm Grads: 36.36487931269518
Training Loss (progress: 0.50): 5.513932062210538; Norm Grads: 35.62642731219961
Training Loss (progress: 0.60): 5.496274245033918; Norm Grads: 33.46278531098223
Training Loss (progress: 0.70): 5.392716924940129; Norm Grads: 34.06996915774758
Training Loss (progress: 0.80): 5.447231436171046; Norm Grads: 34.3530877618778
Training Loss (progress: 0.90): 5.274825837600453; Norm Grads: 35.553625996710615
Evaluation on validation dataset:
Step 5, mean loss 16.693840017935933
Step 10, mean loss 36.89291878834516
Step 15, mean loss 67.12486937250674
Step 20, mean loss 62.04959823208752
Step 25, mean loss 62.55754444336161
Step 30, mean loss 65.238402059198
Step 35, mean loss 64.21232558827528
Step 40, mean loss 61.63690851592683
Step 45, mean loss 61.858545166118034
Step 50, mean loss 60.81666086703172
Step 55, mean loss 53.430271092319266
Step 60, mean loss 54.39376553018097
Step 65, mean loss 52.63200435267265
Step 70, mean loss 55.97628194193387
Step 75, mean loss 60.85449920503711
Step 80, mean loss 65.5402390766142
Step 85, mean loss 69.95360696485899
Step 90, mean loss 72.07628133222602
Step 95, mean loss 73.89887555127308
Unrolled forward losses 0.5764518560678932
Evaluation on test dataset:
Step 5, mean loss 17.43087947561233
Step 10, mean loss 40.87569795946453
Step 15, mean loss 60.28785719319369
Step 20, mean loss 73.50536360772986
Step 25, mean loss 66.33599241399756
Step 30, mean loss 64.83523024929322
Step 35, mean loss 62.73034150798918
Step 40, mean loss 63.28789818789184
Step 45, mean loss 64.65808295899058
Step 50, mean loss 63.85422175239947
Step 55, mean loss 55.8769060340811
Step 60, mean loss 54.35710772733756
Step 65, mean loss 56.121258500237744
Step 70, mean loss 60.44378092183905
Step 75, mean loss 61.84942184092817
Step 80, mean loss 66.3279525398309
Step 85, mean loss 70.0443993402185
Step 90, mean loss 72.8158198426204
Step 95, mean loss 75.40893695123023
Unrolled forward losses 0.6386827806166333
Saved model at models/GNN_FS_FS_resolution64_n16_tw5_unrolling2_time12111741.pt

Training time:  14:08:51.061491
Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 6.306448783468674; Norm Grads: 30.60087831508661
Training Loss (progress: 0.10): 6.197708433528861; Norm Grads: 31.706244057985657
Training Loss (progress: 0.20): 6.143176971678408; Norm Grads: 34.90688511383502
Training Loss (progress: 0.30): 6.055503836587251; Norm Grads: 35.63651963864407
Training Loss (progress: 0.40): 6.048866840046342; Norm Grads: 35.23339927690267
Training Loss (progress: 0.50): 6.025003884876127; Norm Grads: 37.321118629773785
Training Loss (progress: 0.60): 6.076420945988594; Norm Grads: 37.49377619032271
Training Loss (progress: 0.70): 6.068968956259215; Norm Grads: 40.857174607641795
Training Loss (progress: 0.80): 6.030437681710219; Norm Grads: 39.31165020837915
Training Loss (progress: 0.90): 6.240890159794683; Norm Grads: 38.056339305337346
Evaluation on validation dataset:
Step 5, mean loss 15.121999425226175
Step 10, mean loss 34.06487559173626
Step 15, mean loss 61.26804982723913
Step 20, mean loss 58.715511336981415
Step 25, mean loss 58.86092333258972
Step 30, mean loss 60.479533909594196
Step 35, mean loss 59.121433816409194
Step 40, mean loss 56.24393178161068
Step 45, mean loss 57.92539105208621
Step 50, mean loss 59.23842826724946
Step 55, mean loss 52.18933465680869
Step 60, mean loss 53.48330719428547
Step 65, mean loss 51.17086663402395
Step 70, mean loss 54.57936627312263
Step 75, mean loss 59.124303028801094
Step 80, mean loss 64.10989214391867
Step 85, mean loss 68.84314809412105
Step 90, mean loss 71.19193261827259
Step 95, mean loss 73.55137421747912
Unrolled forward losses 0.5322636811208792
Evaluation on test dataset:
Step 5, mean loss 15.187992115978705
Step 10, mean loss 38.319432199016376
Step 15, mean loss 55.10703552982892
Step 20, mean loss 69.04023929798423
Step 25, mean loss 63.16585958834595
Step 30, mean loss 61.4513307803836
Step 35, mean loss 58.56404314010089
Step 40, mean loss 57.88316269404825
Step 45, mean loss 58.26669731530001
Step 50, mean loss 60.648424869269775
Step 55, mean loss 53.99371081434532
Step 60, mean loss 54.13622062902614
Step 65, mean loss 54.57208039479404
Step 70, mean loss 58.600075971383404
Step 75, mean loss 60.53745914111913
Step 80, mean loss 64.90799137152942
Step 85, mean loss 68.78447664446608
Step 90, mean loss 72.18040539714559
Step 95, mean loss 74.74449119002972
Unrolled forward losses 0.5987411281096309
Saved model at models/GNN_FS_FS_resolution64_n16_tw5_unrolling2_time12111741.pt

Training time:  21:53:59.035606
Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 6.137593120753956; Norm Grads: 40.92941208076674
Training Loss (progress: 0.10): 6.115921648968854; Norm Grads: 39.88918076335285
Training Loss (progress: 0.20): 5.962956617720073; Norm Grads: 44.29176370668982
Training Loss (progress: 0.30): 6.0792295025484995; Norm Grads: 42.573289991327655
Training Loss (progress: 0.40): 6.117423754762969; Norm Grads: 42.652283625667756
Training Loss (progress: 0.50): 6.031990681261123; Norm Grads: 44.97099874860942
Training Loss (progress: 0.60): 5.970713835442545; Norm Grads: 45.40638744286714
Training Loss (progress: 0.70): 5.9723443823952245; Norm Grads: 46.05895876443146
Training Loss (progress: 0.80): 5.938972506534673; Norm Grads: 45.11455383152296
Training Loss (progress: 0.90): 5.856517083813449; Norm Grads: 49.02875225276149
Evaluation on validation dataset:
Step 5, mean loss 16.539549119859718
Step 10, mean loss 35.98835478445524
Step 15, mean loss 63.07783792850698
Step 20, mean loss 58.53954372380051
Step 25, mean loss 58.551347534085615
Step 30, mean loss 62.74124775340253
Step 35, mean loss 61.148400403134396
Step 40, mean loss 59.08809132218647
Step 45, mean loss 60.7911286234337
Step 50, mean loss 61.3556202698593
Step 55, mean loss 54.08701004812943
Step 60, mean loss 55.3753106039948
Step 65, mean loss 52.52852906739376
Step 70, mean loss 56.70835502859354
Step 75, mean loss 61.448529559455984
Step 80, mean loss 66.44425902190571
Step 85, mean loss 71.31617205846932
Step 90, mean loss 73.09756631298056
Step 95, mean loss 76.13678674891872
Unrolled forward losses 0.5623180435071131
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 5.828112456968567; Norm Grads: 45.3582453753186
Training Loss (progress: 0.10): 5.972880013301419; Norm Grads: 46.751251742362996
Training Loss (progress: 0.20): 5.838085369042037; Norm Grads: 46.092778615369966
Training Loss (progress: 0.30): 5.899946243627037; Norm Grads: 49.84720553556814
Training Loss (progress: 0.40): 5.773426786031875; Norm Grads: 47.18963805938108
Training Loss (progress: 0.50): 5.851602408169569; Norm Grads: 51.44017473141531
Training Loss (progress: 0.60): 5.825960259956567; Norm Grads: 49.50394322100862
Training Loss (progress: 0.70): 5.7131171215008205; Norm Grads: 51.717111721204205
Training Loss (progress: 0.80): 5.735434989501309; Norm Grads: 49.0250874642971
Training Loss (progress: 0.90): 5.899374703331695; Norm Grads: 53.130758583966745
Evaluation on validation dataset:
Step 5, mean loss 17.649624830364075
Step 10, mean loss 38.080020462116394
Step 15, mean loss 68.52337983466509
Step 20, mean loss 62.99816745751905
Step 25, mean loss 61.01949482719305
Step 30, mean loss 65.68237110094135
Step 35, mean loss 63.53765809946536
Step 40, mean loss 94.69147900728524
Step 45, mean loss 89.05854765174456
Step 50, mean loss 76.80335090077682
Step 55, mean loss 60.61103832360695
Step 60, mean loss 55.09632975322715
Step 65, mean loss 52.06429157033803
Step 70, mean loss 55.92401047029038
Step 75, mean loss 60.3545602571876
Step 80, mean loss 65.1491878339034
Step 85, mean loss 70.18222964472835
Step 90, mean loss 72.04134174366052
Step 95, mean loss 74.48708993230588
Unrolled forward losses 0.5950003197205688
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 5.654209537182773; Norm Grads: 52.604245938162094
Training Loss (progress: 0.10): 5.646342994162936; Norm Grads: 52.758739668160416
Training Loss (progress: 0.20): 5.604625840318475; Norm Grads: 54.23849619759431
Training Loss (progress: 0.30): 5.625145825398878; Norm Grads: 55.08594609733336
Training Loss (progress: 0.40): 5.63328374852237; Norm Grads: 58.06879401193909
Training Loss (progress: 0.50): 5.589735445084239; Norm Grads: 56.210588170766684
Training Loss (progress: 0.60): 5.5977070160598945; Norm Grads: 55.77169903709526
Training Loss (progress: 0.70): 5.736836639121783; Norm Grads: 58.84269466286988
Training Loss (progress: 0.80): 5.729473325020271; Norm Grads: 58.66544662347138
Training Loss (progress: 0.90): 5.657601928167676; Norm Grads: 59.28445064333005
Evaluation on validation dataset:
Step 5, mean loss 22.66620784206847
Step 10, mean loss 42.82415292375072
Step 15, mean loss 69.65039340141834
Step 20, mean loss 63.78501811714244
Step 25, mean loss 61.874193689433426
Step 30, mean loss 65.6504122097029
Step 35, mean loss 63.83370011703715
Step 40, mean loss 74.95617815785381
Step 45, mean loss 73.85300645680095
Step 50, mean loss 68.0401015920255
Step 55, mean loss 59.32810622300045
Step 60, mean loss 58.241274823280435
Step 65, mean loss 53.9513897827829
Step 70, mean loss 57.748360335842904
Step 75, mean loss 62.8781646850851
Step 80, mean loss 67.65093499892923
Step 85, mean loss 72.78461370709574
Step 90, mean loss 74.33266878778733
Step 95, mean loss 76.82701742625852
Unrolled forward losses 0.669127389433605
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 5.611907351132135; Norm Grads: 60.17697197726803
Training Loss (progress: 0.10): 5.559944947133081; Norm Grads: 64.1864513999603
Training Loss (progress: 0.20): 5.644633389620102; Norm Grads: 64.16984025218844
