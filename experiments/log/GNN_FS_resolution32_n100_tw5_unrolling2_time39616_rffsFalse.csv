Training on dataset data/fs_2d_pde_128_train_dataset.h5
cuda:0
models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt
Number of parameters: 619769
Training started at: 2025-03-09 06:16:19
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 5.696747096999051; Norm Grads: 15.680554337220862; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.592130511238026; Norm Grads: 24.383997407836638; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.585356590375361; Norm Grads: 26.77103665734259; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.318389928009891; Norm Grads: 29.240871992195608; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.246957153898383; Norm Grads: 31.738746433640404; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.208817353056683; Norm Grads: 32.020887900025464; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.129256890086783; Norm Grads: 33.61957464551317; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.124634188504174; Norm Grads: 36.62301863768862; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 3.950413107667535; Norm Grads: 35.847346226387494; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 3.999057519820512; Norm Grads: 35.25711937994045; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 39.965985224974304
Step 10, mean loss 37.52602362700539
Step 15, mean loss 33.438416146664295
Step 20, mean loss 46.18751579237524
Step 25, mean loss 53.651502584255326
Step 30, mean loss 53.51754540761214
Step 35, mean loss 54.18263902723377
Step 40, mean loss 59.4576636433992
Step 45, mean loss 65.7754455666001
Step 50, mean loss 67.89267770039021
Step 55, mean loss 70.55616360653056
Step 60, mean loss 73.8556149766525
Step 65, mean loss 74.88243820652977
Step 70, mean loss 68.19069969455738
Step 75, mean loss 63.32610094304546
Step 80, mean loss 59.086686752419084
Step 85, mean loss 58.063504423693956
Step 90, mean loss 59.95335020934389
Step 95, mean loss 61.455420371966696
Unrolled forward losses 330.38910773597956
Evaluation on test dataset:
Step 5, mean loss 38.32080195828233
Step 10, mean loss 36.4355602829353
Step 15, mean loss 35.152343872318156
Step 20, mean loss 51.30962341215218
Step 25, mean loss 60.303200821105506
Step 30, mean loss 54.12146552090353
Step 35, mean loss 61.267532571011266
Step 40, mean loss 68.15150323171432
Step 45, mean loss 74.5949046410225
Step 50, mean loss 73.93093063535505
Step 55, mean loss 73.76326888666955
Step 60, mean loss 72.91417893979732
Step 65, mean loss 75.06808618504996
Step 70, mean loss 70.96501465720158
Step 75, mean loss 67.11210308294217
Step 80, mean loss 63.00012988281847
Step 85, mean loss 61.07559295578679
Step 90, mean loss 64.34274821837525
Step 95, mean loss 68.09012914569632
Unrolled forward losses 326.0055374481295
Saved model at models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt

Training time:  0:29:25.756502
Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 5.114939162461493; Norm Grads: 31.04926561829528; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.973655479348333; Norm Grads: 29.603954933683966; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.984034638628166; Norm Grads: 28.027925792726414; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.8987788819498315; Norm Grads: 28.908226158138785; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.069185962212459; Norm Grads: 26.372068750302546; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.913313961613574; Norm Grads: 28.585162670334853; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.873531967960391; Norm Grads: 26.53830883624742; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.8643409091415135; Norm Grads: 28.691170366756943; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.855810208518014; Norm Grads: 26.716051472581665; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.680574104753491; Norm Grads: 27.97798354474062; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 32.365286647660696
Step 10, mean loss 31.92246973110696
Step 15, mean loss 30.11580046592291
Step 20, mean loss 41.022041525549234
Step 25, mean loss 48.77079585243702
Step 30, mean loss 49.46612592934823
Step 35, mean loss 51.68542755690828
Step 40, mean loss 56.96033074271844
Step 45, mean loss 63.99183164046761
Step 50, mean loss 66.83715465547348
Step 55, mean loss 69.53493829716976
Step 60, mean loss 72.7271350065594
Step 65, mean loss 72.37849127769408
Step 70, mean loss 66.50855111599054
Step 75, mean loss 62.39281577902041
Step 80, mean loss 58.653220590539846
Step 85, mean loss 57.691932513081895
Step 90, mean loss 60.403648561536016
Step 95, mean loss 62.17633818205546
Unrolled forward losses 219.0657129608838
Evaluation on test dataset:
Step 5, mean loss 30.970475508178716
Step 10, mean loss 33.30435528483703
Step 15, mean loss 31.65995900825538
Step 20, mean loss 46.542869442040114
Step 25, mean loss 55.350255414572274
Step 30, mean loss 50.55240587160227
Step 35, mean loss 57.95819000234219
Step 40, mean loss 65.68015863408647
Step 45, mean loss 71.67600985593295
Step 50, mean loss 72.66670606091049
Step 55, mean loss 73.55149223591282
Step 60, mean loss 72.30621175175176
Step 65, mean loss 73.16020350598873
Step 70, mean loss 69.14698858791834
Step 75, mean loss 66.13956393032629
Step 80, mean loss 62.18027826253516
Step 85, mean loss 61.00807276100599
Step 90, mean loss 65.00042793901893
Step 95, mean loss 68.36612891702285
Unrolled forward losses 226.7687902027045
Saved model at models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt

Training time:  1:00:38.238646
Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 5.508916874848033; Norm Grads: 23.594948148384418; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.328084822990521; Norm Grads: 26.824257163979418; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.4483322258417; Norm Grads: 26.883241628117307; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 5.463530703101599; Norm Grads: 26.275855867144827; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.441750611761014; Norm Grads: 27.805461252438757; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.1806312901813305; Norm Grads: 27.64835781775413; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.4242157409033425; Norm Grads: 27.817942105773447; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.428623044257594; Norm Grads: 28.188354575274573; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.374357144582355; Norm Grads: 29.392863467040694; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 5.366638957637083; Norm Grads: 27.784648776852656; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 27.24770821990707
Step 10, mean loss 28.7473343071731
Step 15, mean loss 27.4472851886946
Step 20, mean loss 38.79847041584017
Step 25, mean loss 45.75436905492162
Step 30, mean loss 46.38185181499895
Step 35, mean loss 50.52366835073242
Step 40, mean loss 54.74501804802614
Step 45, mean loss 61.47055915991432
Step 50, mean loss 63.67900808237245
Step 55, mean loss 66.52428469770626
Step 60, mean loss 69.139606368817
Step 65, mean loss 68.96549576849819
Step 70, mean loss 63.998744993440695
Step 75, mean loss 60.22601249954441
Step 80, mean loss 56.34548969999643
Step 85, mean loss 55.878463007946834
Step 90, mean loss 58.06314679420949
Step 95, mean loss 60.27008975866994
Unrolled forward losses 191.18675053819834
Evaluation on test dataset:
Step 5, mean loss 27.750832470217347
Step 10, mean loss 30.31350416818969
Step 15, mean loss 29.522951373823176
Step 20, mean loss 43.75484568883718
Step 25, mean loss 52.41863801636204
Step 30, mean loss 47.920989423490866
Step 35, mean loss 56.41440411145537
Step 40, mean loss 63.197516957109855
Step 45, mean loss 68.55623055650473
Step 50, mean loss 69.5992609702271
Step 55, mean loss 70.51999124883599
Step 60, mean loss 69.14432724604298
Step 65, mean loss 70.04213585382367
Step 70, mean loss 66.45311856977703
Step 75, mean loss 63.55602775445145
Step 80, mean loss 60.307936894271734
Step 85, mean loss 59.17940302269491
Step 90, mean loss 62.43124605634208
Step 95, mean loss 66.5108335685095
Unrolled forward losses 196.97875269335228
Saved model at models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt

Training time:  1:33:56.556317
Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 5.089480706077086; Norm Grads: 30.1065683404424; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.24939498380183; Norm Grads: 29.83673328578464; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.324382801822526; Norm Grads: 29.91792474315189; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 5.352605786699843; Norm Grads: 29.584031100939352; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.265744048829033; Norm Grads: 29.935631298624063; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.233154775073894; Norm Grads: 29.96637319921775; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.385428951076759; Norm Grads: 30.39884288664451; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.221652457865782; Norm Grads: 31.087289636661655; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.038165073564619; Norm Grads: 31.40470508494521; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 5.2157773625241015; Norm Grads: 31.994449310099107; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 24.916254558494984
Step 10, mean loss 27.55325898065863
Step 15, mean loss 27.023415299012512
Step 20, mean loss 37.27325558972115
Step 25, mean loss 47.89669387569204
Step 30, mean loss 48.80287067091608
Step 35, mean loss 48.62739932439199
Step 40, mean loss 52.37461517686691
Step 45, mean loss 59.055330426749975
Step 50, mean loss 62.183501143446705
Step 55, mean loss 64.81413592575556
Step 60, mean loss 67.6999496049912
Step 65, mean loss 67.84406078538267
Step 70, mean loss 63.474378780337375
Step 75, mean loss 59.775384192510465
Step 80, mean loss 55.81195319651874
Step 85, mean loss 55.217912620435
Step 90, mean loss 56.738019313464896
Step 95, mean loss 58.960089260506656
Unrolled forward losses 178.62663398584203
Evaluation on test dataset:
Step 5, mean loss 25.382109862867672
Step 10, mean loss 28.57688696595344
Step 15, mean loss 27.946158124570637
Step 20, mean loss 42.39921097247034
Step 25, mean loss 53.54830586094366
Step 30, mean loss 47.47906572700226
Step 35, mean loss 52.498244138281805
Step 40, mean loss 60.51205141502575
Step 45, mean loss 66.60394022050164
Step 50, mean loss 68.36571051275027
Step 55, mean loss 69.11044941978815
Step 60, mean loss 68.2970481199504
Step 65, mean loss 68.99473849799229
Step 70, mean loss 66.05167098963472
Step 75, mean loss 63.46948621295045
Step 80, mean loss 59.603357818025955
Step 85, mean loss 58.72001799740717
Step 90, mean loss 61.28741696792082
Step 95, mean loss 65.26979453525463
Unrolled forward losses 187.17023957054414
Saved model at models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt

Training time:  2:07:02.395541
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 5.238378768701468; Norm Grads: 32.3874784824756; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.175920988299021; Norm Grads: 30.38254071460182; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.072676184934305; Norm Grads: 30.963807008012413; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 5.080685636504756; Norm Grads: 31.009555766750744; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.115738573904085; Norm Grads: 33.279778680066336; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.105879436511433; Norm Grads: 32.52737761170333; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.051213069535255; Norm Grads: 32.30469737654436; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.213394876103923; Norm Grads: 32.11992123016743; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.280587080157004; Norm Grads: 33.23736771220448; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 5.098212374845834; Norm Grads: 32.77706166049561; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 24.489500283297197
Step 10, mean loss 27.42556991945369
Step 15, mean loss 26.92011254833044
Step 20, mean loss 38.43563120635945
Step 25, mean loss 46.995484428347794
Step 30, mean loss 47.4075781232016
Step 35, mean loss 48.52137159232157
Step 40, mean loss 51.90673976342445
Step 45, mean loss 59.09105227329634
Step 50, mean loss 61.66573821726092
Step 55, mean loss 64.09093509879584
Step 60, mean loss 67.06435374217858
Step 65, mean loss 67.33528354160623
Step 70, mean loss 62.777814316113755
Step 75, mean loss 59.206187051198164
Step 80, mean loss 55.4565403274764
Step 85, mean loss 54.71166758279458
Step 90, mean loss 56.76913841359172
Step 95, mean loss 58.432959100802165
Unrolled forward losses 191.1151010100174
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 5.045602252895883; Norm Grads: 35.015517700585725; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.0372275342743; Norm Grads: 33.68407297203607; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.010219887218651; Norm Grads: 32.886107647957786; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 5.0059076432884035; Norm Grads: 35.70781541544332; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.068625773207834; Norm Grads: 35.16461288634474; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.920923988825516; Norm Grads: 36.87952250456176; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.923714625323551; Norm Grads: 37.24497879700086; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.141355834405405; Norm Grads: 35.77871236219449; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.200213911501228; Norm Grads: 36.613767769448; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 5.0186148169437175; Norm Grads: 36.574395454084204; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 25.024826977833342
Step 10, mean loss 25.542691848654993
Step 15, mean loss 26.01536044241204
Step 20, mean loss 36.655205860858395
Step 25, mean loss 46.8112061426394
Step 30, mean loss 48.85734461830363
Step 35, mean loss 47.73990504048051
Step 40, mean loss 51.21241045246556
Step 45, mean loss 58.21941663674675
Step 50, mean loss 61.082263176095175
Step 55, mean loss 64.01013022991779
Step 60, mean loss 66.86457637431155
Step 65, mean loss 66.00870796398934
Step 70, mean loss 61.38689439275726
Step 75, mean loss 57.65168516991862
Step 80, mean loss 54.57360898235194
Step 85, mean loss 54.48328803114293
Step 90, mean loss 56.623809778146594
Step 95, mean loss 59.12548547884814
Unrolled forward losses 184.34396938923805
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 4.936440192119795; Norm Grads: 36.837513100539404; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.979734979799027; Norm Grads: 36.73487140172616; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.999276917820517; Norm Grads: 38.393159763448665; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 5.0661273023081375; Norm Grads: 35.83154435752269; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.122784046799407; Norm Grads: 39.97108050584171; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.893364097681353; Norm Grads: 38.65628333434371; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.26112130707826; Norm Grads: 39.35395583812471; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.014027005389028; Norm Grads: 39.30760046526372; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.127841250619685; Norm Grads: 39.467468435402054; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.899167629812648; Norm Grads: 40.25519687677786; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 25.92098879958634
Step 10, mean loss 25.807482369504584
Step 15, mean loss 26.23793578096149
Step 20, mean loss 36.47878707080907
Step 25, mean loss 47.28925712212309
Step 30, mean loss 48.26339700972669
Step 35, mean loss 48.67564967931802
Step 40, mean loss 51.035350953808944
Step 45, mean loss 57.48287383516774
Step 50, mean loss 60.79384542410774
Step 55, mean loss 63.18104947690648
Step 60, mean loss 66.03125466487485
Step 65, mean loss 66.05323369293222
Step 70, mean loss 62.11347406331926
Step 75, mean loss 58.502099416341224
Step 80, mean loss 54.90433110609618
Step 85, mean loss 54.82772938854837
Step 90, mean loss 56.643465796319845
Step 95, mean loss 59.19931774770322
Unrolled forward losses 182.26244972901432
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 5.067492334744728; Norm Grads: 38.83192496640583; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.059087879430952; Norm Grads: 38.802933150695864; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.075445827641862; Norm Grads: 37.817965801251255; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.962216029488066; Norm Grads: 40.02920408325243; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.896887732570938; Norm Grads: 40.23467580965962; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.024310966925173; Norm Grads: 39.36163809323872; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.020356334882496; Norm Grads: 40.23402795278524; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.087371276466996; Norm Grads: 40.66189610996462; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.940875060798506; Norm Grads: 38.2675944367764; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 5.108056037316975; Norm Grads: 41.113127606251766; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 26.524616118729767
Step 10, mean loss 25.332248175439986
Step 15, mean loss 25.56391387550212
Step 20, mean loss 35.46023741740363
Step 25, mean loss 44.10735607054552
Step 30, mean loss 47.79073873061371
Step 35, mean loss 47.3469280483326
Step 40, mean loss 50.86714004929468
Step 45, mean loss 57.731435414150255
Step 50, mean loss 60.615573978330495
Step 55, mean loss 63.09042625424748
Step 60, mean loss 66.09733290868245
Step 65, mean loss 65.81707692862601
Step 70, mean loss 61.69975978345463
Step 75, mean loss 57.964257918360744
Step 80, mean loss 54.26459971470782
Step 85, mean loss 54.27152759200681
Step 90, mean loss 56.30412960078607
Step 95, mean loss 58.9959180370156
Unrolled forward losses 179.986846791697
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 4.8649598207991875; Norm Grads: 42.54531601960857; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.83111503910166; Norm Grads: 41.73015156660415; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.988722246115509; Norm Grads: 41.94608286793445; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.863357167252348; Norm Grads: 43.106238615371; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 5.077080940793084; Norm Grads: 42.43700046119721; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.087589088575381; Norm Grads: 41.28251150336452; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.979073282526272; Norm Grads: 42.33723586587294; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.0177281391735455; Norm Grads: 43.84387261769201; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 5.123875147572214; Norm Grads: 41.36903394086143; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.871293689397608; Norm Grads: 42.040816538917554; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 27.61242222817029
Step 10, mean loss 25.446804038348542
Step 15, mean loss 25.825193337007335
Step 20, mean loss 36.87854372411327
Step 25, mean loss 46.17476553483104
Step 30, mean loss 50.117396809109636
Step 35, mean loss 46.7790633008229
Step 40, mean loss 49.479784645958006
Step 45, mean loss 56.74277587616825
Step 50, mean loss 60.12642360414098
Step 55, mean loss 62.651793818759316
Step 60, mean loss 65.84640983081752
Step 65, mean loss 65.24829226881043
Step 70, mean loss 61.19262528543983
Step 75, mean loss 57.72035579055132
Step 80, mean loss 53.97104333589567
Step 85, mean loss 53.92113404332855
Step 90, mean loss 55.56596685285619
Step 95, mean loss 58.11796036197634
Unrolled forward losses 181.5088957340796
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 4.864811814708277; Norm Grads: 42.03889351377118; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.783375017181765; Norm Grads: 40.8835359846921; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.987990237991812; Norm Grads: 42.32862419018213; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.901960379954619; Norm Grads: 45.262609066539724; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.716771368412918; Norm Grads: 44.96027988149223; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.784918364810849; Norm Grads: 43.74553227984623; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.648118021123146; Norm Grads: 44.1196759782041; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.8764655867074636; Norm Grads: 43.166012011416235; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.963672374386144; Norm Grads: 42.58702623307881; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.83083934940887; Norm Grads: 43.496344631815056; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 25.20327772753408
Step 10, mean loss 24.80463381988293
Step 15, mean loss 24.917420908796807
Step 20, mean loss 36.29897347345368
Step 25, mean loss 47.59887920237442
Step 30, mean loss 49.420771652178544
Step 35, mean loss 47.10406800893722
Step 40, mean loss 49.31570804936523
Step 45, mean loss 56.54541254864995
Step 50, mean loss 59.71020662090924
Step 55, mean loss 62.04172398410599
Step 60, mean loss 65.05274332629656
Step 65, mean loss 64.7393152680938
Step 70, mean loss 60.44712504890101
Step 75, mean loss 56.54175722383637
Step 80, mean loss 53.41024574270908
Step 85, mean loss 53.645943837998516
Step 90, mean loss 55.60067699554391
Step 95, mean loss 58.41531937837992
Unrolled forward losses 185.5480205531296
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 4.851940672488319; Norm Grads: 42.51508550006174; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.986657110907034; Norm Grads: 44.90240835066438; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.932252518028539; Norm Grads: 45.03485080952836; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.805870573817104; Norm Grads: 43.47816941088065; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.850271187652043; Norm Grads: 45.14059781995465; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 5.1080839352576595; Norm Grads: 45.970952194561725; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.88094276548645; Norm Grads: 44.314318876243064; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 5.001785588386489; Norm Grads: 46.119821953017436; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.905859620971033; Norm Grads: 44.83269103441011; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.9330902307256235; Norm Grads: 44.717687915306406; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 21.849846751318957
Step 10, mean loss 24.222393423181472
Step 15, mean loss 23.921793588144002
Step 20, mean loss 33.35662694369553
Step 25, mean loss 41.32301872814819
Step 30, mean loss 45.180863280610176
Step 35, mean loss 45.52006817756465
Step 40, mean loss 48.918642175987344
Step 45, mean loss 55.51616957989606
Step 50, mean loss 59.192101075919574
Step 55, mean loss 61.504475503020814
Step 60, mean loss 64.35822012962161
Step 65, mean loss 64.47931145374811
Step 70, mean loss 60.7881075454125
Step 75, mean loss 57.4988191687719
Step 80, mean loss 54.31866217514191
Step 85, mean loss 55.02451662662004
Step 90, mean loss 57.07689933199073
Step 95, mean loss 60.31203368439505
Unrolled forward losses 199.52200259182774
Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 4.993191834512159; Norm Grads: 45.48097860800101; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.029351554903604; Norm Grads: 47.540136240097524; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 5.002132067806927; Norm Grads: 45.01047168436504; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.633154819352166; Norm Grads: 46.99049449708682; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.864014613878636; Norm Grads: 46.12654445886167; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.87054149381221; Norm Grads: 45.878045541709994; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.732637668255419; Norm Grads: 47.89642661077717; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.736962612684197; Norm Grads: 46.11430962491132; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.836151109207851; Norm Grads: 47.636711595005444; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.857924219614554; Norm Grads: 48.30473352457175; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 23.61837247813772
Step 10, mean loss 24.657507430794915
Step 15, mean loss 24.459215580138586
Step 20, mean loss 33.54719401471179
Step 25, mean loss 41.18150949754242
Step 30, mean loss 45.81930870032534
Step 35, mean loss 46.4373336534859
Step 40, mean loss 49.79999122502011
Step 45, mean loss 56.630817450481764
Step 50, mean loss 59.68758958581036
Step 55, mean loss 62.14876845702759
Step 60, mean loss 65.17257754200324
Step 65, mean loss 65.00368533537537
Step 70, mean loss 61.026481314054486
Step 75, mean loss 57.70979510189523
Step 80, mean loss 54.41533125487068
Step 85, mean loss 55.19658812235123
Step 90, mean loss 57.348709461555174
Step 95, mean loss 60.62894624708107
Unrolled forward losses 194.48178731967286
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 4.810796006278958; Norm Grads: 47.582774808731756; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 5.036158858480328; Norm Grads: 46.807567270197005; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.905548039445441; Norm Grads: 47.25319599150348; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.769134134853886; Norm Grads: 50.93974073017352; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.886558070328914; Norm Grads: 47.25116222170758; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.799770075723798; Norm Grads: 46.98230531106831; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.778090101167125; Norm Grads: 46.980949846324705; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.95713298377987; Norm Grads: 47.98716132627461; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.900359937313219; Norm Grads: 47.973140697045714; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.939517210801093; Norm Grads: 49.622681751842165; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 23.64650066548898
Step 10, mean loss 25.47806665404722
Step 15, mean loss 24.474967582413967
Step 20, mean loss 34.09151181929397
Step 25, mean loss 42.35270993542301
Step 30, mean loss 45.94269521938131
Step 35, mean loss 47.47372941655456
Step 40, mean loss 50.04134546641132
Step 45, mean loss 56.50328730267045
Step 50, mean loss 59.60619274433063
Step 55, mean loss 62.23355682152388
Step 60, mean loss 65.11106245827784
Step 65, mean loss 65.1161390169776
Step 70, mean loss 60.594453701068474
Step 75, mean loss 57.14442025622545
Step 80, mean loss 53.652630883002786
Step 85, mean loss 54.189948227742406
Step 90, mean loss 56.109570907818494
Step 95, mean loss 59.301310539459045
Unrolled forward losses 189.52219832646227
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 4.916434155119903; Norm Grads: 47.01940176122489; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.773769768445319; Norm Grads: 45.92883160407478; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.857151503774691; Norm Grads: 49.3548263190954; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.761184925613131; Norm Grads: 48.05423943271088; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.942899895973744; Norm Grads: 47.58214945635374; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.8135955482363215; Norm Grads: 47.474421450463424; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.794180048796244; Norm Grads: 47.517452724364716; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.840067372915036; Norm Grads: 49.980528629567644; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.919040100251569; Norm Grads: 45.340530604638715; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.938092548354923; Norm Grads: 48.58975313276603; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 22.09003024777138
Step 10, mean loss 24.146726144541006
Step 15, mean loss 24.007408861274662
Step 20, mean loss 33.426640882088975
Step 25, mean loss 43.31577408638424
Step 30, mean loss 46.49167650109962
Step 35, mean loss 44.95436760525254
Step 40, mean loss 47.81465660524005
Step 45, mean loss 55.23091226754395
Step 50, mean loss 58.644293609337446
Step 55, mean loss 60.809099162961736
Step 60, mean loss 63.757313772719456
Step 65, mean loss 63.708707363237394
Step 70, mean loss 59.86211797555736
Step 75, mean loss 56.55866639839
Step 80, mean loss 53.15852931856282
Step 85, mean loss 54.13927380740306
Step 90, mean loss 56.52248082721877
Step 95, mean loss 60.01338585499511
Unrolled forward losses 175.74927537224897
Evaluation on test dataset:
Step 5, mean loss 22.244106988619922
Step 10, mean loss 25.344671108055415
Step 15, mean loss 25.77520572398184
Step 20, mean loss 38.56909139171928
Step 25, mean loss 49.3644935455572
Step 30, mean loss 43.94570046804496
Step 35, mean loss 48.72713720827667
Step 40, mean loss 56.303478525154404
Step 45, mean loss 61.85587309572724
Step 50, mean loss 63.71390593861955
Step 55, mean loss 65.07344052108954
Step 60, mean loss 64.16235954477466
Step 65, mean loss 64.16767166233991
Step 70, mean loss 61.73175069189081
Step 75, mean loss 59.702097060815134
Step 80, mean loss 57.12687590999171
Step 85, mean loss 56.93361589336821
Step 90, mean loss 60.75977655433778
Step 95, mean loss 65.56931752948483
Unrolled forward losses 182.02212570238459
Saved model at models/GNN_FS_resolution32_n100_tw5_unrolling2_time39616_rffsFalse.pt

Training time:  7:41:03.695036
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 4.98423758191411; Norm Grads: 48.86044875007075; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.965513700650537; Norm Grads: 46.15029134089574; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.827798024319444; Norm Grads: 48.30183506169789; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.949673022823152; Norm Grads: 50.022726443671104; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.897959317160804; Norm Grads: 49.49398349593293; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.708342343897702; Norm Grads: 47.85982751699167; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.747977600270326; Norm Grads: 49.39949788335324; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.922485334588957; Norm Grads: 50.17201403865111; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.804777265039446; Norm Grads: 51.17035449385873; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.865920744981305; Norm Grads: 49.85730849066375; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 24.0056340416506
Step 10, mean loss 24.007775217327136
Step 15, mean loss 24.590840846834595
Step 20, mean loss 34.75860076476215
Step 25, mean loss 47.95799585570265
Step 30, mean loss 52.579456908555635
Step 35, mean loss 46.34112537252307
Step 40, mean loss 48.188749115692076
Step 45, mean loss 55.382088440799826
Step 50, mean loss 58.84468539537821
Step 55, mean loss 61.031148516073905
Step 60, mean loss 64.24873047539194
Step 65, mean loss 63.946510345987136
Step 70, mean loss 60.245779885535015
Step 75, mean loss 56.5398879384996
Step 80, mean loss 53.019967392755454
Step 85, mean loss 53.3854688742312
Step 90, mean loss 54.896936352522225
Step 95, mean loss 57.924024914928154
Unrolled forward losses 175.7855867815806
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 4.617395050720654; Norm Grads: 51.09141652709647; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.885246575482613; Norm Grads: 50.130264086920995; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.920736455933385; Norm Grads: 50.532476863903945; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.809302561305794; Norm Grads: 51.13057567212898; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.7913350453782515; Norm Grads: 49.10129429351268; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.825463532082014; Norm Grads: 50.83394640308826; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.871999153378439; Norm Grads: 49.38795512495163; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.966441084586876; Norm Grads: 52.02664056027443; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.716378740056947; Norm Grads: 49.110644185511774; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.709882379942438; Norm Grads: 50.47194473403503; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 24.407764021001423
Step 10, mean loss 24.513534173732175
Step 15, mean loss 24.222362938371447
Step 20, mean loss 34.05048261888069
Step 25, mean loss 44.46941839368479
Step 30, mean loss 48.155625790838585
Step 35, mean loss 46.33748684929763
Step 40, mean loss 49.04006042054445
Step 45, mean loss 55.66099293967612
Step 50, mean loss 59.07186145757953
Step 55, mean loss 61.45609216383258
Step 60, mean loss 64.39987422527453
Step 65, mean loss 64.09779563647919
Step 70, mean loss 60.27837048566334
Step 75, mean loss 56.82826102548253
Step 80, mean loss 53.50066053675951
Step 85, mean loss 53.943961096521384
Step 90, mean loss 55.76819196848243
Step 95, mean loss 59.03405157531277
Unrolled forward losses 177.58941054161193
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 4.83559672660904; Norm Grads: 50.95348782889186; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.767355880782135; Norm Grads: 49.32399390315504; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.848757870320718; Norm Grads: 50.690424063430214; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.862695864674498; Norm Grads: 48.41874731099481; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.935605432195253; Norm Grads: 52.3036032558854; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.847882387114932; Norm Grads: 50.995256740472804; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.751949182788712; Norm Grads: 51.334667800109116; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.739833984809272; Norm Grads: 49.40303672767406; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.96966723407831; Norm Grads: 49.39307036971501; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.821558265441807; Norm Grads: 49.24440329011245; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 23.84184408417854
Step 10, mean loss 24.33422852541218
Step 15, mean loss 24.123734238075784
Step 20, mean loss 34.98868145235087
Step 25, mean loss 48.781096654195096
Step 30, mean loss 51.07259618383644
Step 35, mean loss 46.125781141772265
Step 40, mean loss 48.929502821790116
Step 45, mean loss 55.851364916261
Step 50, mean loss 59.00413995249641
Step 55, mean loss 61.287844944291166
Step 60, mean loss 64.26415790442067
Step 65, mean loss 64.06936269880674
Step 70, mean loss 60.332490171792955
Step 75, mean loss 56.750069550300644
Step 80, mean loss 53.63642585205839
Step 85, mean loss 54.73252159924864
Step 90, mean loss 57.45346306262606
Step 95, mean loss 61.10658225475245
Unrolled forward losses 176.65869925299012
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 4.731070390412561; Norm Grads: 50.77134909427288; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.851175483977734; Norm Grads: 51.66407548577493; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.7133153671101615; Norm Grads: 50.08075858265188; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.892002599951657; Norm Grads: 51.76676467717078; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.673903247292801; Norm Grads: 52.256802314289295; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.848040481069108; Norm Grads: 52.58646443575966; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 5.042374546501664; Norm Grads: 51.739301062430854; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.907709853697686; Norm Grads: 51.50402670156816; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.803810778031581; Norm Grads: 49.56631752086831; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.794738409564498; Norm Grads: 49.54139696480266; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 23.77541407595875
Step 10, mean loss 24.315469141101907
Step 15, mean loss 23.956680870627483
Step 20, mean loss 34.16854900358134
Step 25, mean loss 42.901295205485894
Step 30, mean loss 46.600443491825246
Step 35, mean loss 45.93629932418172
Step 40, mean loss 49.19893077694644
Step 45, mean loss 56.156983479426074
Step 50, mean loss 59.55722471067393
Step 55, mean loss 62.00679795791133
Step 60, mean loss 64.87180173114095
Step 65, mean loss 65.06812942161206
Step 70, mean loss 61.1472468028275
Step 75, mean loss 58.087301206915
Step 80, mean loss 54.882423109113546
Step 85, mean loss 55.531455633230635
Step 90, mean loss 57.69246486801908
Step 95, mean loss 61.27135872595201
Unrolled forward losses 183.47953749552212
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 4.757988957069738; Norm Grads: 50.196560440606945; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.861140202032373; Norm Grads: 49.57845331033567; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.736855844913265; Norm Grads: 48.88421312271389; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.6834202344809945; Norm Grads: 49.95655062715536; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.714349489686601; Norm Grads: 51.96079221455511; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.884572631734206; Norm Grads: 51.666648453068134; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.783624952990089; Norm Grads: 51.109165077016016; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.799665366961379; Norm Grads: 48.83664073885789; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.78146963332911; Norm Grads: 52.854337509164466; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.690203693157865; Norm Grads: 50.57838365106134; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 22.470392983298073
Step 10, mean loss 23.58893885443649
Step 15, mean loss 23.765012144626034
Step 20, mean loss 34.20627673467282
Step 25, mean loss 42.3484354002306
Step 30, mean loss 47.695896289529806
Step 35, mean loss 45.00453286043248
Step 40, mean loss 47.94219650741151
Step 45, mean loss 55.097915780434064
Step 50, mean loss 58.9213407371208
Step 55, mean loss 61.14085035077353
Step 60, mean loss 63.926726426935296
Step 65, mean loss 63.85699169862225
Step 70, mean loss 60.0996209764673
Step 75, mean loss 56.7111339361774
Step 80, mean loss 53.553823902316054
Step 85, mean loss 54.71689352141594
Step 90, mean loss 56.89649371511271
Step 95, mean loss 60.532616808260315
Unrolled forward losses 198.99635511814546
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 4.7735864791356954; Norm Grads: 49.929912003759085; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.844558911517469; Norm Grads: 51.764016520262444; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.818543311350622; Norm Grads: 52.692939131059674; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.699376383941901; Norm Grads: 50.292935554931084; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.8174457394723795; Norm Grads: 50.84747579364185; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.931913350819529; Norm Grads: 52.09906957995012; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.875642576054017; Norm Grads: 53.817779888978045; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.840641167109495; Norm Grads: 49.33416395479926; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.630862849792627; Norm Grads: 52.35762299381902; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.938203468462515; Norm Grads: 54.590546389289; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 21.663052263762804
Step 10, mean loss 23.549507933934624
Step 15, mean loss 23.207278276135526
Step 20, mean loss 33.11148039707346
Step 25, mean loss 39.737771972364186
Step 30, mean loss 44.49480463408798
Step 35, mean loss 44.67703260961955
Step 40, mean loss 47.49193465582799
Step 45, mean loss 54.490314690926006
Step 50, mean loss 58.02975877106691
Step 55, mean loss 60.46813781559852
Step 60, mean loss 63.30215616041653
Step 65, mean loss 62.91293527395793
Step 70, mean loss 59.05859655735208
Step 75, mean loss 55.36037746398302
Step 80, mean loss 52.19821612175055
Step 85, mean loss 52.77978584386408
Step 90, mean loss 54.553643429211675
Step 95, mean loss 57.375565912956105
Unrolled forward losses 191.36350910553028
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 4.836094698508951; Norm Grads: 53.205273207184554; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.787944231826134; Norm Grads: 51.8071757563157; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.84041155021148; Norm Grads: 51.5639412189426; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.787177562774962; Norm Grads: 50.7893750517533; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.6648843433454426; Norm Grads: 51.12563575813003; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.875010144732409; Norm Grads: 53.91386305290437; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.727800746153747; Norm Grads: 53.84876354416105; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.697537228316605; Norm Grads: 54.038080848692886; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.755184717474177; Norm Grads: 54.516760904468505; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.835993431786378; Norm Grads: 51.771625430715474; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 24.145888562068976
Step 10, mean loss 24.407015734193322
Step 15, mean loss 24.474994902019812
Step 20, mean loss 33.89605478520436
Step 25, mean loss 41.60244535637027
Step 30, mean loss 44.70676434690845
Step 35, mean loss 45.52551860896583
Step 40, mean loss 48.91750246478331
Step 45, mean loss 55.28807331586668
Step 50, mean loss 58.73032971210155
Step 55, mean loss 61.21524950682068
Step 60, mean loss 64.51455764060825
Step 65, mean loss 63.60963379308791
Step 70, mean loss 60.398312037146766
Step 75, mean loss 56.52406005945717
Step 80, mean loss 53.05140801037242
Step 85, mean loss 52.986136610586975
Step 90, mean loss 54.43078270566274
Step 95, mean loss 56.917025253407175
Unrolled forward losses 178.8980996491619
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 4.867146085663647; Norm Grads: 51.06533648945021; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.74124032272543; Norm Grads: 51.84469318442482; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.8130153865607195; Norm Grads: 51.544292525737646; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.789140780475596; Norm Grads: 51.87075302900718; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.898140866648652; Norm Grads: 48.96325009232867; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.709434769847697; Norm Grads: 53.4028030564987; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.757658539455199; Norm Grads: 53.82967043504912; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.845988805215359; Norm Grads: 53.441405490767785; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.615633980734408; Norm Grads: 51.36886703626753; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.843897120655136; Norm Grads: 53.0299797028389; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 22.084686661307888
Step 10, mean loss 24.3841697143654
Step 15, mean loss 23.92070556361501
Step 20, mean loss 33.58554891368521
Step 25, mean loss 40.8267142198429
Step 30, mean loss 44.59860306875949
Step 35, mean loss 44.98740247524193
Step 40, mean loss 48.525999313081314
Step 45, mean loss 55.51829617496033
Step 50, mean loss 59.17886719654551
Step 55, mean loss 61.492280907725636
Step 60, mean loss 64.47777677338502
Step 65, mean loss 64.30134939773302
Step 70, mean loss 60.704359212064375
Step 75, mean loss 57.212923723138005
Step 80, mean loss 54.16319173327407
Step 85, mean loss 55.842688219440426
Step 90, mean loss 58.537365340434
Step 95, mean loss 62.42173452447427
Unrolled forward losses 206.34372548985198
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 4.838990994007326; Norm Grads: 52.67086581505912; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.717469562425871; Norm Grads: 54.52960887875508; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.837770326844325; Norm Grads: 56.06582572107274; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.808294544006503; Norm Grads: 54.23670777225021; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.81422717650168; Norm Grads: 51.648935527461845; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.843985368547303; Norm Grads: 54.36414043363625; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.673173158625199; Norm Grads: 53.527500874210766; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.959064835491734; Norm Grads: 54.66266751930023; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.814920063858898; Norm Grads: 53.02597630488082; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.814470641898086; Norm Grads: 53.75541293861232; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 22.599017521293337
Step 10, mean loss 23.42431850301338
Step 15, mean loss 23.411048887563382
Step 20, mean loss 33.68683538892782
Step 25, mean loss 43.2679047513426
Step 30, mean loss 48.12349333971766
Step 35, mean loss 45.082677753943955
Step 40, mean loss 48.023659297922705
Step 45, mean loss 55.18816689092786
Step 50, mean loss 58.87205356881006
Step 55, mean loss 61.11493546534594
Step 60, mean loss 63.714806773674844
Step 65, mean loss 63.72598105143319
Step 70, mean loss 59.99956974311229
Step 75, mean loss 56.684227964609775
Step 80, mean loss 53.5655326074447
Step 85, mean loss 54.44673116443135
Step 90, mean loss 56.498897947631235
Step 95, mean loss 59.969311351833035
Unrolled forward losses 186.04604945664818
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 4.79507451964906; Norm Grads: 51.52749420127738; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.841231197677378; Norm Grads: 50.830388759039366; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.8332755591996595; Norm Grads: 51.974094878065266; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.829887001782771; Norm Grads: 55.30936181171134; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.7490033719551485; Norm Grads: 51.80323814601633; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.7342149599115055; Norm Grads: 53.77899015330177; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.697446584900875; Norm Grads: 51.04608417033295; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.882306215762186; Norm Grads: 54.90218758429647; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.752803164230765; Norm Grads: 53.15970702011103; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.789429831364875; Norm Grads: 54.2393715096464; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 21.507125723725842
Step 10, mean loss 23.317585782528433
Step 15, mean loss 23.06168779395838
Step 20, mean loss 33.17133298302447
Step 25, mean loss 44.18376455162499
Step 30, mean loss 46.965539047259355
Step 35, mean loss 45.13435160680902
Step 40, mean loss 48.337878140058336
Step 45, mean loss 55.36650660894375
Step 50, mean loss 58.62014871794923
Step 55, mean loss 60.91965015937545
Step 60, mean loss 63.731212260407695
Step 65, mean loss 63.88121719728906
Step 70, mean loss 60.44130837087491
Step 75, mean loss 57.399349197588606
Step 80, mean loss 54.44720666618301
Step 85, mean loss 56.02124883101367
Step 90, mean loss 58.85848667657477
Step 95, mean loss 62.98887719663778
Unrolled forward losses 185.60445417696684
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 4.865496675922893; Norm Grads: 54.17348962786592; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.10): 4.703299074320967; Norm Grads: 55.49668997462784; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.20): 4.648693696036746; Norm Grads: 54.91396210383755; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.30): 4.7424975823879905; Norm Grads: 57.18162948997024; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.40): 4.929279950632897; Norm Grads: 55.80547519506603; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.50): 4.792160552202587; Norm Grads: 56.422128244361474; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.60): 4.785274102494359; Norm Grads: 54.096186939303536; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.70): 4.710405373760851; Norm Grads: 52.51822012037978; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.80): 4.7071652084302285; Norm Grads: 55.38206551396117; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Training Loss (progress: 0.90): 4.803800070953724; Norm Grads: 54.98437305578577; Sigmas: [None, None, None, None, None, None]; Coeffs: [None, None, None, None, None, None]
Evaluation on validation dataset:
Step 5, mean loss 21.7362029209269
Step 10, mean loss 23.61144756373103
Step 15, mean loss 23.948057003943163
Step 20, mean loss 32.76947117711761
Step 25, mean loss 40.0741291914182
Step 30, mean loss 46.03920390728274
Step 35, mean loss 45.09127323762171
Step 40, mean loss 47.93871155025727
Step 45, mean loss 54.331548832417425
Step 50, mean loss 57.66636011297803
Step 55, mean loss 60.18267441321679
Step 60, mean loss 63.21536147782806
Step 65, mean loss 62.747239200582804
Step 70, mean loss 59.285923349499924
Step 75, mean loss 55.43397067968377
Step 80, mean loss 52.121903217130416
Step 85, mean loss 52.06208129755269
Step 90, mean loss 53.27475746284221
Step 95, mean loss 55.618919022836465
Unrolled forward losses 179.02555370491055
Test loss: 182.02212570238459
Training time (until epoch 13):  {datetime.timedelta(seconds=27663, microseconds=695036)}
