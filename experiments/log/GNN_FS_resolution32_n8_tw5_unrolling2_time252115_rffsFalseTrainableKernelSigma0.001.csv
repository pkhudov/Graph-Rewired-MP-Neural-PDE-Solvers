Training on dataset data/fs_2d_pde_128_train_dataset.h5
cuda:0
models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt
Number of parameters: 619781.0
Training started at: 2025-02-05 21:15:54
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 5.659892648944192; Norm Grads: 15.517725111055773; Sigmas: [0.013171873311091124, 0.015035696230525758, 0.014922754290430473, 0.014598096177719063, 0.016397482976647212, 0.016814611604367972]; Coeffs: [1.017366017433968, 1.0183160217378688, 1.0182335627145012, 1.0170233970724811, 1.0192871557864769, 1.0193782419738087]
Training Loss (progress: 0.10): 4.277654834579753; Norm Grads: 86.89452664730506; Sigmas: [0.01553013522712603, 0.004276626906420281, 0.0026355162245306003, 0.0024139009276891183, 0.017584114097787935, 0.020394924968805225]; Coeffs: [1.077743016471053, 1.0578769750855463, 1.0708872622200396, 1.0505783251632792, 1.0544696976468833, 1.058745824354071]
Training Loss (progress: 0.20): 4.110767666915847; Norm Grads: 129.33620886468148; Sigmas: [0.012819930030907912, 0.005122738338439647, 0.0020280424131096262, 0.0017669558716013364, 0.015810406508818552, 0.026665833176754635]; Coeffs: [1.104692090069305, 1.0761821438972377, 1.1005914172680884, 1.0677153426414299, 1.0777048361582897, 1.0846752321297954]
Training Loss (progress: 0.30): 3.91462316853408; Norm Grads: 160.38844608250508; Sigmas: [0.011947841512698369, 0.005590078902158304, 0.0019231333846674084, 0.0018230407579854786, 0.013183880120584354, 0.030839123429033038]; Coeffs: [1.1215909280000274, 1.0926419921451813, 1.123199045879387, 1.0872651642020208, 1.101016928098794, 1.1062869506510251]
Training Loss (progress: 0.40): 4.021046663988555; Norm Grads: 150.28252825240847; Sigmas: [0.014273799771251157, 0.0056455291230104905, 0.002118190269525481, 0.002068006154653576, 0.012253511088716574, 0.0323201550530387]; Coeffs: [1.1347952334238802, 1.1042844377270855, 1.1420749572398678, 1.107731876290235, 1.120562287520051, 1.1229190972290362]
Training Loss (progress: 0.50): 3.9278472303422767; Norm Grads: 159.14348211052123; Sigmas: [0.015838872244612674, 0.005769673698838132, 0.0021772004795456872, 0.001982763872844266, 0.011330352367944194, 0.03540274747259898]; Coeffs: [1.145188691352215, 1.1144323433219478, 1.1600094352577472, 1.1292881056122401, 1.139902543094582, 1.139994457385781]
Training Loss (progress: 0.60): 3.8519597043861515; Norm Grads: 184.5182588911587; Sigmas: [0.01842870475158159, 0.00547708552462165, 0.00238811433918036, 0.0022673772262411045, 0.00971101957473932, 0.036813112636939004]; Coeffs: [1.154867682570595, 1.1220980638818032, 1.1764797855133147, 1.1522596625065191, 1.1576360774103356, 1.1533087013014418]
Training Loss (progress: 0.70): 3.7080193198912346; Norm Grads: 159.5351467841745; Sigmas: [0.017978338204699112, 0.005463841332049971, 0.002333498481567068, 0.0022371908695359294, 0.009064102608269693, 0.03816805402313886]; Coeffs: [1.161263601828462, 1.1280485998753988, 1.1900013732005437, 1.1754899272531956, 1.1720930281460844, 1.163893059180269]
Training Loss (progress: 0.80): 3.7946117353695423; Norm Grads: 155.21975253384304; Sigmas: [0.019917204978594824, 0.005564888181015645, 0.001963326523203338, 0.0021596262233640373, 0.008609942531109452, 0.03948612380040115]; Coeffs: [1.167886878689395, 1.1338154515247991, 1.2022440324784265, 1.1980619484843995, 1.184974173273795, 1.1733976215177913]
Training Loss (progress: 0.90): 3.718621454624436; Norm Grads: 189.8482745229073; Sigmas: [0.021675895749899313, 0.005528488084296553, 0.002307976257502551, 0.002414919834546691, 0.008231687244299912, 0.040699074787487556]; Coeffs: [1.1734931156573785, 1.139854574555451, 1.2144217263708799, 1.2201435101308624, 1.1955194818038408, 1.1817723425563196]
Evaluation on validation dataset:
Step 5, mean loss 25.933886661384683
Step 10, mean loss 28.145712804194474
Step 15, mean loss 27.3846597048612
Step 20, mean loss 39.13279808008704
Step 25, mean loss 45.194626634639626
Step 30, mean loss 45.691999045647044
Step 35, mean loss 48.75187241949567
Step 40, mean loss 52.90219245079945
Step 45, mean loss 59.483481983294254
Step 50, mean loss 61.800306611376726
Step 55, mean loss 62.31660599456774
Step 60, mean loss 63.36881737890555
Step 65, mean loss 61.97133856693213
Step 70, mean loss 58.08195560080421
Step 75, mean loss 53.62517866063445
Step 80, mean loss 50.223654277135445
Step 85, mean loss 48.693997958463946
Step 90, mean loss 50.681747537930875
Step 95, mean loss 52.36696412480622
Unrolled forward losses 315.5335369002744
Evaluation on test dataset:
Step 5, mean loss 26.860413177734717
Step 10, mean loss 30.269729546077368
Step 15, mean loss 29.36995484269781
Step 20, mean loss 43.612463813930376
Step 25, mean loss 52.85888587169805
Step 30, mean loss 47.25808415623521
Step 35, mean loss 52.625083251323794
Step 40, mean loss 60.35625362612292
Step 45, mean loss 66.73988455109298
Step 50, mean loss 67.81052735489948
Step 55, mean loss 65.93525603247097
Step 60, mean loss 63.096066519123674
Step 65, mean loss 62.93282495231068
Step 70, mean loss 59.359781588395265
Step 75, mean loss 55.80380958791841
Step 80, mean loss 53.8255582947046
Step 85, mean loss 52.18029213215317
Step 90, mean loss 54.94089601854467
Step 95, mean loss 57.493321096074546
Unrolled forward losses 305.10648182008254
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  0:31:38.190732
Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 4.7700168862165055; Norm Grads: 147.47829349772115; Sigmas: [0.02242637682580297, 0.005676602613221289, 0.0023333189208913302, 0.0021677850706121947, 0.007745570556159178, 0.04113829756015309]; Coeffs: [1.1796042313751443, 1.1454415578300854, 1.2237409056392943, 1.2399082670482584, 1.2052948350943289, 1.1892133070910542]
Training Loss (progress: 0.10): 4.8465105337300605; Norm Grads: 126.98160887250076; Sigmas: [0.025828669400872414, 0.005858454172606427, 0.002422613347934342, 0.0020820970629269217, 0.008272052698726239, 0.047527521602597565]; Coeffs: [1.1839299428460708, 1.149658113382805, 1.2291304240200989, 1.251603859926129, 1.2118487054816545, 1.1918387079131303]
Training Loss (progress: 0.20): 4.772859125363463; Norm Grads: 137.28149239675938; Sigmas: [0.026703644362036948, 0.005903919161459046, 0.0023613139624435015, 0.0024189394856535093, 0.008192231749611324, 0.05375298237192877]; Coeffs: [1.1877947131338733, 1.1551044905014638, 1.2351881065238892, 1.2646491110897624, 1.2188475826805185, 1.1977380274463691]
Training Loss (progress: 0.30): 4.707205607626507; Norm Grads: 142.84625506413624; Sigmas: [0.028226027770182613, 0.005622845045182767, 0.002132014862116279, 0.002032687023865229, 0.008010385454004393, 0.0595003991404407]; Coeffs: [1.1930946315787745, 1.1602238440435009, 1.2432891875509446, 1.2774108490699534, 1.2249566748238834, 1.2039114986457695]
Training Loss (progress: 0.40): 4.837472900844789; Norm Grads: 134.80555030336268; Sigmas: [0.030932280727370504, 0.005893623910045813, 0.0019510424582990145, 0.0022689230070360262, 0.00857900700669396, 0.06446456633705146]; Coeffs: [1.197291553850143, 1.166475659632937, 1.2491700615154484, 1.2913554729371237, 1.2322448487763473, 1.2093495984530733]
Training Loss (progress: 0.50): 4.727060597069576; Norm Grads: 133.18481924833227; Sigmas: [0.032439249128247936, 0.0059407404958046325, 0.0022439530964410356, 0.002327518838293613, 0.007739764029049213, 0.07102683363215748]; Coeffs: [1.2028280097867543, 1.1721693202901182, 1.2558845081803511, 1.3051270281825211, 1.2374896457419173, 1.2143866831035837]
Training Loss (progress: 0.60): 4.614925937676021; Norm Grads: 149.0465489509469; Sigmas: [0.03474025403827393, 0.00623177663793793, 0.0023881147798293636, 0.0020573833228246428, 0.007894386117238113, 0.07655803852719756]; Coeffs: [1.2084957125066615, 1.1785807672620672, 1.2617912054830736, 1.3174018469075914, 1.2434276317138526, 1.2202824693452141]
Training Loss (progress: 0.70): 4.378437768468264; Norm Grads: 145.6581831353715; Sigmas: [0.0361462006446089, 0.006387886451299969, 0.002527112833336955, 0.0022335616047125736, 0.007849820717641494, 0.08175984417270882]; Coeffs: [1.214440257399218, 1.183703491483918, 1.2676293536219676, 1.3306231706495084, 1.2504879678897203, 1.2259344117793043]
Training Loss (progress: 0.80): 4.666517680480208; Norm Grads: 132.9905506578843; Sigmas: [0.03581368367298829, 0.005626825646732759, 0.0022910450295955927, 0.002190875104980818, 0.008122854570375792, 0.08485184998292006]; Coeffs: [1.219221733736034, 1.1897313372739593, 1.2743223247336326, 1.34310311504281, 1.2561400873546038, 1.2303245374925054]
Training Loss (progress: 0.90): 4.495249345257178; Norm Grads: 151.24852691720687; Sigmas: [0.03705900398327053, 0.005940290907259956, 0.002188550309304105, 0.0019377228176919203, 0.0076688692629368884, 0.08957194027402414]; Coeffs: [1.223495296183135, 1.1955218548317197, 1.2798630940773563, 1.3566269741333434, 1.261481009066988, 1.2364523252164683]
Evaluation on validation dataset:
Step 5, mean loss 22.462681134385463
Step 10, mean loss 26.213436979780333
Step 15, mean loss 24.88824571772214
Step 20, mean loss 35.991954418128465
Step 25, mean loss 42.75427198380212
Step 30, mean loss 45.29280664280439
Step 35, mean loss 46.976448230389025
Step 40, mean loss 50.41883896475737
Step 45, mean loss 56.17362014944666
Step 50, mean loss 58.67205030066644
Step 55, mean loss 60.120373157026364
Step 60, mean loss 62.2414363325485
Step 65, mean loss 60.91166171916095
Step 70, mean loss 57.2633057770405
Step 75, mean loss 52.82994994236425
Step 80, mean loss 49.35981950061611
Step 85, mean loss 48.14682614656744
Step 90, mean loss 50.3486829383469
Step 95, mean loss 51.61883306544599
Unrolled forward losses 223.4236633675713
Evaluation on test dataset:
Step 5, mean loss 23.83521814236586
Step 10, mean loss 27.720584940272843
Step 15, mean loss 26.465190484785836
Step 20, mean loss 40.985700874899244
Step 25, mean loss 49.6145968203764
Step 30, mean loss 43.90826573938108
Step 35, mean loss 49.61961558824453
Step 40, mean loss 57.18765974469716
Step 45, mean loss 63.29437638034193
Step 50, mean loss 64.84199509113455
Step 55, mean loss 63.05830427548948
Step 60, mean loss 61.44071261234309
Step 65, mean loss 61.669967208729446
Step 70, mean loss 58.620588696070925
Step 75, mean loss 54.25969237516475
Step 80, mean loss 52.461713627492415
Step 85, mean loss 51.34672669571583
Step 90, mean loss 54.54682452640809
Step 95, mean loss 56.88837611699951
Unrolled forward losses 229.04168617042527
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  1:03:35.665630
Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 5.2370817473795945; Norm Grads: 106.16681032200307; Sigmas: [0.03927732683175758, 0.006121786406687081, 0.002477828236972192, 0.002230997294976096, 0.007917717688872155, 0.09496371697233379]; Coeffs: [1.229637849318457, 1.2003050203212993, 1.2867233390473891, 1.369239798139588, 1.2666870434751585, 1.242792499771395]
Training Loss (progress: 0.10): 5.32013306058369; Norm Grads: 111.83846812573864; Sigmas: [0.03834248215890019, 0.005784881973577591, 0.002426700613855541, 0.002295610703645036, 0.007955364561830474, 0.09828927100764662]; Coeffs: [1.2310231583259725, 1.2018533632994912, 1.2879786581955548, 1.3732678644204486, 1.268560377222322, 1.2454512734108687]
Training Loss (progress: 0.20): 5.107430894013312; Norm Grads: 116.24331273210181; Sigmas: [0.038628976155575666, 0.006111950832340736, 0.0025400612572901255, 0.0021372754929968405, 0.008127304994440398, 0.10087989657587447]; Coeffs: [1.2323391961510313, 1.2046518411125586, 1.2894275581650554, 1.3773482971956257, 1.2703890319900615, 1.2491802559504668]
Training Loss (progress: 0.30): 5.070509304860168; Norm Grads: 126.36284663380667; Sigmas: [0.039400649411579, 0.0058635779297408945, 0.0024815728120747174, 0.0022882422148261103, 0.00812993111483733, 0.10355714818965894]; Coeffs: [1.2349375113637582, 1.2060293351449252, 1.29089018092496, 1.380925687850922, 1.2722888673801065, 1.2520704492440633]
Training Loss (progress: 0.40): 5.189361895942487; Norm Grads: 126.40148983741561; Sigmas: [0.03960915976996286, 0.005901623235892469, 0.0023354414387179536, 0.0022950787388546475, 0.007819232937679093, 0.10615844938997608]; Coeffs: [1.2367563552181848, 1.2075888938431394, 1.291793887086407, 1.3845349661619561, 1.273609832548481, 1.2543607192777935]
Training Loss (progress: 0.50): 5.170843918958223; Norm Grads: 124.9576408116753; Sigmas: [0.040107535617322415, 0.006279671886034304, 0.002476089008972602, 0.0022825670074533852, 0.007891734754343136, 0.10900574999989199]; Coeffs: [1.2394028379880826, 1.2095207006053288, 1.2928654610610857, 1.3880518414042242, 1.275313657027688, 1.257513861993134]
Training Loss (progress: 0.60): 5.095620108686186; Norm Grads: 131.14267417440274; Sigmas: [0.039733049535646485, 0.006217510629146178, 0.002636248940561262, 0.002220791654086843, 0.007987775272475788, 0.11166236576054459]; Coeffs: [1.2405605156581847, 1.2110579650567002, 1.2946992847850458, 1.3915828692993817, 1.2772043683222876, 1.2601972757305204]
Training Loss (progress: 0.70): 4.999234652243747; Norm Grads: 125.17020477547965; Sigmas: [0.039703955615319704, 0.006141130572989303, 0.0024869789700441773, 0.002274632465657834, 0.008011646794281974, 0.11369315712211317]; Coeffs: [1.2429585496329432, 1.2124688751770192, 1.2965477330346515, 1.3950253291919332, 1.2786017015854225, 1.262762373540223]
Training Loss (progress: 0.80): 5.087248451274506; Norm Grads: 131.69230028255882; Sigmas: [0.04080125498320441, 0.00632753410106014, 0.002576312654156237, 0.0023496805620335363, 0.008161067531030334, 0.11597763226887184]; Coeffs: [1.2444731523879717, 1.2144527582241802, 1.2976009768310075, 1.3991655098965876, 1.2805540880766633, 1.2649054230370762]
Training Loss (progress: 0.90): 5.148607124165754; Norm Grads: 125.88164069786873; Sigmas: [0.04102914061561203, 0.006092480650579981, 0.0025187582725265663, 0.0022352080164218095, 0.00822023084630879, 0.11901887533398108]; Coeffs: [1.2460298293233705, 1.2164900682329705, 1.299657867056622, 1.4025146342084323, 1.2820382148748053, 1.2682503589179686]
Evaluation on validation dataset:
Step 5, mean loss 20.843267920734213
Step 10, mean loss 25.495015891802268
Step 15, mean loss 23.777145272797327
Step 20, mean loss 34.80259054803204
Step 25, mean loss 42.168850146818144
Step 30, mean loss 44.59380655885346
Step 35, mean loss 46.13173296785607
Step 40, mean loss 49.69760616964723
Step 45, mean loss 55.532730955301304
Step 50, mean loss 58.00264837908387
Step 55, mean loss 59.45198480811847
Step 60, mean loss 61.48343510169829
Step 65, mean loss 61.321040357469855
Step 70, mean loss 57.172658654826066
Step 75, mean loss 53.209005356921494
Step 80, mean loss 49.44397442754542
Step 85, mean loss 47.96125659478748
Step 90, mean loss 49.45392864136879
Step 95, mean loss 51.26991697746793
Unrolled forward losses 202.927211878194
Evaluation on test dataset:
Step 5, mean loss 21.700164886224517
Step 10, mean loss 26.425926824304934
Step 15, mean loss 25.776498721897894
Step 20, mean loss 39.91851254414209
Step 25, mean loss 48.104064608202876
Step 30, mean loss 42.01707420774797
Step 35, mean loss 49.73892503993996
Step 40, mean loss 57.13434821749745
Step 45, mean loss 62.72192637664271
Step 50, mean loss 63.58769914268661
Step 55, mean loss 62.48885506720556
Step 60, mean loss 60.496978197839944
Step 65, mean loss 61.302009271418164
Step 70, mean loss 58.75690448631227
Step 75, mean loss 54.68783353705066
Step 80, mean loss 52.63899631487182
Step 85, mean loss 51.20810944631285
Step 90, mean loss 53.703545914631775
Step 95, mean loss 56.44390303851422
Unrolled forward losses 206.22151526295647
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  1:39:45.434272
Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 5.043888009027564; Norm Grads: 134.77072198580493; Sigmas: [0.040495631721941254, 0.006176641053539053, 0.002435607176061303, 0.0021097521746887902, 0.008133885709131908, 0.12012154866429217]; Coeffs: [1.2484116687530071, 1.2182585111634667, 1.3010332909911686, 1.4058687141828456, 1.2835546487659821, 1.2702730046017814]
Training Loss (progress: 0.10): 5.199912711474558; Norm Grads: 117.49922204165361; Sigmas: [0.04152985383921911, 0.0059648407859890056, 0.0025970701505257897, 0.00225652085668213, 0.007901926148065121, 0.1224071211599577]; Coeffs: [1.249930148691478, 1.2198833051592746, 1.303060964920571, 1.4092523897010711, 1.2848349450275582, 1.2727276345100487]
Training Loss (progress: 0.20): 5.04041147172862; Norm Grads: 131.73554723051132; Sigmas: [0.04182537727925708, 0.006265436098790252, 0.002574134733202873, 0.002279063656069804, 0.008445271135627888, 0.12388888563476247]; Coeffs: [1.2520540316233073, 1.2215337495760359, 1.3044733480252444, 1.4119502345495443, 1.2865757017642143, 1.275038444306161]
Training Loss (progress: 0.30): 5.150809627285401; Norm Grads: 149.68168682758989; Sigmas: [0.04122393853740147, 0.006398606399612589, 0.0024681605511575255, 0.0024225478743581576, 0.008308335589895962, 0.12669821886216454]; Coeffs: [1.2531290681400697, 1.2231878872976258, 1.3058541093034317, 1.4151884465711544, 1.2878305126698635, 1.2776910251848508]
Training Loss (progress: 0.40): 4.987287554861884; Norm Grads: 143.71908220750817; Sigmas: [0.04175353947062158, 0.006384518770242907, 0.002513819923349718, 0.002132319680973934, 0.008415259809206564, 0.12819020292197228]; Coeffs: [1.2552031952428027, 1.2246557608657271, 1.307546208088937, 1.4187156381928732, 1.2897417496355685, 1.2798436729506912]
Training Loss (progress: 0.50): 5.060263744307967; Norm Grads: 137.9068338906067; Sigmas: [0.04241635193184262, 0.006427409477806366, 0.002549809929737257, 0.0021736301986583773, 0.008640238104849514, 0.13040201702540652]; Coeffs: [1.2569320568297906, 1.2263614185134084, 1.308664120769421, 1.4222078728369716, 1.2916341059432939, 1.2826076645147795]
Training Loss (progress: 0.60): 5.089058268584471; Norm Grads: 134.12147936306815; Sigmas: [0.04227744698266932, 0.006551006811778973, 0.0024473370610310617, 0.0022240926189720247, 0.00853726191027687, 0.13288053912847164]; Coeffs: [1.2586552869627563, 1.2280645341615524, 1.3101950638798188, 1.4258029323069967, 1.2930744201322617, 1.2849996277643703]
Training Loss (progress: 0.70): 5.016687266296031; Norm Grads: 137.7589965220337; Sigmas: [0.04283589936783416, 0.00633507253080573, 0.002497485424441967, 0.0020885447093839573, 0.008338795994473836, 0.13468599456072775]; Coeffs: [1.260239529140448, 1.2296189527609442, 1.3122387291330462, 1.4289915291226463, 1.2945799199356054, 1.28787760049988]
Training Loss (progress: 0.80): 4.95697845867993; Norm Grads: 149.22862223635545; Sigmas: [0.04290011035082016, 0.0063744761356248295, 0.002690998093043534, 0.0021680256162087733, 0.008773108260832599, 0.13683494816281744]; Coeffs: [1.261638747114522, 1.230798211869444, 1.313889245853957, 1.4319780288074357, 1.296584597055808, 1.2898159815024839]
Training Loss (progress: 0.90): 4.9776019561385265; Norm Grads: 154.8169336712258; Sigmas: [0.04200304386106037, 0.0067909908147953425, 0.0023836626197095995, 0.0022806748363295155, 0.008499253976258229, 0.13842215699551644]; Coeffs: [1.2625682657920028, 1.232600426528582, 1.314885894984852, 1.4352470818532679, 1.297766725438262, 1.2924869571508453]
Evaluation on validation dataset:
Step 5, mean loss 21.770245591172127
Step 10, mean loss 23.252063178032643
Step 15, mean loss 23.100082526156065
Step 20, mean loss 34.030623766795394
Step 25, mean loss 42.17946977930222
Step 30, mean loss 43.76044894532398
Step 35, mean loss 44.20220622001675
Step 40, mean loss 47.81763307971769
Step 45, mean loss 54.441284467616434
Step 50, mean loss 58.04948819093845
Step 55, mean loss 59.6088284560534
Step 60, mean loss 61.281508488002125
Step 65, mean loss 60.5562541250019
Step 70, mean loss 56.94882391018223
Step 75, mean loss 53.110613461449326
Step 80, mean loss 49.33338650743359
Step 85, mean loss 48.26670572766187
Step 90, mean loss 49.8694804890863
Step 95, mean loss 52.06000054098952
Unrolled forward losses 213.40944765087932
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 5.039627477609951; Norm Grads: 155.05052155575876; Sigmas: [0.042156985823879015, 0.006753205514952345, 0.0023701097842888158, 0.0021519813215774668, 0.008726295990152094, 0.14101050526060738]; Coeffs: [1.2641150340432306, 1.2348893396358114, 1.316151459552482, 1.4383345133225132, 1.2996586175375542, 1.2953567185895758]
Training Loss (progress: 0.10): 5.181235671910327; Norm Grads: 128.7176115789745; Sigmas: [0.04246946909231194, 0.006392740808135874, 0.002655374185624441, 0.002290699923740708, 0.008647743750032919, 0.14268904195696921]; Coeffs: [1.2659972873140959, 1.2365600633281668, 1.3180113336255879, 1.4419447748531902, 1.3013176477446424, 1.2976800004353444]
Training Loss (progress: 0.20): 5.1676162555304614; Norm Grads: 130.4020944789587; Sigmas: [0.04253592661617369, 0.00664078530681857, 0.0026833541196971383, 0.002154609932259336, 0.008580954047907523, 0.14410291071410883]; Coeffs: [1.2678339550940585, 1.2386392242682813, 1.3196147266875373, 1.4450023693239722, 1.3029596910080001, 1.2994900418940487]
Training Loss (progress: 0.30): 5.015618128593247; Norm Grads: 146.25574331595513; Sigmas: [0.04303366516521926, 0.0062514930923937605, 0.0024020056932456324, 0.002140152070923196, 0.00862523901328686, 0.1458673558922722]; Coeffs: [1.269892770070766, 1.240809270309498, 1.3209132379711193, 1.4485318668913474, 1.3046312006368121, 1.3023213048171023]
Training Loss (progress: 0.40): 4.88914780554177; Norm Grads: 145.35205375618995; Sigmas: [0.043504964386690985, 0.006484767030068725, 0.0026541974217544916, 0.0024424287144974516, 0.008740356980742808, 0.14759416937393108]; Coeffs: [1.2715849500588474, 1.2423186754774824, 1.3232486457947374, 1.4520434182447768, 1.3063571293650538, 1.304938574252173]
Training Loss (progress: 0.50): 4.896371192495071; Norm Grads: 147.8735020478143; Sigmas: [0.04269450394276345, 0.00654087279057069, 0.002638989416378179, 0.002158850018647015, 0.008692923260120448, 0.1489963649557474]; Coeffs: [1.2725337491561373, 1.243445358792032, 1.3249658912459972, 1.454952723207495, 1.3075619007172814, 1.3070383818722018]
Training Loss (progress: 0.60): 4.9348842584898085; Norm Grads: 147.29287081694272; Sigmas: [0.04290059492186505, 0.0064991201046083235, 0.0025006321530586105, 0.0023762708724001137, 0.008790711146696696, 0.15106140723849018]; Coeffs: [1.2745668917565214, 1.245290650910613, 1.3258855040825266, 1.4584010869353412, 1.3092807367040658, 1.3098358617376873]
Training Loss (progress: 0.70): 5.054749359161224; Norm Grads: 140.43631314874327; Sigmas: [0.043558381827222124, 0.006478779939966021, 0.002582577541084184, 0.0022131603327451886, 0.008610969105856535, 0.15282597726320102]; Coeffs: [1.2760076275421506, 1.2468358820861833, 1.3277211402611444, 1.4614104020770047, 1.310648012624924, 1.3121241705172042]
Training Loss (progress: 0.80): 4.871014893511556; Norm Grads: 158.49217280324794; Sigmas: [0.04358579778044601, 0.006598596849504596, 0.002496498548322207, 0.0020233399395779396, 0.008612199172787433, 0.15368676067339626]; Coeffs: [1.2774899721930972, 1.2486518346132753, 1.3292739377186824, 1.4645530206885589, 1.311924422672592, 1.3140818267888705]
Training Loss (progress: 0.90): 5.17545887536943; Norm Grads: 141.2416976363045; Sigmas: [0.04288187770758172, 0.006799772597597031, 0.0025528380673149843, 0.0023587832637856293, 0.008632126827546108, 0.1553051438011406]; Coeffs: [1.2787696626490868, 1.2500223507765753, 1.3304372792626002, 1.4674098069774217, 1.3136530476812724, 1.3162061247505559]
Evaluation on validation dataset:
Step 5, mean loss 21.078703570006667
Step 10, mean loss 24.19735403832542
Step 15, mean loss 23.28073666245172
Step 20, mean loss 35.53518909714013
Step 25, mean loss 48.29170904666924
Step 30, mean loss 48.453351515050656
Step 35, mean loss 44.831064964308645
Step 40, mean loss 48.009641200282594
Step 45, mean loss 54.068378761799195
Step 50, mean loss 57.704152359503915
Step 55, mean loss 59.342980714015795
Step 60, mean loss 61.411143673385425
Step 65, mean loss 61.010994309584774
Step 70, mean loss 57.65650914057723
Step 75, mean loss 53.793679880763065
Step 80, mean loss 50.11889519277174
Step 85, mean loss 49.09304974198004
Step 90, mean loss 50.77256118527517
Step 95, mean loss 53.35594351924071
Unrolled forward losses 188.7667685340393
Evaluation on test dataset:
Step 5, mean loss 21.655479586526866
Step 10, mean loss 25.20441467728633
Step 15, mean loss 24.31248834428485
Step 20, mean loss 40.38587774819065
Step 25, mean loss 55.05508846155937
Step 30, mean loss 46.68159382696488
Step 35, mean loss 49.18553525505416
Step 40, mean loss 55.50065943782725
Step 45, mean loss 61.79083918767649
Step 50, mean loss 63.745880632064235
Step 55, mean loss 62.678583647340936
Step 60, mean loss 61.047755950510215
Step 65, mean loss 62.03093740115361
Step 70, mean loss 59.20670536844226
Step 75, mean loss 55.25523428993587
Step 80, mean loss 53.36217172763196
Step 85, mean loss 52.73767260729089
Step 90, mean loss 55.64861949070665
Step 95, mean loss 58.78793538420415
Unrolled forward losses 192.60668390475504
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  2:47:34.265174
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 5.075458827494436; Norm Grads: 135.18894941380043; Sigmas: [0.043402827740655466, 0.006785696714453307, 0.002621993782425264, 0.0022784304604686377, 0.008810856079202378, 0.15761252191880462]; Coeffs: [1.2804383866075117, 1.25137552873184, 1.33193330318541, 1.4700058390674966, 1.3149863690847676, 1.318746945620144]
Training Loss (progress: 0.10): 5.019897191289524; Norm Grads: 147.07335708501734; Sigmas: [0.043423189375820216, 0.006846078689163264, 0.0025087305469658613, 0.0022546029117383607, 0.008709624970517181, 0.15866419405001198]; Coeffs: [1.2813065200480722, 1.251969733310776, 1.332403987118311, 1.4712852812874602, 1.3158278918913116, 1.3205568314840208]
Training Loss (progress: 0.20): 5.072956414183714; Norm Grads: 144.7460491347659; Sigmas: [0.04288590746458949, 0.006725802149771814, 0.0025565176847815586, 0.0022720878753748376, 0.008799760880128621, 0.15917255445060247]; Coeffs: [1.281685709972302, 1.252493209380267, 1.3331135924740112, 1.472476402673617, 1.3165266678590621, 1.321924730002629]
Training Loss (progress: 0.30): 4.974984325308414; Norm Grads: 144.45646500492103; Sigmas: [0.043091368501259913, 0.006818205734426435, 0.0025237951630653083, 0.0023491271782816697, 0.008872431139786386, 0.15969837597182715]; Coeffs: [1.2825466142409347, 1.2531275975874292, 1.3336989272308184, 1.4738314590656556, 1.3172511170786811, 1.3235453158032577]
Training Loss (progress: 0.40): 4.986006854267146; Norm Grads: 155.3000530200744; Sigmas: [0.04325292827349256, 0.006711165658818687, 0.0025026689052571995, 0.002201967525974424, 0.00867676256687394, 0.1599384272245]; Coeffs: [1.2834084412414168, 1.2538090365234762, 1.334393535299814, 1.4750630718489037, 1.3178723460217554, 1.3248065097848105]
Training Loss (progress: 0.50): 4.817254933172118; Norm Grads: 145.27395619979728; Sigmas: [0.042938153372599853, 0.006913782933826789, 0.0025481587441937956, 0.002267618001407536, 0.008766805047368471, 0.15977608701792528]; Coeffs: [1.2836608793918904, 1.2546449669332698, 1.3350636021663782, 1.4763043354182703, 1.318534142696724, 1.325449201117147]
Training Loss (progress: 0.60): 4.903501305927665; Norm Grads: 150.82363877330553; Sigmas: [0.042852979817643806, 0.006844970366866536, 0.0026238900349113427, 0.0022435351357605027, 0.00879214708075247, 0.16017639094437125]; Coeffs: [1.2843739965816494, 1.2550312081814992, 1.3356063995430696, 1.4773674146102218, 1.3193899592219676, 1.3265702304478462]
Training Loss (progress: 0.70): 5.0591975579678; Norm Grads: 156.6924938320779; Sigmas: [0.04299542298455857, 0.0067171701221221776, 0.002529130213727649, 0.002242174002229669, 0.008791527210226769, 0.16067156711219718]; Coeffs: [1.2850401545430474, 1.2556136927395478, 1.3361523482711108, 1.478360848251507, 1.3200225165042667, 1.327623437135951]
Training Loss (progress: 0.80): 4.914241755741058; Norm Grads: 159.0908056647082; Sigmas: [0.042756446963450906, 0.006701218030337897, 0.00251411144222564, 0.002196431265208504, 0.008738307259454318, 0.16154804670938788]; Coeffs: [1.2857006949137462, 1.2560516693388533, 1.33704042636329, 1.47936536571436, 1.3208205405007798, 1.3291236865876968]
Training Loss (progress: 0.90): 4.7857039262387095; Norm Grads: 145.53264661710537; Sigmas: [0.04307209518375272, 0.006844140659364257, 0.002654142420852575, 0.0022511233386447887, 0.008589937299079867, 0.16196781341451533]; Coeffs: [1.2864032394810219, 1.2567894196062461, 1.3376435010247107, 1.480571566686008, 1.3214471760815263, 1.3301743119613967]
Evaluation on validation dataset:
Step 5, mean loss 18.977199557264875
Step 10, mean loss 22.648839750829033
Step 15, mean loss 22.45731147058407
Step 20, mean loss 32.08995936160464
Step 25, mean loss 38.06261252363569
Step 30, mean loss 44.46895273185612
Step 35, mean loss 43.198889681157496
Step 40, mean loss 45.861911851396506
Step 45, mean loss 52.332546200559214
Step 50, mean loss 55.902808817504216
Step 55, mean loss 57.700208518751516
Step 60, mean loss 59.5477349384538
Step 65, mean loss 58.59623410504459
Step 70, mean loss 55.10450224957355
Step 75, mean loss 51.71438033429111
Step 80, mean loss 48.07780904376247
Step 85, mean loss 47.17883060280324
Step 90, mean loss 49.220715955990535
Step 95, mean loss 51.988447482875685
Unrolled forward losses 174.75337744333882
Evaluation on test dataset:
Step 5, mean loss 20.1889097134435
Step 10, mean loss 24.009850158176825
Step 15, mean loss 23.33392280865218
Step 20, mean loss 36.106168993507836
Step 25, mean loss 44.603693154956744
Step 30, mean loss 40.971120367728616
Step 35, mean loss 48.19826711523288
Step 40, mean loss 52.61537028037522
Step 45, mean loss 59.36126950298574
Step 50, mean loss 61.21812316725407
Step 55, mean loss 60.72632860346971
Step 60, mean loss 58.442653815212196
Step 65, mean loss 59.33707343814336
Step 70, mean loss 56.684211607184224
Step 75, mean loss 52.98278557962248
Step 80, mean loss 51.137710533781785
Step 85, mean loss 50.415018194702625
Step 90, mean loss 53.593636926971215
Step 95, mean loss 57.240293252811604
Unrolled forward losses 181.4561273672265
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  3:21:13.244752
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 4.765306559921278; Norm Grads: 155.08191279528128; Sigmas: [0.04305180464300439, 0.006801826963558167, 0.002632433913603551, 0.0021963581930138083, 0.00847181050085099, 0.16226826967870808]; Coeffs: [1.2870009676094938, 1.2573747698980813, 1.3382358916954893, 1.4816067999975202, 1.3220226609127523, 1.3313139105211464]
Training Loss (progress: 0.10): 4.9111805837055655; Norm Grads: 155.19138400521524; Sigmas: [0.0430288693434171, 0.006863801568841158, 0.002495222919187534, 0.002321658682630344, 0.008749932016094131, 0.1624395837080701]; Coeffs: [1.2872117015392963, 1.257852086511183, 1.3390113327998143, 1.4829308344050685, 1.3229488601879467, 1.3324096882181944]
Training Loss (progress: 0.20): 4.951094526586005; Norm Grads: 158.67070949466995; Sigmas: [0.04295539289377758, 0.006890116599600474, 0.0024864551991968433, 0.0021973328857911724, 0.008699316662381358, 0.16333279412070692]; Coeffs: [1.2880023793462154, 1.2584060392247618, 1.339818279267526, 1.483599222575141, 1.3234135349333487, 1.3337481161852947]
Training Loss (progress: 0.30): 5.074159007975312; Norm Grads: 156.42273606541815; Sigmas: [0.043435338742317524, 0.006821054727689497, 0.0025785066448507565, 0.0022098790493937804, 0.008723060561871053, 0.16325591518367355]; Coeffs: [1.2890085405274823, 1.2589464456961492, 1.340553174420918, 1.4850723656195095, 1.324107413687807, 1.334681967440505]
Training Loss (progress: 0.40): 4.8623862508901485; Norm Grads: 164.15740300238565; Sigmas: [0.043408447508347346, 0.0068385399960866795, 0.0025931556785483913, 0.002215926012383639, 0.008798924706305139, 0.1635433460038317]; Coeffs: [1.2896714979174744, 1.259369424704356, 1.3411313081807599, 1.4859444718793444, 1.3249669154258583, 1.3355464303081424]
Training Loss (progress: 0.50): 4.951349855089809; Norm Grads: 167.2654349072187; Sigmas: [0.04319465508658585, 0.006995175404452585, 0.0024417220219759518, 0.002147027715987384, 0.008667964093772155, 0.1635845586623959]; Coeffs: [1.290002964116579, 1.2601421418613683, 1.3414272393385127, 1.4870793594313987, 1.3252389539622356, 1.3367096846015771]
Training Loss (progress: 0.60): 4.7592513678224595; Norm Grads: 172.47190174616335; Sigmas: [0.04321326222550572, 0.006900350677096014, 0.0024649625976792358, 0.002210809840987957, 0.008649190937948923, 0.16413321400471062]; Coeffs: [1.2907881109085533, 1.2607526392695279, 1.3417050195754059, 1.4879531624342692, 1.3257234377350293, 1.3379230799654405]
Training Loss (progress: 0.70): 4.678428536155076; Norm Grads: 148.69530079334032; Sigmas: [0.04311073268664585, 0.006913517764490327, 0.0026576426634862976, 0.002241905400641104, 0.00878348350772762, 0.1644074888656923]; Coeffs: [1.2914814370962724, 1.2611230349675508, 1.3428532466622385, 1.4888538554764374, 1.32657688440175, 1.3388506842237986]
Training Loss (progress: 0.80): 5.0102768433757; Norm Grads: 163.98418038395204; Sigmas: [0.04299877006609898, 0.007008869514903906, 0.0025638838770046138, 0.002252578697664709, 0.008761414656287264, 0.16484029366098663]; Coeffs: [1.2918556075022731, 1.2617220767733164, 1.3431345984350174, 1.4899276696877701, 1.3272925955445183, 1.339820712372361]
Training Loss (progress: 0.90): 4.909965230465079; Norm Grads: 157.2611984432213; Sigmas: [0.04287064607704212, 0.0068920431043722735, 0.0026037802232312143, 0.002232289743673443, 0.008685650135241493, 0.16510323749686986]; Coeffs: [1.2924158368858616, 1.2621809403759363, 1.3437406697220782, 1.49101106812887, 1.3278177328266745, 1.340778039053892]
Evaluation on validation dataset:
Step 5, mean loss 18.571449431635614
Step 10, mean loss 22.811761758655773
Step 15, mean loss 22.58960881131242
Step 20, mean loss 31.850973318437863
Step 25, mean loss 38.487998515172144
Step 30, mean loss 45.29188585192099
Step 35, mean loss 43.38329088147793
Step 40, mean loss 45.364316554664136
Step 45, mean loss 52.28478373789956
Step 50, mean loss 56.02038553118017
Step 55, mean loss 57.71565742379493
Step 60, mean loss 59.4493198327943
Step 65, mean loss 58.36934181988065
Step 70, mean loss 55.2207429105309
Step 75, mean loss 51.65536266540175
Step 80, mean loss 48.29073964496398
Step 85, mean loss 47.29402893345876
Step 90, mean loss 49.128804036146605
Step 95, mean loss 51.98971684868477
Unrolled forward losses 191.11243209105575
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 4.932824744840444; Norm Grads: 159.38844192668358; Sigmas: [0.043003806274260155, 0.007032216282851053, 0.002605169880736142, 0.002154333283375417, 0.008670534753098445, 0.16545723265527942]; Coeffs: [1.2931335689276533, 1.2629581742499694, 1.3446166062664786, 1.4923272760713537, 1.3285570170788825, 1.342036484227211]
Training Loss (progress: 0.10): 5.013310067398025; Norm Grads: 159.86119108987037; Sigmas: [0.04332922744835823, 0.006941526025716992, 0.0025957500284390046, 0.002309923777915115, 0.008787191402085705, 0.16575018897499313]; Coeffs: [1.2940987784430662, 1.2634352851574295, 1.3453720426650737, 1.493393434463633, 1.3291893130544357, 1.3429695470879806]
Training Loss (progress: 0.20): 4.9062952094871815; Norm Grads: 165.8738467037715; Sigmas: [0.04302035970935701, 0.006785073922706802, 0.0026343176100457814, 0.0022091305749089157, 0.008919145491799955, 0.16612361876462256]; Coeffs: [1.2944517154664406, 1.2638809570301, 1.3460909855505454, 1.494623993149168, 1.3300915647565152, 1.3439915644520248]
Training Loss (progress: 0.30): 4.666052837980009; Norm Grads: 158.76560185567214; Sigmas: [0.04262979476174261, 0.006926835238227851, 0.002598744159894953, 0.0022915508807647648, 0.008795876225731988, 0.1668180571527736]; Coeffs: [1.2947371193461688, 1.2645589700785649, 1.3465505313811952, 1.495654229561457, 1.3306011400815443, 1.34544972976702]
Training Loss (progress: 0.40): 4.716662063348244; Norm Grads: 167.82695077202615; Sigmas: [0.04300339244538908, 0.006911195164068883, 0.0025436273827380168, 0.0022311195811844067, 0.008758744211674628, 0.1673505926056975]; Coeffs: [1.2955617982170342, 1.2651795342892418, 1.3471535535526122, 1.4964021415737672, 1.3311682658644044, 1.3464051065000915]
Training Loss (progress: 0.50): 4.7685601623902345; Norm Grads: 175.29950934396118; Sigmas: [0.043078052443552464, 0.006910382218474874, 0.0025147829752306347, 0.002239325238687802, 0.00875501003848797, 0.16758220826725417]; Coeffs: [1.2963348202661724, 1.2656571145082884, 1.347565009765117, 1.497417258804686, 1.3317794453892264, 1.3473986527252024]
Training Loss (progress: 0.60): 4.8914053856190565; Norm Grads: 160.35098411010438; Sigmas: [0.04290787476529624, 0.006990304140376905, 0.0024435924610739035, 0.0022809676326251164, 0.008734342438900835, 0.16780393741687416]; Coeffs: [1.2964642722164166, 1.266354483175766, 1.3484570634409279, 1.4987131201983634, 1.3324443339452214, 1.348211776502902]
Training Loss (progress: 0.70): 4.688386994636274; Norm Grads: 156.41238764519866; Sigmas: [0.042483257968739016, 0.007045816171538173, 0.002619551562981904, 0.0021759544266480887, 0.008619810209022107, 0.16796780888866872]; Coeffs: [1.2968497007105055, 1.2670349461678172, 1.349087350702433, 1.4998190826171556, 1.33303979158724, 1.349211845856831]
Training Loss (progress: 0.80): 4.8225877844654095; Norm Grads: 156.5799779077415; Sigmas: [0.04229547992549476, 0.007133235955048297, 0.0026133106877762177, 0.0023117129110899128, 0.008795737423468205, 0.1682636916584592]; Coeffs: [1.2972295935648606, 1.2676364302809047, 1.34975152108458, 1.5008158374181986, 1.3337335985376568, 1.350299601205551]
Training Loss (progress: 0.90): 4.851864330637122; Norm Grads: 164.09784657189576; Sigmas: [0.04273241184095546, 0.007051612648796935, 0.002544792749904926, 0.002344054865886653, 0.00870124729032081, 0.16860518065213476]; Coeffs: [1.298140635838406, 1.268076318221564, 1.3505512200177918, 1.5019558805516977, 1.334592112826862, 1.3512174258056542]
Evaluation on validation dataset:
Step 5, mean loss 19.306587858563088
Step 10, mean loss 23.260255392276207
Step 15, mean loss 22.546774630623055
Step 20, mean loss 32.44822875481194
Step 25, mean loss 41.6800663068981
Step 30, mean loss 46.224691185618454
Step 35, mean loss 42.971156951689856
Step 40, mean loss 45.60798875774947
Step 45, mean loss 52.348796997074444
Step 50, mean loss 55.79037031723692
Step 55, mean loss 57.671243828150615
Step 60, mean loss 59.62300134902988
Step 65, mean loss 58.72378260415482
Step 70, mean loss 54.98578739469713
Step 75, mean loss 51.440036542633344
Step 80, mean loss 47.41810109381714
Step 85, mean loss 46.5187904929342
Step 90, mean loss 48.61596304155697
Step 95, mean loss 51.38091995081459
Unrolled forward losses 177.07964516686897
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 4.83346903779381; Norm Grads: 157.55149506563524; Sigmas: [0.04261660747024094, 0.007023194472003686, 0.00259542561833328, 0.00226709873691659, 0.008821243368023762, 0.16874872120650422]; Coeffs: [1.2985917062555332, 1.2688492521595638, 1.35113166736403, 1.5030842691649773, 1.3351305833297387, 1.3523314049432151]
Training Loss (progress: 0.10): 5.060458560853973; Norm Grads: 168.21922053316808; Sigmas: [0.04249486851290057, 0.007041935917295111, 0.0026808072663975268, 0.0022526197954278737, 0.008961483461673359, 0.1691233844241695]; Coeffs: [1.2992543083701518, 1.2695772263116558, 1.351785244732886, 1.5040128587868273, 1.335822730449077, 1.3533001850832882]
Training Loss (progress: 0.20): 4.923028729634461; Norm Grads: 169.90504110219317; Sigmas: [0.042468464016442074, 0.006868480790136742, 0.0027059711541283283, 0.0022286531684578377, 0.008755696833926803, 0.1697594891989592]; Coeffs: [1.2997159215275096, 1.2700681198834838, 1.3525304337987825, 1.5053230159706923, 1.3362815017123668, 1.354522344329538]
Training Loss (progress: 0.30): 4.70876388182022; Norm Grads: 179.4181720007227; Sigmas: [0.0427526130187283, 0.006992613752524428, 0.0026362303101014066, 0.0022819731047231456, 0.008737705216265703, 0.16989623793831432]; Coeffs: [1.300408804935034, 1.2707495176884613, 1.3531516109926798, 1.5062924934439392, 1.3369584120551306, 1.355318890510618]
Training Loss (progress: 0.40): 4.879518609329941; Norm Grads: 179.83433831244483; Sigmas: [0.04255161024976618, 0.007194625547337344, 0.002627625697786791, 0.0023088641012049783, 0.008988473997641726, 0.17049137755696034]; Coeffs: [1.3009584347641696, 1.271254298086663, 1.353657435142323, 1.5076204319564022, 1.337810606034622, 1.356587106734498]
Training Loss (progress: 0.50): 4.7818872674905; Norm Grads: 161.24811674970368; Sigmas: [0.042693806917803896, 0.00707437473847686, 0.0025784865939676533, 0.002194722097117014, 0.008864898548327274, 0.17039964922718331]; Coeffs: [1.3014445982369898, 1.2717124999656477, 1.3541621133264756, 1.508476095577913, 1.3382231948818448, 1.3574970282181573]
Training Loss (progress: 0.60): 4.838905613883237; Norm Grads: 174.0551489032594; Sigmas: [0.04280367322314272, 0.007267371495914017, 0.0025530720132644464, 0.0022539004212746554, 0.008959482836641417, 0.17085881729025823]; Coeffs: [1.3021647275893233, 1.272271690551191, 1.3547573145698009, 1.5094870503748576, 1.338905825848679, 1.3585856664683358]
Training Loss (progress: 0.70): 4.906708329820577; Norm Grads: 177.44814858222674; Sigmas: [0.04276386549311423, 0.006954806965057107, 0.0025616693440897753, 0.0022578788527156707, 0.008789975654314039, 0.1708653258861621]; Coeffs: [1.3025586512492109, 1.2727677747432693, 1.3554557687028053, 1.5105733487940625, 1.3393725787059512, 1.3592929278389336]
Training Loss (progress: 0.80): 4.698264467989854; Norm Grads: 175.7203162382696; Sigmas: [0.04300463237554186, 0.007078995978266445, 0.0026097651841215375, 0.0022357103228357383, 0.008807323485485985, 0.17125737676204295]; Coeffs: [1.3031309643849145, 1.273330872106542, 1.3557274630325533, 1.5115445981885796, 1.3399235547068515, 1.360586878906006]
Training Loss (progress: 0.90): 4.728939652881211; Norm Grads: 166.83961868400078; Sigmas: [0.04291590027723155, 0.007249249489622147, 0.002552565890659629, 0.0022708001204928565, 0.008930796103717744, 0.17126992762342835]; Coeffs: [1.3041381408738888, 1.2738159528910558, 1.3565036099422538, 1.512510354088655, 1.340542648749951, 1.3613468596720508]
Evaluation on validation dataset:
Step 5, mean loss 20.2286128094115
Step 10, mean loss 24.21289135495606
Step 15, mean loss 22.64076039034272
Step 20, mean loss 33.778744069967985
Step 25, mean loss 39.97880024315795
Step 30, mean loss 43.29495759968604
Step 35, mean loss 43.94298072024403
Step 40, mean loss 47.26324529569187
Step 45, mean loss 53.64185924783709
Step 50, mean loss 57.09461504270287
Step 55, mean loss 58.43485963837195
Step 60, mean loss 60.425527544121984
Step 65, mean loss 59.97619049916616
Step 70, mean loss 56.13850762472364
Step 75, mean loss 52.428359255108745
Step 80, mean loss 48.81668112066998
Step 85, mean loss 47.88591240200988
Step 90, mean loss 50.23875282112827
Step 95, mean loss 53.28936886039661
Unrolled forward losses 182.65683087931566
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 4.753245343271074; Norm Grads: 172.08367140281467; Sigmas: [0.04281164127925127, 0.0072102863832192035, 0.002567450844013334, 0.0021716852532302692, 0.00874739762619014, 0.1715845721216352]; Coeffs: [1.3044923494360106, 1.2743503882239342, 1.3570789989306953, 1.5135051532802353, 1.3409845129113989, 1.3622753805329275]
Training Loss (progress: 0.10): 4.777197842568405; Norm Grads: 173.60192073544425; Sigmas: [0.042848338821590705, 0.007134854038392408, 0.0024655539831364517, 0.002277478176797762, 0.00893493717709611, 0.17205091552590826]; Coeffs: [1.3050150542229872, 1.2751600405840078, 1.3576890193179485, 1.5146510241241338, 1.3417073719412618, 1.3634186775482409]
Training Loss (progress: 0.20): 4.9374364548343035; Norm Grads: 164.71768257096912; Sigmas: [0.042954174176292374, 0.006946311776605567, 0.0027178022650599393, 0.0022735513661559753, 0.008831002778091908, 0.17249905340102892]; Coeffs: [1.3055933819665384, 1.2754263748422108, 1.3585635652991306, 1.5157009369734937, 1.3422109713762156, 1.3644219333524292]
Training Loss (progress: 0.30): 4.978160537947789; Norm Grads: 163.6728510942149; Sigmas: [0.042756171691116236, 0.0071583681134848075, 0.0026684152738858796, 0.0023047072495712396, 0.008892495159300108, 0.17272115937492163]; Coeffs: [1.305832355712486, 1.276359196061871, 1.3590052043844194, 1.5168222581712176, 1.3427061477311888, 1.365514505300348]
Training Loss (progress: 0.40): 4.76676041630756; Norm Grads: 165.01148367871684; Sigmas: [0.04259332097778894, 0.006981565071438643, 0.0026544375508501345, 0.0023473130962206783, 0.00895859346892218, 0.1729201671494139]; Coeffs: [1.3063516953446463, 1.277036632359972, 1.3595923464714827, 1.518013725377907, 1.3435577909852294, 1.3663084781554717]
Training Loss (progress: 0.50): 4.75137601901933; Norm Grads: 163.40828146903888; Sigmas: [0.04259443755086783, 0.007182215303806621, 0.002564161756406812, 0.0022309823428033632, 0.009107487245022845, 0.17281076842229062]; Coeffs: [1.3067184881204745, 1.2775056581067288, 1.3603111378414543, 1.5189568515973133, 1.3441992896758617, 1.367367582342841]
Training Loss (progress: 0.60): 4.603603841959849; Norm Grads: 164.93206517357555; Sigmas: [0.04208974290144334, 0.007146036661249096, 0.002629183542381548, 0.002201686278032439, 0.008926700734294071, 0.17316877342949816]; Coeffs: [1.307049542015609, 1.2779450313299852, 1.3610431578760143, 1.5200251730509056, 1.3447703874493973, 1.3681605570367876]
Training Loss (progress: 0.70): 4.986275383428751; Norm Grads: 174.98127255511852; Sigmas: [0.042536358324405533, 0.007089136224580825, 0.0026142500070811497, 0.0022466680952231677, 0.008963720407790988, 0.17397576377977386]; Coeffs: [1.3079302427759165, 1.278540044476979, 1.3615794497459048, 1.5211505016759475, 1.3454029727692574, 1.3695894750710482]
Training Loss (progress: 0.80): 4.751185697252899; Norm Grads: 185.32985981857618; Sigmas: [0.04249065300813202, 0.007182856558742865, 0.0026203126503927146, 0.0022169589197922174, 0.008837680937010033, 0.1741171470526444]; Coeffs: [1.3085001535637664, 1.2792683846440622, 1.3622601901016744, 1.5219315576281713, 1.3458079813248889, 1.3704650196378474]
Training Loss (progress: 0.90): 4.922071998389694; Norm Grads: 191.3444288121777; Sigmas: [0.042427907586064524, 0.0070042093993360885, 0.0025754442114784577, 0.002151603067187787, 0.00905590754728928, 0.17447388228366983]; Coeffs: [1.308988509589435, 1.2796038982457676, 1.363106773323901, 1.5227698485338137, 1.346549465272252, 1.3713558248849953]
Evaluation on validation dataset:
Step 5, mean loss 18.458333317421836
Step 10, mean loss 22.967043598912255
Step 15, mean loss 21.890829062588686
Step 20, mean loss 32.194861434589086
Step 25, mean loss 44.23360807392393
Step 30, mean loss 49.06323410792918
Step 35, mean loss 43.959709429371415
Step 40, mean loss 45.12518780847837
Step 45, mean loss 52.01727268813271
Step 50, mean loss 55.645781632695275
Step 55, mean loss 57.59910404454229
Step 60, mean loss 59.38184196177788
Step 65, mean loss 58.46689511852142
Step 70, mean loss 54.924484493842044
Step 75, mean loss 51.36406078580081
Step 80, mean loss 47.69430234080802
Step 85, mean loss 47.150107596739204
Step 90, mean loss 49.52421587041968
Step 95, mean loss 52.87799031973737
Unrolled forward losses 179.98693672859434
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 4.880665638549194; Norm Grads: 172.89747642311124; Sigmas: [0.042562727298141076, 0.007025714701270634, 0.0026469665827975643, 0.0022873319988414085, 0.009034781646860146, 0.17469064165771866]; Coeffs: [1.309505717866025, 1.2803425801471817, 1.3635185157040643, 1.5239133082479954, 1.3472605362721704, 1.372291037894734]
Training Loss (progress: 0.10): 4.930359707314234; Norm Grads: 177.61473417844985; Sigmas: [0.0426067656289917, 0.0069845084761301045, 0.002603068942611748, 0.002250912502245448, 0.00898119468530089, 0.17497934018746347]; Coeffs: [1.3097282031731987, 1.280463610798839, 1.3637484907437933, 1.5242920831277293, 1.3475077073920347, 1.3729279923729218]
Training Loss (progress: 0.20): 4.909827190204646; Norm Grads: 184.27734024559; Sigmas: [0.04261142748778021, 0.007047799124068313, 0.0026394773074922355, 0.0022394995572498615, 0.009011945922911315, 0.17515511067239325]; Coeffs: [1.3099211913739852, 1.2806180989954545, 1.3639296396825111, 1.5246702809155765, 1.3478338567490549, 1.3735113188750512]
Training Loss (progress: 0.30): 4.824718177357052; Norm Grads: 175.13690109393093; Sigmas: [0.042625235632207485, 0.007151209861647476, 0.002619306495850327, 0.0022647107960295097, 0.008994859158737588, 0.17529932898259906]; Coeffs: [1.310118328267816, 1.2808804693988436, 1.3640956226004401, 1.5250933111141136, 1.3481265024197777, 1.3739905282803824]
Training Loss (progress: 0.40): 4.947332434760208; Norm Grads: 176.861506052385; Sigmas: [0.04254204401612752, 0.007073219043731524, 0.00257255698620852, 0.002210803244175621, 0.00896877961052511, 0.1755122757899125]; Coeffs: [1.3104163855645754, 1.280995103769391, 1.3643393609046695, 1.525314195528284, 1.348345480188498, 1.37464533039592]
Training Loss (progress: 0.50): 4.595070644461321; Norm Grads: 187.18741107857772; Sigmas: [0.04247352470195564, 0.007174354639778431, 0.002624507152753703, 0.0022699392066927123, 0.009056272342533063, 0.17565138692766066]; Coeffs: [1.3106919846481198, 1.2812806981785434, 1.364608852284714, 1.5257759625742093, 1.3487239567067077, 1.3751557854262697]
Training Loss (progress: 0.60): 4.749721947776528; Norm Grads: 180.8052831549325; Sigmas: [0.04261132965085452, 0.007181274383980198, 0.002614370130226951, 0.002264354519424608, 0.008963547620085957, 0.17562666275583974]; Coeffs: [1.3109878100570085, 1.2815725679926169, 1.3648467534478719, 1.5262526457151646, 1.3488989647172374, 1.3754962396783719]
Training Loss (progress: 0.70): 4.581295107094609; Norm Grads: 181.32071722978284; Sigmas: [0.04254283394462078, 0.007111462950748029, 0.0026734436884374084, 0.002230556336750352, 0.008972680030809267, 0.17554318751373219]; Coeffs: [1.3112517887309099, 1.2816625002230417, 1.3652837956168276, 1.52664487815167, 1.3491293221436775, 1.3758616105772654]
Training Loss (progress: 0.80): 4.851602042589716; Norm Grads: 176.46194826032539; Sigmas: [0.04251253184601154, 0.007134343247417434, 0.002674071475326278, 0.0022641033777689177, 0.00902025614168715, 0.1757116115375282]; Coeffs: [1.3114187170658436, 1.2820065331259363, 1.365460201342268, 1.5269916669373502, 1.3493858729507182, 1.3764576132692448]
Training Loss (progress: 0.90): 4.703911527408844; Norm Grads: 199.01959352334586; Sigmas: [0.04247196924248183, 0.0071561981713317195, 0.002606575440318846, 0.0022624804506336444, 0.008900301162694035, 0.17570599143510093]; Coeffs: [1.31155463963215, 1.2822969008339105, 1.3656683179911087, 1.5273406059357313, 1.3495563837135955, 1.37682353539582]
Evaluation on validation dataset:
Step 5, mean loss 19.67136205331844
Step 10, mean loss 22.991589249932154
Step 15, mean loss 21.742837010710236
Step 20, mean loss 32.25795203444733
Step 25, mean loss 47.15016951772368
Step 30, mean loss 52.037473545801
Step 35, mean loss 43.95487282581445
Step 40, mean loss 44.49026662805805
Step 45, mean loss 51.17266920992877
Step 50, mean loss 55.452188718099904
Step 55, mean loss 57.27157843179032
Step 60, mean loss 59.454203263786
Step 65, mean loss 58.57520731155778
Step 70, mean loss 55.0334541541116
Step 75, mean loss 51.52995611355995
Step 80, mean loss 47.7612779580477
Step 85, mean loss 47.19470838518842
Step 90, mean loss 49.87189326280515
Step 95, mean loss 53.40481723131322
Unrolled forward losses 171.02249337174882
Evaluation on test dataset:
Step 5, mean loss 20.324030349113734
Step 10, mean loss 24.06648185699565
Step 15, mean loss 22.83394816717886
Step 20, mean loss 36.610003532343015
Step 25, mean loss 53.20726874409715
Step 30, mean loss 48.25543996590896
Step 35, mean loss 46.86877743471304
Step 40, mean loss 52.27522154668577
Step 45, mean loss 58.81404664594487
Step 50, mean loss 60.67820905534296
Step 55, mean loss 60.19694059092187
Step 60, mean loss 58.31998659471158
Step 65, mean loss 59.37170690726987
Step 70, mean loss 56.48831244719838
Step 75, mean loss 52.70264230254617
Step 80, mean loss 51.017645720979246
Step 85, mean loss 50.37644726161972
Step 90, mean loss 54.28102587297953
Step 95, mean loss 58.67709152556111
Unrolled forward losses 182.97665310865926
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  6:14:43.231619
Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 4.812547520840794; Norm Grads: 168.41603319940552; Sigmas: [0.04251360319510486, 0.0070453752436722165, 0.0026913925265655914, 0.00222056368978219, 0.008888086895273747, 0.17590503800584015]; Coeffs: [1.311668928372019, 1.2824449750035092, 1.3660989899527876, 1.5276233735498332, 1.3498854590921245, 1.3773769985220996]
Training Loss (progress: 0.10): 4.69102858370136; Norm Grads: 179.97898284774507; Sigmas: [0.04232224799379387, 0.007101343492461337, 0.002708012526472637, 0.002189566003445227, 0.009008642811681091, 0.17589756405117854]; Coeffs: [1.311884403645343, 1.2827516485357595, 1.366311094971691, 1.5278989669079308, 1.3502545266799033, 1.3777967766772339]
Training Loss (progress: 0.20): 4.772760773331785; Norm Grads: 177.54214427755738; Sigmas: [0.042351550099428606, 0.0070959410293023216, 0.002659998733648064, 0.0022248639376860357, 0.008980781260194389, 0.17593680839403542]; Coeffs: [1.3120515522270448, 1.282954202340277, 1.3664929513521586, 1.5283984911182371, 1.3505087778833933, 1.3782244563318704]
Training Loss (progress: 0.30): 4.737509070562644; Norm Grads: 194.8326621178589; Sigmas: [0.042402172323638465, 0.007120380745436284, 0.002600536007998742, 0.0023098166608042855, 0.008916477643814964, 0.175920129242239]; Coeffs: [1.3122791985164324, 1.2831151341780445, 1.3667122631385753, 1.5288834950109345, 1.3506996027105418, 1.3786642130306306]
Training Loss (progress: 0.40): 4.973676832389579; Norm Grads: 168.63038949364238; Sigmas: [0.04254210204178452, 0.007130202074928699, 0.0026307280344442957, 0.002225301503752858, 0.008918372941673466, 0.17602742250041012]; Coeffs: [1.31257738064834, 1.283301398393403, 1.3670207193752373, 1.5290415258117807, 1.350976029765553, 1.379267701936163]
Training Loss (progress: 0.50): 4.800835782256365; Norm Grads: 180.88403631401954; Sigmas: [0.04253383511593066, 0.0071620152649225, 0.0026908287752889165, 0.002252910396955366, 0.008968644030059203, 0.1762208922563728]; Coeffs: [1.3128066705414465, 1.283536197259132, 1.3672294665693678, 1.529529273875017, 1.3512858380369803, 1.3797941896013382]
Training Loss (progress: 0.60): 4.8599632332551685; Norm Grads: 187.1245802205428; Sigmas: [0.04249457655383772, 0.007184027885811339, 0.002638253894869095, 0.0022965754550862798, 0.009015283890370004, 0.17607369996337247]; Coeffs: [1.3129695440312152, 1.2837547615958138, 1.3675387716258849, 1.5298271614285903, 1.351537156253403, 1.3800020205782175]
Training Loss (progress: 0.70): 4.8442534338282055; Norm Grads: 189.6464017067753; Sigmas: [0.042498278324301836, 0.00707872563301658, 0.002641447078528663, 0.002275834112179845, 0.009091991336997653, 0.17614158541063446]; Coeffs: [1.3132134324133238, 1.283818156135442, 1.3676788562116855, 1.5302267399071285, 1.3518718411901094, 1.3804198494523208]
Training Loss (progress: 0.80): 4.837712125893887; Norm Grads: 175.2695415799909; Sigmas: [0.04254297105480033, 0.007161157349893772, 0.00263769676644522, 0.002211676482820141, 0.008895818818138102, 0.17629403686458106]; Coeffs: [1.3133986314655133, 1.284222232678758, 1.3680186654173696, 1.530512693892237, 1.3519296775331147, 1.3808512532261832]
Training Loss (progress: 0.90): 5.070130883874143; Norm Grads: 195.25242068843144; Sigmas: [0.04271021272474185, 0.007124243314491342, 0.0026341000739633132, 0.0022707168161666836, 0.009040069607346482, 0.17652941436110026]; Coeffs: [1.3137354441086426, 1.2843709635653722, 1.3681804022738684, 1.53093509633034, 1.352409459517895, 1.3814415700710638]
Evaluation on validation dataset:
Step 5, mean loss 19.141025589195124
Step 10, mean loss 22.762302036504288
Step 15, mean loss 21.510749634650722
Step 20, mean loss 31.236268571289663
Step 25, mean loss 37.88851681298503
Step 30, mean loss 41.974211396616894
Step 35, mean loss 42.24579616919522
Step 40, mean loss 45.574455508532445
Step 45, mean loss 51.68105510648253
Step 50, mean loss 56.04203307184914
Step 55, mean loss 57.8643244713925
Step 60, mean loss 59.715915951935074
Step 65, mean loss 58.74697308290488
Step 70, mean loss 55.26668833879547
Step 75, mean loss 51.68717488901528
Step 80, mean loss 47.7215059462462
Step 85, mean loss 46.54768338060224
Step 90, mean loss 48.248588972338005
Step 95, mean loss 50.82391166784747
Unrolled forward losses 169.19753743404942
Evaluation on test dataset:
Step 5, mean loss 19.985616286907614
Step 10, mean loss 23.994369194014407
Step 15, mean loss 22.78507140505972
Step 20, mean loss 35.64485126364396
Step 25, mean loss 43.617354753585865
Step 30, mean loss 39.04366168632065
Step 35, mean loss 48.34614587252467
Step 40, mean loss 53.132211122609704
Step 45, mean loss 59.489358050858996
Step 50, mean loss 61.080113782155195
Step 55, mean loss 60.92487209017171
Step 60, mean loss 58.91308219718648
Step 65, mean loss 59.63743933356179
Step 70, mean loss 56.62150084434647
Step 75, mean loss 52.988412562999066
Step 80, mean loss 51.210676452538536
Step 85, mean loss 49.91057792731837
Step 90, mean loss 52.816679727948255
Step 95, mean loss 56.28403855602602
Unrolled forward losses 176.2137003282549
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  6:49:46.914916
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 4.57133647657376; Norm Grads: 191.02150013065892; Sigmas: [0.042750952620887385, 0.007115244995767046, 0.002564175354486953, 0.0022389534040358223, 0.00903149141118611, 0.17662624367845745]; Coeffs: [1.3139890452654803, 1.284661068984662, 1.3683607842334977, 1.531312409034898, 1.3526556794714302, 1.3817759618391223]
Training Loss (progress: 0.10): 4.719487132848544; Norm Grads: 180.14079361494726; Sigmas: [0.04265557905522156, 0.007167117693609588, 0.0026162542289664336, 0.002226336531311436, 0.009052988290202535, 0.17649021715868973]; Coeffs: [1.31419275018058, 1.2849095174298615, 1.3685546791916174, 1.5316347633556389, 1.3528209610610429, 1.382142729274155]
Training Loss (progress: 0.20): 5.030207997501234; Norm Grads: 179.17696828023685; Sigmas: [0.04261105224454966, 0.007209427359606712, 0.002635657475655819, 0.0022723829359992424, 0.009015501762171653, 0.17693445534573915]; Coeffs: [1.3142310368890402, 1.2851611606738642, 1.3688672855031274, 1.5321024531782033, 1.353047992980758, 1.3827815567004176]
Training Loss (progress: 0.30): 4.690685695644575; Norm Grads: 189.69505026580873; Sigmas: [0.042516217309873996, 0.007172286410802466, 0.0026502698397606775, 0.002250931339736272, 0.008985168267581464, 0.17697064253952888]; Coeffs: [1.3144632384701427, 1.2852427907983794, 1.3691702542932442, 1.532548915882061, 1.3532770087361652, 1.3831263631045039]
Training Loss (progress: 0.40): 4.6127944463837665; Norm Grads: 186.24101560173813; Sigmas: [0.04247843540827798, 0.007249323463844795, 0.0026822072745136725, 0.0022478003759643906, 0.009006105546725152, 0.17692780376288555]; Coeffs: [1.314770737444929, 1.2855543550840391, 1.36933813396438, 1.5329217018504102, 1.3536251567669901, 1.3834197324298965]
Training Loss (progress: 0.50): 4.78841434004564; Norm Grads: 186.3881345605853; Sigmas: [0.042388849431369786, 0.00721363131073476, 0.0026580430219481643, 0.0022295752755165494, 0.009024024515711195, 0.1770130737598326]; Coeffs: [1.314952886993601, 1.2857829556147906, 1.3694795019837886, 1.533239386811917, 1.3539364098754807, 1.3838510053665591]
Training Loss (progress: 0.60): 4.676683075531553; Norm Grads: 186.72597453829815; Sigmas: [0.04242397171408352, 0.007274374619016793, 0.00268657976524199, 0.002247979784021838, 0.00896449077627585, 0.17720607681028366]; Coeffs: [1.3152407987793466, 1.285998904594489, 1.3697466512814933, 1.5336867591834, 1.354095522867051, 1.3843212341364979]
Training Loss (progress: 0.70): 4.719493068163452; Norm Grads: 189.16187485190295; Sigmas: [0.04263428222716212, 0.007168967409539119, 0.0026585912641390896, 0.002264994229438947, 0.008933689793723486, 0.17707472911807307]; Coeffs: [1.31559506904186, 1.286126478128018, 1.3699795904513852, 1.5341677518441121, 1.3542980067849546, 1.384677824925659]
Training Loss (progress: 0.80): 4.7582358220759575; Norm Grads: 185.00044647171558; Sigmas: [0.04264228784126527, 0.007173705740219542, 0.0026061417096833943, 0.002210983508172688, 0.008990201381672667, 0.17708728423328154]; Coeffs: [1.3157544758221542, 1.2863268365663278, 1.3701059654157086, 1.534524869612827, 1.3546334544589278, 1.385034562888242]
Training Loss (progress: 0.90): 4.735455438911273; Norm Grads: 199.46474414493375; Sigmas: [0.04250328842693002, 0.007264337337670555, 0.002623316773046007, 0.0022671543413374504, 0.008945186143344315, 0.17710246024446405]; Coeffs: [1.3159641173441925, 1.2866336240460057, 1.370403950199349, 1.5349596876824378, 1.3548501360649603, 1.38539125670193]
Evaluation on validation dataset:
Step 5, mean loss 17.865444689898293
Step 10, mean loss 22.168215160571044
Step 15, mean loss 21.051710702137015
Step 20, mean loss 30.508988936427972
Step 25, mean loss 37.365248461991335
Step 30, mean loss 41.94241618735319
Step 35, mean loss 42.40102235697922
Step 40, mean loss 44.9687019368711
Step 45, mean loss 51.49557630431213
Step 50, mean loss 55.30779446933752
Step 55, mean loss 56.988274413968725
Step 60, mean loss 59.082513271963194
Step 65, mean loss 58.0018016642199
Step 70, mean loss 54.71628977525718
Step 75, mean loss 51.27124312839224
Step 80, mean loss 47.6394318513633
Step 85, mean loss 47.03512082766747
Step 90, mean loss 49.59303366572585
Step 95, mean loss 53.00283365743154
Unrolled forward losses 177.69743249903874
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 4.692527902146537; Norm Grads: 180.89307885157672; Sigmas: [0.04235551658752547, 0.00726555750059003, 0.0027141992463203582, 0.002274063263919018, 0.009008373554270725, 0.1772689008350771]; Coeffs: [1.3160228452264675, 1.286929219545401, 1.370742201670717, 1.5351996389481495, 1.355122900203982, 1.3858977350857955]
Training Loss (progress: 0.10): 4.6708905270204575; Norm Grads: 173.20485385594682; Sigmas: [0.04235507206053763, 0.007245920638932713, 0.0026577165469949837, 0.0022390628228240173, 0.008973880014928017, 0.17736147710483968]; Coeffs: [1.3162774090688742, 1.2870560289168411, 1.3709326932571493, 1.5355413873705868, 1.3552477005155534, 1.3864056789798387]
Training Loss (progress: 0.20): 4.885610995133416; Norm Grads: 172.2730128394357; Sigmas: [0.04234644351274849, 0.007237738011353525, 0.002708525396250808, 0.0022518508729791422, 0.008920985580325377, 0.1773403057444951]; Coeffs: [1.3164929161323013, 1.2873125926044924, 1.371262457164133, 1.535866842852773, 1.3554397126632471, 1.3867434639493812]
Training Loss (progress: 0.30): 4.7466920756097375; Norm Grads: 185.5877119324755; Sigmas: [0.042372711383103695, 0.007180494265587586, 0.0026097515841474917, 0.0022512328867276047, 0.009097609346828217, 0.1774264376687779]; Coeffs: [1.3167602206486806, 1.2875626248302772, 1.3713797839234803, 1.5363218379136852, 1.3559106704490784, 1.3872219825995198]
Training Loss (progress: 0.40): 4.639623835984986; Norm Grads: 193.6769598156318; Sigmas: [0.04225474330460031, 0.0071406709257477675, 0.0026252833242974647, 0.002239178175504028, 0.009010956209910949, 0.17741856131444098]; Coeffs: [1.3169856356056984, 1.2876946951173436, 1.371587636556045, 1.5367444855321144, 1.3560271298883295, 1.3877149792038268]
Training Loss (progress: 0.50): 4.937913510418097; Norm Grads: 174.43227679234664; Sigmas: [0.042113110140204794, 0.007198163910109677, 0.0026515778461108377, 0.0022573905735271084, 0.009028492291176787, 0.1774728221730783]; Coeffs: [1.3172166358941761, 1.2879045346386022, 1.3719029385961048, 1.5371060537233803, 1.3562977231813005, 1.388154305601169]
Training Loss (progress: 0.60): 4.823935257964154; Norm Grads: 171.47597614649737; Sigmas: [0.04220917506690017, 0.00720423830852819, 0.002657233572859595, 0.0022014155630663795, 0.009107677331794035, 0.1775706960620298]; Coeffs: [1.317505305585674, 1.288225295541931, 1.3721003047088096, 1.5373499651562494, 1.3567151378758089, 1.3886243379618377]
Training Loss (progress: 0.70): 4.796192388779451; Norm Grads: 193.36140026819152; Sigmas: [0.042183947415833166, 0.007169145997692936, 0.0026695322634724228, 0.0022286504009967506, 0.008941566496351265, 0.1775969608972987]; Coeffs: [1.3177221503859664, 1.288415004442763, 1.3723885860303402, 1.5376544400251766, 1.356797465601817, 1.389038524388348]
Training Loss (progress: 0.80): 4.729791580064409; Norm Grads: 186.63642035991427; Sigmas: [0.04225003066686666, 0.007196071444690708, 0.0026645482889756287, 0.002257798042739149, 0.009019324561859898, 0.17772850253736674]; Coeffs: [1.3178641457678757, 1.2886338472753973, 1.3726652499545862, 1.5381267363241269, 1.3570680977658918, 1.3895882557634824]
Training Loss (progress: 0.90): 4.946375179078097; Norm Grads: 179.8589214517365; Sigmas: [0.04209086204552175, 0.007209804093985515, 0.002620370202916967, 0.002294592623711915, 0.008887282410467587, 0.17772285945480332]; Coeffs: [1.3180509123105755, 1.2887989097720423, 1.3729405748676706, 1.5385202745422646, 1.3572487036616139, 1.3899906594649958]
Evaluation on validation dataset:
Step 5, mean loss 17.522795561536064
Step 10, mean loss 21.686766489120515
Step 15, mean loss 20.925255823653362
Step 20, mean loss 30.28755998579419
Step 25, mean loss 36.80776508534163
Step 30, mean loss 42.06093099149052
Step 35, mean loss 41.72942295251259
Step 40, mean loss 44.37867875512881
Step 45, mean loss 50.724130730089854
Step 50, mean loss 54.54634828991222
Step 55, mean loss 56.464648475496475
Step 60, mean loss 58.60732843284978
Step 65, mean loss 57.47546138142181
Step 70, mean loss 54.485982394839425
Step 75, mean loss 51.13141362452522
Step 80, mean loss 47.710220653660066
Step 85, mean loss 47.24313777466242
Step 90, mean loss 49.71194890128845
Step 95, mean loss 53.34262475984208
Unrolled forward losses 170.96063583533433
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 4.756903784878801; Norm Grads: 186.45055968571157; Sigmas: [0.042026763243747225, 0.007232602546345995, 0.0026240174675371264, 0.002270443194473991, 0.00901749468037861, 0.17759169787173057]; Coeffs: [1.3182902196560973, 1.289097007761442, 1.3730935479343487, 1.5389378732232535, 1.3576149279375813, 1.390217617612237]
Training Loss (progress: 0.10): 4.65361764937225; Norm Grads: 200.25310198339767; Sigmas: [0.04211214240331376, 0.007203438135703013, 0.0026723254023871207, 0.0022517587992797196, 0.009032278697872532, 0.17774412108017354]; Coeffs: [1.3187179737367805, 1.2892255035621856, 1.3733386320699639, 1.5392063573973847, 1.3579357360272037, 1.3907206694348402]
Training Loss (progress: 0.20): 4.644779956404501; Norm Grads: 191.83091835755982; Sigmas: [0.04213509202564637, 0.007100589569458694, 0.002591917826682111, 0.0022748156967210423, 0.008981828810071382, 0.17784076216417605]; Coeffs: [1.3188987836534114, 1.2893478272184822, 1.3735045196759454, 1.5395102055459209, 1.3580773986019816, 1.3911426412793768]
Training Loss (progress: 0.30): 4.991596199899978; Norm Grads: 180.770732599187; Sigmas: [0.04209098583346355, 0.007263311638993606, 0.002662941679540006, 0.0023148651522311376, 0.009003813456273817, 0.17809212256327894]; Coeffs: [1.3190648150352715, 1.289680227541328, 1.3737956900328192, 1.5398672418575208, 1.3583561273758553, 1.3916599533616587]
Training Loss (progress: 0.40): 4.821221907615952; Norm Grads: 177.22749026284595; Sigmas: [0.0419846176941097, 0.007235106293339556, 0.0026396824388335498, 0.002284364358195895, 0.009023859782799721, 0.17816232269282098]; Coeffs: [1.3192453303137384, 1.2898746314814302, 1.374088707520724, 1.5402515928865597, 1.358523879052852, 1.392264365002641]
Training Loss (progress: 0.50): 4.678246119390119; Norm Grads: 195.96180281306005; Sigmas: [0.04194143238534915, 0.00719408733864079, 0.0025893250619699213, 0.0021906853239041946, 0.008961197810838104, 0.17807678633318233]; Coeffs: [1.3193569627658095, 1.2900735063158428, 1.3742973627999187, 1.5406062118527182, 1.3587520128907655, 1.3924299939841507]
Training Loss (progress: 0.60): 4.838668492340301; Norm Grads: 176.86201518100322; Sigmas: [0.04201749901451923, 0.007281788326651829, 0.0026195864916429084, 0.0022333671368020102, 0.008978297921464106, 0.17804154793064086]; Coeffs: [1.319691871836398, 1.2904010510731188, 1.374529179067881, 1.5409782483651975, 1.3589750227492479, 1.3928524135977522]
Training Loss (progress: 0.70): 4.692560424322525; Norm Grads: 194.40399903074083; Sigmas: [0.041954759371263466, 0.007147343440161428, 0.002603532000997198, 0.0022472325979413866, 0.008971327677648987, 0.17807904296352484]; Coeffs: [1.3198602895974207, 1.2904771126367955, 1.374800901095636, 1.5414062636290125, 1.359262062800618, 1.3932682262263871]
Training Loss (progress: 0.80): 4.757964652622306; Norm Grads: 183.30364644772212; Sigmas: [0.041984383849291484, 0.007203802399156339, 0.0026156896302744295, 0.0022675474237069146, 0.009058834029215066, 0.17832686608041984]; Coeffs: [1.3201589884595966, 1.2907232296249018, 1.3750566183480881, 1.5419001487091362, 1.3596563479592416, 1.3938940163301572]
Training Loss (progress: 0.90): 4.8749721975118385; Norm Grads: 181.95204364955083; Sigmas: [0.042133380329325454, 0.007259206384215978, 0.0026409596435889326, 0.0022689042876581785, 0.008966883213782813, 0.17837857268521928]; Coeffs: [1.320502459349607, 1.2909672675078012, 1.3752412851331426, 1.5422666542865533, 1.3598008335842018, 1.3941723118214941]
Evaluation on validation dataset:
Step 5, mean loss 17.758717982514327
Step 10, mean loss 21.579149747357732
Step 15, mean loss 20.76539812657266
Step 20, mean loss 30.44508564885303
Step 25, mean loss 37.63679830305576
Step 30, mean loss 45.574922334147075
Step 35, mean loss 42.61433968610427
Step 40, mean loss 43.716503619598896
Step 45, mean loss 50.5669155621346
Step 50, mean loss 54.01938388043965
Step 55, mean loss 55.8123460397419
Step 60, mean loss 57.90377554766724
Step 65, mean loss 56.92578489761654
Step 70, mean loss 53.84311149809261
Step 75, mean loss 50.734804699860064
Step 80, mean loss 47.381922737279055
Step 85, mean loss 46.82338275126369
Step 90, mean loss 49.23087616309002
Step 95, mean loss 52.4607938236435
Unrolled forward losses 171.7226918423272
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 4.801395758249345; Norm Grads: 197.54134540068603; Sigmas: [0.04199160112891195, 0.007235073222123783, 0.0026263264879105783, 0.0022442150495110918, 0.008990733340638761, 0.1783653802110392]; Coeffs: [1.3205528579007766, 1.2910527137549486, 1.3754678807057348, 1.5424829352577913, 1.360053445903573, 1.394541440086155]
Training Loss (progress: 0.10): 4.738203767677711; Norm Grads: 180.63124817221043; Sigmas: [0.0418957455467115, 0.007262471029770671, 0.002636737501428177, 0.0022571435359730932, 0.00900020264647099, 0.17849720219959297]; Coeffs: [1.320531966273474, 1.2911911312709285, 1.3755957451752092, 1.5426161700048588, 1.360161874753838, 1.394815105695333]
Training Loss (progress: 0.20): 4.862220189424372; Norm Grads: 186.1569695732719; Sigmas: [0.04196479755857469, 0.0071711213467440665, 0.002612378645670931, 0.0022315205016955175, 0.008995961284526649, 0.17852921106787822]; Coeffs: [1.3206922801200038, 1.2912161724463773, 1.3756581590088814, 1.5427488158705043, 1.3602657724943965, 1.3949936879525044]
Training Loss (progress: 0.30): 4.811842797992813; Norm Grads: 183.5991306161144; Sigmas: [0.041975916671913936, 0.007182724930382859, 0.0026035975680599632, 0.00224065820277299, 0.009045253978613759, 0.17850894046945126]; Coeffs: [1.3207711688910204, 1.2913183937472283, 1.3757560600953356, 1.5429413814594066, 1.3604317151367171, 1.3951943666394448]
Training Loss (progress: 0.40): 4.680779578848207; Norm Grads: 181.00265743674012; Sigmas: [0.041899859355109086, 0.007160521025107535, 0.002671363887548145, 0.0022315724593637504, 0.009009209127657215, 0.17845080009347422]; Coeffs: [1.3207833715015418, 1.291403332108776, 1.3758792396898099, 1.5430925761556542, 1.3604647799206584, 1.395332435172364]
Training Loss (progress: 0.50): 4.727189354411626; Norm Grads: 185.61687371259612; Sigmas: [0.04190209009502263, 0.0072488499673758686, 0.002671606439241729, 0.0022355506544998066, 0.008993023941105566, 0.17855058950281963]; Coeffs: [1.3208834779318366, 1.2915382687381562, 1.3759931798075007, 1.5432452859618897, 1.3605553991083106, 1.395557762294574]
Training Loss (progress: 0.60): 4.8780563785429285; Norm Grads: 184.39425464411718; Sigmas: [0.04188227423500168, 0.007212717650611197, 0.0026229476245983436, 0.0022246000066624434, 0.009032419298184949, 0.1785743395012237]; Coeffs: [1.3209389935308502, 1.2916239034204982, 1.376026701948632, 1.5434044132768852, 1.3606803296452503, 1.3957646051249049]
Training Loss (progress: 0.70): 4.733388704555791; Norm Grads: 189.48945075340163; Sigmas: [0.041845281167861056, 0.007201541040599261, 0.0026399715713576917, 0.002278221573140007, 0.009046530003130177, 0.17861132277249128]; Coeffs: [1.3209816935077843, 1.2917181127860657, 1.3761522019064596, 1.543585796107898, 1.3608025205604803, 1.395970312844158]
Training Loss (progress: 0.80): 4.609027062234422; Norm Grads: 190.13928068130053; Sigmas: [0.04189396986629228, 0.007227150159978678, 0.002615927622522251, 0.002241252550082509, 0.009017439434077776, 0.17864593917628185]; Coeffs: [1.3210809662191636, 1.291848638625288, 1.3762482971455359, 1.5437329048261055, 1.360858963437433, 1.3961083669468366]
Training Loss (progress: 0.90): 4.66697623138333; Norm Grads: 196.6820185643737; Sigmas: [0.04191762787354624, 0.007165683958970752, 0.002659320124208281, 0.0022290966557355013, 0.008994555652697618, 0.17871215240275606]; Coeffs: [1.321193161576545, 1.291910853062815, 1.3764015937596727, 1.5438934369024118, 1.3609332635136389, 1.3963104417596077]
Evaluation on validation dataset:
Step 5, mean loss 18.585397399528468
Step 10, mean loss 21.97482913521095
Step 15, mean loss 20.89119880384216
Step 20, mean loss 30.337953337338035
Step 25, mean loss 38.14468724354836
Step 30, mean loss 45.33273228010171
Step 35, mean loss 42.481445776179925
Step 40, mean loss 44.20951430142055
Step 45, mean loss 51.01116972057443
Step 50, mean loss 55.20060623688456
Step 55, mean loss 57.192825905283314
Step 60, mean loss 59.09062796887885
Step 65, mean loss 58.30871478226932
Step 70, mean loss 54.86916008669144
Step 75, mean loss 51.33473829272558
Step 80, mean loss 47.760308578981224
Step 85, mean loss 47.06455534021468
Step 90, mean loss 49.42641607233965
Step 95, mean loss 52.99197828724901
Unrolled forward losses 166.07435293752218
Evaluation on test dataset:
Step 5, mean loss 19.554988755724455
Step 10, mean loss 23.341241460494437
Step 15, mean loss 21.987432620086715
Step 20, mean loss 34.45163855282361
Step 25, mean loss 43.941223139968
Step 30, mean loss 41.66174396016397
Step 35, mean loss 46.899494045611334
Step 40, mean loss 51.95893122718146
Step 45, mean loss 58.672230938064544
Step 50, mean loss 60.624606619198005
Step 55, mean loss 60.171298649937285
Step 60, mean loss 58.27773258298938
Step 65, mean loss 59.177333628909025
Step 70, mean loss 56.13144713830037
Step 75, mean loss 52.48203503955327
Step 80, mean loss 50.923747370428075
Step 85, mean loss 50.17942603360303
Step 90, mean loss 53.957269532390185
Step 95, mean loss 58.45526413756131
Unrolled forward losses 176.7784733915028
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  9:10:25.442473
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 4.773296933430796; Norm Grads: 183.7833261173375; Sigmas: [0.04185722403515198, 0.00724605074996916, 0.0026585532778799353, 0.0022459359393750392, 0.009068074329765, 0.1787570148753331]; Coeffs: [1.3212351249996026, 1.291992819046133, 1.3764468318721517, 1.5440276457646782, 1.3611069452568478, 1.3965793850707104]
Training Loss (progress: 0.10): 4.767691217919249; Norm Grads: 173.5574726479019; Sigmas: [0.04191410143488541, 0.0072613529890148175, 0.002619851510479888, 0.0022423111642433627, 0.009016085607396605, 0.17877400958491013]; Coeffs: [1.32136657790242, 1.292115523774354, 1.3765067911189182, 1.5442089683127667, 1.3611509148146173, 1.3967455265313218]
Training Loss (progress: 0.20): 4.605526011219902; Norm Grads: 210.06670055988803; Sigmas: [0.041942534688300004, 0.007166929116384008, 0.0026172881221611425, 0.00224965067528124, 0.008992389554607507, 0.17877749998767442]; Coeffs: [1.321449482328293, 1.2921432728824973, 1.3765666913090029, 1.5443373183844014, 1.3611946374879107, 1.3969442977280984]
Training Loss (progress: 0.30): 4.883275869333242; Norm Grads: 193.20273277712423; Sigmas: [0.04185787885795099, 0.007213237455696081, 0.0025936942265882912, 0.002263737448813786, 0.009035404723608928, 0.17881904212659355]; Coeffs: [1.3214825395914727, 1.2922549868488682, 1.3766651310510323, 1.544460643954728, 1.3613429819298755, 1.3971491373704124]
Training Loss (progress: 0.40): 4.929048351841132; Norm Grads: 184.40282321110757; Sigmas: [0.04180987457067853, 0.007163869356284313, 0.002596387540636848, 0.002238737660944454, 0.009038142154370024, 0.1789171635993065]; Coeffs: [1.3215156335530596, 1.2922893961330977, 1.3767560310364824, 1.5446304956810557, 1.3614620177524026, 1.397392031199868]
Training Loss (progress: 0.50): 4.84094673230597; Norm Grads: 193.1595931713189; Sigmas: [0.041810534660220035, 0.007193881986604392, 0.0026017118970780725, 0.0022678492674853144, 0.009042140171301704, 0.17883077408289258]; Coeffs: [1.321608963344843, 1.2923541191134675, 1.3768518307207702, 1.5447870424529222, 1.3615512030315722, 1.397506999647032]
Training Loss (progress: 0.60): 4.732094482281369; Norm Grads: 199.38013470437124; Sigmas: [0.04182660179629707, 0.007157914702439384, 0.0026327995998734065, 0.002221366507569098, 0.0090539334548408, 0.17892688739568674]; Coeffs: [1.3217208259463618, 1.2923839505045813, 1.376990816386702, 1.5448799742216612, 1.361675918219644, 1.39773727244618]
Training Loss (progress: 0.70): 4.6967073625346085; Norm Grads: 199.35333356097053; Sigmas: [0.041811234609114595, 0.007188365069074843, 0.0026294867366366058, 0.002247842302181935, 0.009068109665717356, 0.1789105021332235]; Coeffs: [1.3218205551663575, 1.2924950969293032, 1.377070016060913, 1.5450072770023426, 1.3617698708220147, 1.397901001384478]
Training Loss (progress: 0.80): 4.765909623389331; Norm Grads: 210.42837460102282; Sigmas: [0.04180318231087377, 0.0072164480070291736, 0.0026617325253930108, 0.00224673231852777, 0.00904316182813923, 0.1789452022184208]; Coeffs: [1.3218304254372477, 1.2926415496829107, 1.3771840667333728, 1.5451250194818695, 1.3618360048458147, 1.3981083153508442]
Training Loss (progress: 0.90): 4.810474307096575; Norm Grads: 188.92207860233552; Sigmas: [0.04179859566694836, 0.007189903653448829, 0.002653223742635907, 0.0022498495533053056, 0.009006498152046166, 0.17895892173348557]; Coeffs: [1.321967357559892, 1.2927034118397098, 1.3772599306333682, 1.5452806724894281, 1.3619077118892984, 1.3983145138023405]
Evaluation on validation dataset:
Step 5, mean loss 18.586946872245843
Step 10, mean loss 22.354011120054608
Step 15, mean loss 20.95359881107801
Step 20, mean loss 30.498615211508156
Step 25, mean loss 40.10768121294956
Step 30, mean loss 45.64030023821282
Step 35, mean loss 43.02260939452239
Step 40, mean loss 44.23219518713404
Step 45, mean loss 50.59019782708358
Step 50, mean loss 55.334077998877554
Step 55, mean loss 57.32656088730238
Step 60, mean loss 59.816359604574615
Step 65, mean loss 59.34625233448056
Step 70, mean loss 55.76648667878164
Step 75, mean loss 52.19371591910944
Step 80, mean loss 48.76683435922497
Step 85, mean loss 48.51241144672143
Step 90, mean loss 51.111744305574376
Step 95, mean loss 55.20974002161795
Unrolled forward losses 175.75877878525233
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 4.62835947832711; Norm Grads: 191.10029378889874; Sigmas: [0.04179000141062652, 0.0072255312599767895, 0.0026288239087071453, 0.002253700381888737, 0.009049382689470897, 0.1790372901620103]; Coeffs: [1.3220369201065492, 1.2928474295938845, 1.3773367437380575, 1.5454331370375674, 1.3620589326480173, 1.398532074510733]
Training Loss (progress: 0.10): 4.567106725517219; Norm Grads: 192.77313764736556; Sigmas: [0.04187336507528373, 0.007226816467999249, 0.0026525887626766527, 0.0022261823588152125, 0.009085572918769763, 0.17903433432076257]; Coeffs: [1.3221880906966699, 1.2929343643944167, 1.3774320952173127, 1.5455312477855276, 1.3621784176129896, 1.3986803050262195]
Training Loss (progress: 0.20): 4.546542411301475; Norm Grads: 202.66570525065612; Sigmas: [0.04180096070916521, 0.0072200125470813555, 0.0026656023495792137, 0.0022363136216095865, 0.009070319709338588, 0.17898998628809207]; Coeffs: [1.3221912089093533, 1.293033576809373, 1.3775113090528475, 1.5457427757124929, 1.362267095029826, 1.3987998551972802]
Training Loss (progress: 0.30): 4.815061770549437; Norm Grads: 190.0826844285835; Sigmas: [0.04184492169076656, 0.0072105865616450176, 0.0026803516330415117, 0.002218921558580885, 0.009043526707994411, 0.17908354763945303]; Coeffs: [1.322306453909951, 1.293098397054628, 1.377621432426266, 1.5458358395503067, 1.3623334778371827, 1.3990278743936775]
Training Loss (progress: 0.40): 4.544441115099507; Norm Grads: 193.55831378692255; Sigmas: [0.04179840183253729, 0.007147482804083939, 0.002637439936802801, 0.002240974063061471, 0.008991699686655152, 0.17906393080249425]; Coeffs: [1.3223743749243826, 1.2931288033497415, 1.377728619433781, 1.5460004254740647, 1.3623900020702997, 1.3991824577126224]
Training Loss (progress: 0.50): 4.657493991204906; Norm Grads: 192.50603026211684; Sigmas: [0.041783578299423974, 0.007223420249363489, 0.0026402902992970698, 0.0022352439267747156, 0.009040566055841746, 0.1790537835023081]; Coeffs: [1.3224346717226652, 1.2932670533938453, 1.3778078840379244, 1.546113379762208, 1.362501481859971, 1.399356923988776]
Training Loss (progress: 0.60): 4.857110649286492; Norm Grads: 181.3604859845035; Sigmas: [0.041860883691722556, 0.007230642922679072, 0.002641464497525814, 0.0022983081477583344, 0.009003552058115568, 0.1790942113426757]; Coeffs: [1.322601346705637, 1.2933651294763369, 1.377914023646728, 1.5463387141784337, 1.3626187324435215, 1.3995526438091104]
Training Loss (progress: 0.70): 4.8262145315827985; Norm Grads: 200.12891395348262; Sigmas: [0.041783318811174315, 0.0072418348808379355, 0.002635910273848965, 0.0022475003305093707, 0.009039081770964895, 0.17919653551708686]; Coeffs: [1.3226449122201671, 1.2934573954668442, 1.3780024618781959, 1.5465045919539278, 1.362734897945305, 1.3997950852498875]
Training Loss (progress: 0.80): 4.659462181856288; Norm Grads: 188.7939082602553; Sigmas: [0.0418217043305163, 0.007206374986935484, 0.002612099096458271, 0.002240407776315843, 0.009050900085778081, 0.17925606958525286]; Coeffs: [1.322766860899685, 1.2935056415738386, 1.3780762049398425, 1.5466213410558989, 1.3628577333583705, 1.399927491462204]
Training Loss (progress: 0.90): 4.652595788159342; Norm Grads: 187.04404720686475; Sigmas: [0.041905646245970415, 0.007200849895547951, 0.002590883883323725, 0.002243113896620128, 0.00902272004669078, 0.17925327462732507]; Coeffs: [1.3229481908883074, 1.2935761632363312, 1.3781500374566438, 1.546768933642656, 1.362934202840865, 1.4001051601102095]
Evaluation on validation dataset:
Step 5, mean loss 17.99552923187173
Step 10, mean loss 22.144848202091048
Step 15, mean loss 21.073063956761143
Step 20, mean loss 30.27428084760527
Step 25, mean loss 39.62777033908975
Step 30, mean loss 46.206365439714766
Step 35, mean loss 42.5057001671704
Step 40, mean loss 44.59761206835168
Step 45, mean loss 50.842659452624154
Step 50, mean loss 54.594933660439
Step 55, mean loss 56.45076683067487
Step 60, mean loss 58.67483022001613
Step 65, mean loss 57.64051423506036
Step 70, mean loss 54.32141315579685
Step 75, mean loss 50.91887049686744
Step 80, mean loss 47.4428118030643
Step 85, mean loss 47.01859820487094
Step 90, mean loss 50.15600812625682
Step 95, mean loss 53.95605576250164
Unrolled forward losses 169.41138599985123
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 4.698192767511524; Norm Grads: 197.24770275588054; Sigmas: [0.04192114970611882, 0.007168294551564735, 0.0026169053188171646, 0.002246656538064411, 0.009062323796759995, 0.1792794932217257]; Coeffs: [1.3229935339411227, 1.2936661893930506, 1.3782874315715847, 1.5469332129955216, 1.3630582977714674, 1.4002740281565755]
Training Loss (progress: 0.10): 4.576237636880315; Norm Grads: 189.69519402099897; Sigmas: [0.04195093273688137, 0.007183862469421177, 0.002651889510182492, 0.0022504677845626812, 0.009034509476490251, 0.17922855272306656]; Coeffs: [1.3231115195301284, 1.2937850372604458, 1.3784353513986765, 1.547065972267799, 1.3631056386543379, 1.400428644199139]
Training Loss (progress: 0.20): 4.752271676050849; Norm Grads: 185.8490981207108; Sigmas: [0.04195826018111086, 0.007235279449416706, 0.002677611426134455, 0.002260455011397753, 0.009026204295683541, 0.1793056053175799]; Coeffs: [1.323190925821322, 1.293944074996839, 1.3785468888008192, 1.5471944967590878, 1.3632125152945411, 1.4005956279643994]
Training Loss (progress: 0.30): 4.715413863237827; Norm Grads: 193.47477926787457; Sigmas: [0.04192699374138851, 0.007188414467515151, 0.0026554807863881673, 0.0022708705499178386, 0.009014398087098597, 0.17933237560585188]; Coeffs: [1.3232942380374748, 1.2939722464705152, 1.378612328786048, 1.547346429210294, 1.3632857683951263, 1.400769683235081]
Training Loss (progress: 0.40): 4.682246827361439; Norm Grads: 193.7024332120377; Sigmas: [0.04188366704389396, 0.007200673778402803, 0.0026174834047220956, 0.0022503607110275162, 0.009037278504980517, 0.17940228147660495]; Coeffs: [1.3233163866172393, 1.2941075763165715, 1.378638102590914, 1.5474638092269792, 1.3634220891143218, 1.4009753668552738]
Training Loss (progress: 0.50): 4.799754115722222; Norm Grads: 189.83777621124622; Sigmas: [0.04197811894957043, 0.007218750497433168, 0.0026742266203937087, 0.0022891245967441216, 0.009032727178168332, 0.17944881816923047]; Coeffs: [1.32344961710572, 1.2941547132763676, 1.3787621290163958, 1.547610094352311, 1.363519409539526, 1.4011982742883287]
Training Loss (progress: 0.60): 4.806497794862548; Norm Grads: 193.8629660019071; Sigmas: [0.04185611606228953, 0.007193736514025201, 0.0026507283525237725, 0.0022305814750004315, 0.008996294721284803, 0.17950831194246353]; Coeffs: [1.3234247755207487, 1.2942186297672127, 1.3787973474493782, 1.5476984167057817, 1.3635539576913265, 1.4013887313283804]
Training Loss (progress: 0.70): 4.561972968892681; Norm Grads: 182.24123158463084; Sigmas: [0.041871436084563715, 0.007140455203889479, 0.0026353780539404145, 0.002239269347708517, 0.009055380672031274, 0.179517094560172]; Coeffs: [1.3235618989957474, 1.2942476222981727, 1.3789410451188955, 1.5478620115713706, 1.3636804515506937, 1.401563590470464]
Training Loss (progress: 0.80): 4.945625929598438; Norm Grads: 201.7085100008578; Sigmas: [0.0418336328258514, 0.007193818310389685, 0.0026248679507600275, 0.002267863447295581, 0.009073086171050633, 0.17962370541363662]; Coeffs: [1.3236164038278173, 1.2943353763650391, 1.379022274656169, 1.5480854178804553, 1.3638495387428415, 1.4017854319555025]
Training Loss (progress: 0.90): 4.721903240590761; Norm Grads: 199.98989596971663; Sigmas: [0.041847189977118567, 0.007232034469412471, 0.002616524104307406, 0.0022378666747221803, 0.009073063606512624, 0.17956009943774917]; Coeffs: [1.3236934384536552, 1.2944277400866095, 1.3790976066948952, 1.5482228924447778, 1.3639811264731572, 1.401898529015689]
Evaluation on validation dataset:
Step 5, mean loss 17.80921511290522
Step 10, mean loss 21.75849985838017
Step 15, mean loss 20.693377854454184
Step 20, mean loss 30.06588320919702
Step 25, mean loss 37.8586631737396
Step 30, mean loss 45.720754125417244
Step 35, mean loss 42.304981753662055
Step 40, mean loss 43.56357262804468
Step 45, mean loss 50.01301205292803
Step 50, mean loss 54.309110292757246
Step 55, mean loss 56.14632182835365
Step 60, mean loss 58.2898949181434
Step 65, mean loss 57.35727376792701
Step 70, mean loss 53.95913951954246
Step 75, mean loss 50.467443066997916
Step 80, mean loss 46.99143400953787
Step 85, mean loss 46.46969829463896
Step 90, mean loss 48.99702421070036
Step 95, mean loss 52.62516304374887
Unrolled forward losses 165.7043568579496
Evaluation on test dataset:
Step 5, mean loss 18.75317634578743
Step 10, mean loss 23.031229712318243
Step 15, mean loss 21.727219845261526
Step 20, mean loss 34.19125627919564
Step 25, mean loss 43.09772323751231
Step 30, mean loss 41.612145328393595
Step 35, mean loss 45.946622656182846
Step 40, mean loss 50.92497258160725
Step 45, mean loss 57.682688743098296
Step 50, mean loss 59.68420789925966
Step 55, mean loss 59.15458772704045
Step 60, mean loss 57.41111831146322
Step 65, mean loss 58.20401522243234
Step 70, mean loss 55.26545042497393
Step 75, mean loss 51.59404549108824
Step 80, mean loss 50.059347370756825
Step 85, mean loss 49.53931407609136
Step 90, mean loss 53.38520545079726
Step 95, mean loss 57.96390995148349
Unrolled forward losses 173.9073429795871
Saved model at models/GNN_FS_resolution32_n8_tw5_unrolling2_time252115_rffsFalseTrainableKernelSigma0.001.pt

Training time:  10:55:44.686437
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 4.615523274472014; Norm Grads: 191.85590231384109; Sigmas: [0.04179131974060389, 0.0072213543166873345, 0.002660704139641519, 0.0022377942295412592, 0.008989303749737484, 0.17964110925230825]; Coeffs: [1.3237159762930841, 1.294515643377548, 1.3792246007500677, 1.5483419427962268, 1.3639932416305147, 1.4020951030117603]
Training Loss (progress: 0.10): 4.721507039090253; Norm Grads: 195.29241717669484; Sigmas: [0.04179305736302293, 0.007199423887453846, 0.0026603760797320962, 0.002225929096971511, 0.009056065248057453, 0.17961250536532922]; Coeffs: [1.3238546390776698, 1.2946075595072313, 1.3793553173141007, 1.548462888398267, 1.3641283709634016, 1.4022213504201018]
Training Loss (progress: 0.20): 4.698131655626011; Norm Grads: 188.55558791294084; Sigmas: [0.04170085085746637, 0.007187594544009501, 0.00262416021587046, 0.0022342014506580494, 0.009025944950683821, 0.17971527600609252]; Coeffs: [1.3238732436311862, 1.2946895467992754, 1.3793982387492612, 1.54859842685759, 1.3641798713323479, 1.4024220848921205]
Training Loss (progress: 0.30): 4.733040245139199; Norm Grads: 200.54354154730686; Sigmas: [0.04173470683508758, 0.007164537591026097, 0.002615155631628897, 0.002235363859627219, 0.009044321270432363, 0.17966579562832247]; Coeffs: [1.323990470346157, 1.2947433127343317, 1.379500759908042, 1.5487668356822408, 1.3643134745338243, 1.4025429397776183]
Training Loss (progress: 0.40): 4.621943581032772; Norm Grads: 180.71920063902544; Sigmas: [0.04176993897866293, 0.0071862594917257265, 0.0026665640299233, 0.0022637599477149935, 0.009042669786725091, 0.17973683482789948]; Coeffs: [1.324162504516163, 1.2948626475226221, 1.3796575431075524, 1.5489784335494956, 1.3644145568249881, 1.4028576947096123]
Training Loss (progress: 0.50): 4.709941205136931; Norm Grads: 189.57160367012372; Sigmas: [0.041799030319276856, 0.007247179701403956, 0.0026125417691097827, 0.0022740438135981146, 0.009038363341909642, 0.17962914477446382]; Coeffs: [1.3242588730937168, 1.2949889897132734, 1.3797360342241363, 1.5490938090702402, 1.3644792926846834, 1.402888323474358]
Training Loss (progress: 0.60): 4.66621604084589; Norm Grads: 188.9575202268003; Sigmas: [0.041824851866755906, 0.007212860923411032, 0.002637471769523868, 0.0022409543140582537, 0.009054976459910933, 0.17963522614497535]; Coeffs: [1.32432556530604, 1.2950719840369758, 1.3798628238937707, 1.5492215505230038, 1.3646031951335, 1.4030663113262594]
Training Loss (progress: 0.70): 4.768440739239519; Norm Grads: 210.8100163338886; Sigmas: [0.04186497059413818, 0.007156211606410452, 0.0026119211344279173, 0.0022490346017550677, 0.009035771721066748, 0.17969500646646258]; Coeffs: [1.3244193802744082, 1.2951094961658853, 1.3798985582747634, 1.5493963434480509, 1.364676120170683, 1.4032896445946008]
Training Loss (progress: 0.80): 4.72719423573855; Norm Grads: 197.1791391004283; Sigmas: [0.04179084316626712, 0.007218897691964419, 0.0026481958194594056, 0.0022499706617096463, 0.008943672417147221, 0.1795911332905732]; Coeffs: [1.324445539644908, 1.29525795837185, 1.3799938838403978, 1.5495169371858575, 1.3646871151529032, 1.4034031697780829]
Training Loss (progress: 0.90): 4.681142460748835; Norm Grads: 188.0428740381768; Sigmas: [0.04185864150399458, 0.00718930711191547, 0.0026243913394636427, 0.002254953764088753, 0.008990693296362477, 0.1795770969750219]; Coeffs: [1.3245558489606148, 1.295306915749466, 1.3800070524092911, 1.5496282751966508, 1.3648581964025093, 1.4035687244571087]
Evaluation on validation dataset:
Step 5, mean loss 17.76163267199128
Step 10, mean loss 21.7985722640921
Step 15, mean loss 20.61201427406889
Step 20, mean loss 29.964258803512088
Step 25, mean loss 35.788136361810324
Step 30, mean loss 41.559366293288434
Step 35, mean loss 41.801811350415406
Step 40, mean loss 44.031245377032405
Step 45, mean loss 50.45126605593468
Step 50, mean loss 54.07232182385481
Step 55, mean loss 55.90993121640347
Step 60, mean loss 58.005964575966615
Step 65, mean loss 57.07882808023922
Step 70, mean loss 53.943470150253034
Step 75, mean loss 50.44584507000803
Step 80, mean loss 46.755896981709704
Step 85, mean loss 46.22797266265647
Step 90, mean loss 48.91731398154309
Step 95, mean loss 52.442677800959956
Unrolled forward losses 175.9961105418874
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 4.69448442859731; Norm Grads: 190.21193094788612; Sigmas: [0.041889371920248324, 0.007219249053022119, 0.0026590092961545474, 0.002226668357547563, 0.009016204958507629, 0.17969488529183744]; Coeffs: [1.3246841575850818, 1.2954552486982613, 1.3801469668193425, 1.5497713805154094, 1.3650044369962935, 1.4038304465781029]
Training Loss (progress: 0.10): 4.681045083895323; Norm Grads: 199.621556207883; Sigmas: [0.04181617530673425, 0.007223293455122084, 0.002680562405143788, 0.0022433000395103908, 0.008974083075067567, 0.17971177994615564]; Coeffs: [1.3247128012972462, 1.295531926817075, 1.3802108249773846, 1.5499614108636945, 1.3650892944432138, 1.4040382070310553]
Training Loss (progress: 0.20): 4.547600111215732; Norm Grads: 198.54616448498254; Sigmas: [0.04180779909611848, 0.007235415045691569, 0.0026793260700499894, 0.002201361520848858, 0.009075389391490524, 0.17970137792382113]; Coeffs: [1.3248184210407579, 1.2956245432196676, 1.3802987169151903, 1.5500708432607013, 1.3652763863675361, 1.4042369387702656]
Training Loss (progress: 0.30): 4.673526435694243; Norm Grads: 197.97907298468468; Sigmas: [0.041765048043909334, 0.007260595210105273, 0.002633195980293581, 0.0022510251621523404, 0.009047397019330237, 0.17974911782816064]; Coeffs: [1.3248827325314931, 1.2956750559591632, 1.3803678311694583, 1.5502234323360389, 1.365341644125378, 1.4044507735450573]
Training Loss (progress: 0.40): 4.731744825793269; Norm Grads: 193.95228148875017; Sigmas: [0.041765721553437586, 0.007253997711172205, 0.0026533612986851746, 0.002248988782869195, 0.009025371822981194, 0.17977683715623055]; Coeffs: [1.3249861578800717, 1.2957390857408124, 1.380469992637826, 1.5503563608741846, 1.3654133843411298, 1.4046572733608653]
Training Loss (progress: 0.50): 4.447610167451437; Norm Grads: 188.48880371732628; Sigmas: [0.04178921960822205, 0.007247513509356113, 0.0026431930010499525, 0.0022531214386748567, 0.009049556809088593, 0.17975784076845253]; Coeffs: [1.3250869716658111, 1.2958170397466087, 1.3805551476014795, 1.5504797234866419, 1.365540156612192, 1.404817389233516]
Training Loss (progress: 0.60): 4.479431914872947; Norm Grads: 198.3148976285914; Sigmas: [0.0418462286284362, 0.007182767863242859, 0.0026540512666238802, 0.0022806596188950402, 0.009056489182917956, 0.1797482081240081]; Coeffs: [1.3251847861278685, 1.2958213042281406, 1.3806616823595543, 1.5506664457983577, 1.365650061810984, 1.404953435802298]
Training Loss (progress: 0.70): 4.794009847967289; Norm Grads: 217.54398622073654; Sigmas: [0.04191506169438901, 0.007237801161229768, 0.0026732892747178597, 0.002214856436386496, 0.009041046328538487, 0.1797957681651135]; Coeffs: [1.325371622323987, 1.2959475919912649, 1.3808399870718147, 1.5507666200039496, 1.3657097369871514, 1.405129333089427]
Training Loss (progress: 0.80): 4.802781582602169; Norm Grads: 192.6855630658282; Sigmas: [0.04182653591104102, 0.007256425771900996, 0.0026187291858573774, 0.0022571499492643424, 0.009098371402052285, 0.17981240620783512]; Coeffs: [1.3253636976934804, 1.296035701256043, 1.3809220979603087, 1.5509803354385616, 1.3658408957280739, 1.4052998327516093]
Training Loss (progress: 0.90): 4.640747963474016; Norm Grads: 204.0396545395262; Sigmas: [0.041784234550645595, 0.007200620565063051, 0.002651285314190749, 0.0022452431937162094, 0.009031401638413943, 0.17988094606054436]; Coeffs: [1.3254150476119693, 1.296057468140521, 1.38105370846432, 1.5511457226845324, 1.3658769118162386, 1.4055402282227394]
Evaluation on validation dataset:
Step 5, mean loss 18.09833898010762
Step 10, mean loss 22.18708576540343
Step 15, mean loss 20.848919606488785
Step 20, mean loss 30.30513665117354
Step 25, mean loss 39.472992515562204
Step 30, mean loss 45.28223419039854
Step 35, mean loss 42.64420628904948
Step 40, mean loss 44.758736273919574
Step 45, mean loss 51.341401603004996
Step 50, mean loss 55.65117966104891
Step 55, mean loss 57.51317683128465
Step 60, mean loss 59.595695299074855
Step 65, mean loss 58.8140181479119
Step 70, mean loss 55.39475639340804
Step 75, mean loss 51.83901750700768
Step 80, mean loss 48.3763753543744
Step 85, mean loss 48.118141419995794
Step 90, mean loss 50.801670096099656
Step 95, mean loss 54.73264220662189
Unrolled forward losses 171.1944503776517
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 4.5967723847507385; Norm Grads: 201.7467111583276; Sigmas: [0.041724447157475475, 0.007262026213791634, 0.0026207690535086357, 0.002263654519987185, 0.009027634373854081, 0.17986478836262884]; Coeffs: [1.3254875149474694, 1.2962011246932093, 1.3810909170442134, 1.551338819049571, 1.3659570945252995, 1.405665663370166]
Training Loss (progress: 0.10): 4.849508212690204; Norm Grads: 186.9197934417974; Sigmas: [0.04179474672707165, 0.007175919235930626, 0.002688121338249443, 0.0022598540253268434, 0.009033880133710152, 0.1798696709483389]; Coeffs: [1.3256073401226176, 1.2962149863411456, 1.3812630710859681, 1.551483261525821, 1.3660705052455362, 1.4058423891967349]
Training Loss (progress: 0.20): 4.820482728349211; Norm Grads: 195.38883365908393; Sigmas: [0.04181505458514534, 0.007173644477143923, 0.0026336154799930602, 0.0022493241426235775, 0.009087103298635173, 0.1799449038557635]; Coeffs: [1.325749639572823, 1.296283532022332, 1.3812741005709086, 1.5515656704128957, 1.366204140952024, 1.406089840539255]
Training Loss (progress: 0.30): 4.610347528335675; Norm Grads: 192.8318605776567; Sigmas: [0.04184151904484749, 0.007244457797475662, 0.0026515545981100064, 0.002274843961032954, 0.009072677352642899, 0.1799175730074518]; Coeffs: [1.325854847570768, 1.2964222512451242, 1.3813785474874787, 1.5517294772475847, 1.3662622424574944, 1.406237641446534]
Training Loss (progress: 0.40): 4.668041210396884; Norm Grads: 195.97396567615837; Sigmas: [0.04180847063882058, 0.007255043307642708, 0.002650050653235613, 0.0022556902443037065, 0.009099650884722414, 0.1799788016180457]; Coeffs: [1.3259090066737176, 1.2965390893022013, 1.3814790247662576, 1.5518371546473926, 1.3664110331521173, 1.4064199223268796]
Training Loss (progress: 0.50): 4.6124304252824535; Norm Grads: 194.957762438681; Sigmas: [0.04180313847787712, 0.0071883222918464945, 0.0026120287705541133, 0.002252218952417535, 0.009115977606507085, 0.18000853213138743]; Coeffs: [1.3260109681946124, 1.2965576806394625, 1.381535670202894, 1.5519960734804468, 1.3665484007401143, 1.4066263592472126]
Training Loss (progress: 0.60): 4.886558823877177; Norm Grads: 210.38295714170795; Sigmas: [0.04183862491619813, 0.007251987068058131, 0.002656222613959782, 0.0022424686067084314, 0.009093531906756578, 0.1799639764734675]; Coeffs: [1.3261301225941768, 1.2966826244546563, 1.3816872794021218, 1.552072519945902, 1.3665893181590585, 1.4067614223931089]
Training Loss (progress: 0.70): 4.80484117722141; Norm Grads: 197.87295654696672; Sigmas: [0.04185239731440614, 0.007274569597634104, 0.00262046731500446, 0.0022212899227089995, 0.009069657538230975, 0.17996476058655306]; Coeffs: [1.3261888052670219, 1.2967837729670844, 1.3817123841163068, 1.552222481215606, 1.3666434873571254, 1.4069479612891715]
Training Loss (progress: 0.80): 4.7215026758167165; Norm Grads: 204.1075391858485; Sigmas: [0.04181731332442962, 0.0072317930799832494, 0.0026240408627213854, 0.0022328658433139656, 0.009067777079384666, 0.1799223008630357]; Coeffs: [1.3261776195972925, 1.2968197046736343, 1.3818160517381637, 1.552343247469823, 1.3667387420783834, 1.4070607787738214]
Training Loss (progress: 0.90): 4.909522389256097; Norm Grads: 210.78839116570043; Sigmas: [0.0417696148256627, 0.007201297815288792, 0.002647278233380172, 0.002277121655137293, 0.009087582249590978, 0.1799537660483561]; Coeffs: [1.3261911664457542, 1.2968654782402451, 1.3818988387721372, 1.5525137124788286, 1.3668549884739365, 1.407300313654245]
Evaluation on validation dataset:
Step 5, mean loss 18.21671117169739
Step 10, mean loss 21.673491319121382
Step 15, mean loss 20.67308576518597
Step 20, mean loss 30.156582191390296
Step 25, mean loss 38.355081571591896
Step 30, mean loss 44.39181397582796
Step 35, mean loss 41.574436478589064
Step 40, mean loss 43.91462999842845
Step 45, mean loss 50.259348652045944
Step 50, mean loss 54.60282038136832
Step 55, mean loss 56.487587787212476
Step 60, mean loss 58.46529252100663
Step 65, mean loss 57.6203584189943
Step 70, mean loss 54.33845365140334
Step 75, mean loss 50.78258592864897
Step 80, mean loss 47.089200500139
Step 85, mean loss 46.52518677328597
Step 90, mean loss 49.02358108128256
Step 95, mean loss 52.648805780025455
Unrolled forward losses 170.34212227617854
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 4.841177710865754; Norm Grads: 202.8449949292079; Sigmas: [0.04179428508193961, 0.007224187917102841, 0.002648391480561752, 0.0022587401121552226, 0.009035472910338316, 0.17998745262349122]; Coeffs: [1.326314842248208, 1.2969473087802632, 1.3819859190465662, 1.5526113618043411, 1.366896638100851, 1.4074540339838801]
Training Loss (progress: 0.10): 4.666962944381652; Norm Grads: 208.940916128628; Sigmas: [0.041801923097275165, 0.007215903564989357, 0.0026230344122397304, 0.002261425977404148, 0.009040827604751419, 0.17996656830905658]; Coeffs: [1.3263989583956268, 1.297005413929707, 1.3820330614945675, 1.552793827325662, 1.3670071706587414, 1.407566212357943]
Training Loss (progress: 0.20): 4.7240696609506125; Norm Grads: 202.23612725245596; Sigmas: [0.04180312961120188, 0.007227043548714481, 0.0026481860400106826, 0.002314152223926944, 0.00909703692961745, 0.1800081241291242]; Coeffs: [1.3265194560300875, 1.2970996947233355, 1.3821276111496443, 1.5529911235312868, 1.3671317207998603, 1.4077765149856196]
Training Loss (progress: 0.30): 4.56415966540644; Norm Grads: 204.36877081092086; Sigmas: [0.04181744575317663, 0.007177418338706629, 0.0026422035523788814, 0.002218995070562669, 0.009069114930496915, 0.1800131010102785]; Coeffs: [1.3265982912678587, 1.29716552844452, 1.3822450496409182, 1.5530898461142983, 1.3672255131597342, 1.4079791327155755]
Training Loss (progress: 0.40): 4.761499051760542; Norm Grads: 209.42922984563748; Sigmas: [0.04176165459225898, 0.007188759445027568, 0.002641379985679215, 0.0022759295514997923, 0.009117174401863269, 0.17995816441357795]; Coeffs: [1.3266815938632899, 1.2972542233210012, 1.3823250663700613, 1.5532986381882208, 1.3673526487124517, 1.4080538372946485]
Training Loss (progress: 0.50): 4.955878006148609; Norm Grads: 209.95191290004672; Sigmas: [0.04177836744841451, 0.0072368297506317245, 0.002623487196774518, 0.002248078134457239, 0.009108022344486455, 0.17998767797845228]; Coeffs: [1.3268239857302349, 1.2973587244816207, 1.382434247388325, 1.5533622939899732, 1.367446517358844, 1.4082014662026072]
Training Loss (progress: 0.60): 4.591907379935061; Norm Grads: 213.03659279909226; Sigmas: [0.0418136742289698, 0.00722455569251128, 0.002658347707091509, 0.00224800824513736, 0.009118574576374163, 0.17996950909753814]; Coeffs: [1.326956093781341, 1.2973922155929154, 1.3825258344313534, 1.5534832483651153, 1.3675641137361, 1.4083518471036318]
Training Loss (progress: 0.70): 4.785037000984539; Norm Grads: 203.21879570988034; Sigmas: [0.041824712045878946, 0.007199364878310398, 0.0026831812793256496, 0.0022646620551711677, 0.009109658523141074, 0.18003163675576236]; Coeffs: [1.3270479753937, 1.2974675022801845, 1.3826439554973102, 1.5536464992410148, 1.3676369826553294, 1.4085825171242345]
Training Loss (progress: 0.80): 4.715893668355152; Norm Grads: 196.2684249033746; Sigmas: [0.04166850135744495, 0.007216403987500789, 0.0026448996731003446, 0.0022328643832015636, 0.009150303926797925, 0.18004360058866933]; Coeffs: [1.3270323139293656, 1.2975556127002934, 1.3826814176008322, 1.5537687331156764, 1.367769189015937, 1.4087481174626981]
Training Loss (progress: 0.90): 4.8371927715924725; Norm Grads: 191.9930791140799; Sigmas: [0.04165398166889651, 0.007202561035855592, 0.0026437990833617637, 0.0022148650694588977, 0.009102519909360526, 0.18010305576051233]; Coeffs: [1.3270799140351213, 1.2976125091853412, 1.3827904176587864, 1.5538731912891417, 1.367839478206778, 1.4089077740118234]
Evaluation on validation dataset:
Step 5, mean loss 19.464449981847856
Step 10, mean loss 22.80038918610206
Step 15, mean loss 21.757715014887218
Step 20, mean loss 31.328769571783397
Step 25, mean loss 38.43729133839939
Step 30, mean loss 43.703588276782746
Step 35, mean loss 43.27209089820343
Step 40, mean loss 45.837805847919604
Step 45, mean loss 51.7590717976704
Step 50, mean loss 55.800425279430726
Step 55, mean loss 57.53467159276336
Step 60, mean loss 59.52102680352538
Step 65, mean loss 58.65326072991393
Step 70, mean loss 55.17751789575983
Step 75, mean loss 51.75972362395656
Step 80, mean loss 48.182075761949235
Step 85, mean loss 47.745387555735746
Step 90, mean loss 50.563003936697044
Step 95, mean loss 54.61671509982874
Unrolled forward losses 171.70873703396512
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 4.576173568619526; Norm Grads: 205.44614972427806; Sigmas: [0.04169250284815775, 0.007213548363372944, 0.002612399149073267, 0.0022693744944803722, 0.009122402469363024, 0.18013542592048526]; Coeffs: [1.327152915305113, 1.2977218919107227, 1.382818596064807, 1.5540454675831799, 1.3679487923936913, 1.4090886989506313]
Training Loss (progress: 0.10): 4.781092182309575; Norm Grads: 201.3149331429954; Sigmas: [0.04175383598761892, 0.007241000269712197, 0.0026384757687964743, 0.0022494172880188766, 0.009059118074058382, 0.18009743544912152]; Coeffs: [1.327274202915395, 1.2978239602244412, 1.3829609994967529, 1.554205219540021, 1.3679615131170024, 1.4092152184409856]
Training Loss (progress: 0.20): 4.732620499670875; Norm Grads: 205.02254918192227; Sigmas: [0.04175824448261728, 0.007317356778440507, 0.0026530663193439813, 0.002230347813416162, 0.009081531535073923, 0.18010906766513665]; Coeffs: [1.3273871213522752, 1.2979253876592731, 1.3830717552780711, 1.554321231459922, 1.3680757408029731, 1.4094171950887988]
Training Loss (progress: 0.30): 4.6698118175433585; Norm Grads: 199.24332155161503; Sigmas: [0.0417407321681359, 0.0072685668531060335, 0.0025685501027135544, 0.0022259571267757025, 0.009090603682295171, 0.18004447515045593]; Coeffs: [1.3274605993813617, 1.2979689374061227, 1.3830742170446606, 1.5544684333109784, 1.368181152981351, 1.409540125743711]
Training Loss (progress: 0.40): 4.587887713336613; Norm Grads: 209.5796613156936; Sigmas: [0.04175077581594578, 0.007260347932156619, 0.002668315120168817, 0.0022633772505472574, 0.009132109138020659, 0.1801168711902353]; Coeffs: [1.3275318295934022, 1.2980401553726275, 1.3832210084002916, 1.5545910835393717, 1.3683102492420682, 1.4097723501863897]
Training Loss (progress: 0.50): 4.685447897381534; Norm Grads: 189.43945212643516; Sigmas: [0.04166459054603505, 0.007292995328302605, 0.0026639776512111905, 0.0022319123617767613, 0.009078703627648869, 0.18010862985171558]; Coeffs: [1.327577012499674, 1.2981078575989287, 1.383288716251822, 1.5547227612425614, 1.3683666901251268, 1.4098812100484601]
Training Loss (progress: 0.60): 4.661861356682605; Norm Grads: 203.49520290061835; Sigmas: [0.041723151028572186, 0.007274413954769033, 0.002628298577435457, 0.002278842699836768, 0.00910809364504326, 0.18017255391268353]; Coeffs: [1.327706436525796, 1.2981926331557845, 1.3833586824803858, 1.5549536887021755, 1.3684851774160611, 1.4101102881546737]
Training Loss (progress: 0.70): 4.878595579400733; Norm Grads: 205.30317822348826; Sigmas: [0.04177799654558011, 0.007245854855764257, 0.0026438989417732956, 0.002240989623766309, 0.009107283136706498, 0.180082887824119]; Coeffs: [1.3278186546106796, 1.2982889650085534, 1.3834508347693697, 1.5550134774538344, 1.3685818953432365, 1.4102380639437937]
Training Loss (progress: 0.80): 4.618440349326034; Norm Grads: 206.5886817777864; Sigmas: [0.041781300434994784, 0.007256864721364459, 0.0026584528239791514, 0.0022604431955680895, 0.00908071175070278, 0.18009693401586993]; Coeffs: [1.3278641989345346, 1.2983947337548882, 1.383557175303093, 1.5551792304552183, 1.3686790479693578, 1.4103490751297483]
Training Loss (progress: 0.90): 4.698146494649558; Norm Grads: 206.6009373504312; Sigmas: [0.041767428388593306, 0.007249300092161839, 0.0026643538967086678, 0.0022599727351404436, 0.00909894020806747, 0.18015768947908783]; Coeffs: [1.3279536950797375, 1.2984762038135076, 1.3837039270122575, 1.5552793316358144, 1.3687683568577256, 1.4105754994241173]
Evaluation on validation dataset:
Step 5, mean loss 19.265147793419903
Step 10, mean loss 22.672253548702813
Step 15, mean loss 21.93192693222019
Step 20, mean loss 30.814152345655323
Step 25, mean loss 37.24760329825894
Step 30, mean loss 43.19209557597608
Step 35, mean loss 43.53713379673465
Step 40, mean loss 45.5746888736995
Step 45, mean loss 51.39022979502138
Step 50, mean loss 55.60641973012969
Step 55, mean loss 57.54325406913341
Step 60, mean loss 59.37095578875976
Step 65, mean loss 58.71158424243978
Step 70, mean loss 55.1855870028495
Step 75, mean loss 51.74857717985342
Step 80, mean loss 48.00943894404997
Step 85, mean loss 47.02327381066589
Step 90, mean loss 48.99234016703711
Step 95, mean loss 52.24299310217183
Unrolled forward losses 177.53961125657477
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 4.725908685114002; Norm Grads: 195.05010144065977; Sigmas: [0.04177122559254025, 0.007310157306968937, 0.0026584655929104226, 0.002249748129542648, 0.009107884273629985, 0.18014500590788182]; Coeffs: [1.328023064857932, 1.298587771876425, 1.3838146428276088, 1.555361723687762, 1.3688271570375015, 1.4107525183569227]
Training Loss (progress: 0.10): 4.628075725329042; Norm Grads: 201.12887012206545; Sigmas: [0.04178340520153328, 0.007284228332425242, 0.0026218724616075455, 0.0022516578768514857, 0.009143315838753495, 0.18028286841634517]; Coeffs: [1.3281277852543736, 1.2986732922955768, 1.3838798370467025, 1.5555413996887304, 1.3689789434191697, 1.4109670442517808]
Training Loss (progress: 0.20): 4.755524767653983; Norm Grads: 203.82032152136907; Sigmas: [0.04181887956004897, 0.0073457913176427315, 0.0026099531983847873, 0.002249745129070567, 0.009146353363387915, 0.18030173446016096]; Coeffs: [1.328240844238359, 1.2988019053658628, 1.383946501205976, 1.5556970285771212, 1.3690827092971436, 1.4111454404283255]
Training Loss (progress: 0.30): 4.71099968234452; Norm Grads: 199.08746616574481; Sigmas: [0.04175456265753059, 0.007370632810685045, 0.002663090126389685, 0.0022449356055056816, 0.009090110460239628, 0.18031376033723545]; Coeffs: [1.3283081673323367, 1.2988708019873263, 1.3840653684287945, 1.5558261053266769, 1.3691299171322975, 1.4113401447213711]
Training Loss (progress: 0.40): 4.676090704631945; Norm Grads: 194.3684822025059; Sigmas: [0.04173985010241759, 0.007353618811821376, 0.002643276676601612, 0.002269477040034604, 0.009108079277998246, 0.18029966124296495]; Coeffs: [1.328334168767439, 1.2989536549629797, 1.3841348785138052, 1.5560164441459163, 1.3692629516986303, 1.411513666060799]
Training Loss (progress: 0.50): 4.755474615999718; Norm Grads: 196.31851992289432; Sigmas: [0.0417088053634356, 0.007262555588200674, 0.0026735354399452143, 0.002261294030216793, 0.009093070387883165, 0.18033097959114863]; Coeffs: [1.3284028888187083, 1.2989722213379795, 1.3842675206265393, 1.5561377380692336, 1.369298730691764, 1.4116371648741184]
Training Loss (progress: 0.60): 4.684475192960598; Norm Grads: 193.4041805082473; Sigmas: [0.041739206915840085, 0.00727999458349737, 0.002616669151003738, 0.0022493600292753852, 0.009133291281186187, 0.18038322927285186]; Coeffs: [1.328530027202919, 1.2990510624211373, 1.3842980402705896, 1.556259241920266, 1.3694649698215478, 1.4118705245124885]
Training Loss (progress: 0.70): 4.6567206929476885; Norm Grads: 203.9508381772651; Sigmas: [0.04172729142707223, 0.007317018801103954, 0.0026393620764794345, 0.0022380820069892626, 0.009151508717314356, 0.18045383572006132]; Coeffs: [1.328625040898773, 1.2991726883469226, 1.3843597826358542, 1.5564499176224587, 1.3696171439794176, 1.4120490583565102]
Training Loss (progress: 0.80): 4.7827912268426465; Norm Grads: 204.75959795996752; Sigmas: [0.041682580225913715, 0.007290818020581682, 0.0026397847747191006, 0.002240088700048779, 0.009151521585666742, 0.18045373092062467]; Coeffs: [1.3286717372637453, 1.2992408221565814, 1.384494199058632, 1.556552380299961, 1.3696841176342578, 1.412178270290057]
Training Loss (progress: 0.90): 4.7261502935551905; Norm Grads: 209.2483830223586; Sigmas: [0.041637515569475085, 0.007265087765187135, 0.0026372743640873278, 0.002262440827367201, 0.009174203426493036, 0.18048413046634762]; Coeffs: [1.3287588134887407, 1.2992868790562966, 1.3845495466832927, 1.5567108905587803, 1.3697713343214248, 1.4123382535775384]
Evaluation on validation dataset:
Step 5, mean loss 18.409837993853102
Step 10, mean loss 22.05940939273867
Step 15, mean loss 20.91322338793855
Step 20, mean loss 30.374704098334384
Step 25, mean loss 40.710722733535746
Step 30, mean loss 47.48431575428011
Step 35, mean loss 43.102920968455344
Step 40, mean loss 44.31436425606449
Step 45, mean loss 50.800710491895565
Step 50, mean loss 54.92830762639583
Step 55, mean loss 56.879670278334586
Step 60, mean loss 58.92531499340307
Step 65, mean loss 58.38990749576756
Step 70, mean loss 54.76975731310211
Step 75, mean loss 51.39232597949224
Step 80, mean loss 47.92464397485688
Step 85, mean loss 47.8115480189417
Step 90, mean loss 50.953143689858976
Step 95, mean loss 55.200255272933184
Unrolled forward losses 168.41644627504564
Test loss: 173.9073429795871
Training time (until epoch 18):  {datetime.timedelta(seconds=39344, microseconds=686437)}
