Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Number of parameters: 1031645
Training started at: 2024-11-15 10:13:58
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.3652888348884886
Training Loss (progress: 0.10): 0.5820930140786195
Training Loss (progress: 0.20): 0.4054168402360518
Training Loss (progress: 0.30): 0.3638536391562409
Training Loss (progress: 0.40): 0.2561187101066033
Training Loss (progress: 0.50): 0.21292204488742897
Training Loss (progress: 0.60): 0.18990948253563741
Training Loss (progress: 0.70): 0.16491321526143343
Training Loss (progress: 0.80): 0.18180138699926562
Training Loss (progress: 0.90): 0.14407383158739284
Evaluation on validation dataset:
Step 25, mean loss 0.15123999328368476
Step 50, mean loss 0.24182614462449958
Step 75, mean loss 0.20564861064632603
Step 100, mean loss 0.2924356346664216
Step 125, mean loss 0.2931901186672806
Step 150, mean loss 0.34888611147638077
Step 175, mean loss 0.43752215155464774
Step 200, mean loss 0.5536921929055342
Step 225, mean loss 0.5344137812494018
Unrolled forward losses 31.826686824073864
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.20936436570451714
Step 50, mean loss 0.26200719478494966
Step 75, mean loss 0.2785544195051106
Step 100, mean loss 0.3658848425475307
Step 125, mean loss 0.5926123503175158
Step 150, mean loss 0.34361730625905873
Step 175, mean loss 0.349108017689312
Step 200, mean loss 0.5088630610167054
Step 225, mean loss 0.626781555283004
Unrolled forward losses 33.67024080038185
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  1:26:27.277595 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.3201995680518312
Training Loss (progress: 0.10): 0.29295425620326226
Training Loss (progress: 0.20): 0.3016566681255204
Training Loss (progress: 0.30): 0.27187852462137974
Training Loss (progress: 0.40): 0.25221690544592285
Training Loss (progress: 0.50): 0.27033244236270365
Training Loss (progress: 0.60): 0.23935790663012407
Training Loss (progress: 0.70): 0.2341017467348477
Training Loss (progress: 0.80): 0.225687731089396
Training Loss (progress: 0.90): 0.22109337719425684
Evaluation on validation dataset:
Step 25, mean loss 0.16985474206514772
Step 50, mean loss 0.15404809771894007
Step 75, mean loss 0.15152099135967045
Step 100, mean loss 0.17439586750848868
Step 125, mean loss 0.19125248267491846
Step 150, mean loss 0.2458313989749207
Step 175, mean loss 0.3541552768568833
Step 200, mean loss 0.47078682277865147
Step 225, mean loss 0.42470565359620027
Unrolled forward losses 5.84777876301801
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.17391951223691074
Step 50, mean loss 0.20816519775690417
Step 75, mean loss 0.17797473375779832
Step 100, mean loss 0.26125452556388673
Step 125, mean loss 0.31657291176161606
Step 150, mean loss 0.25985274070741093
Step 175, mean loss 0.2934247136163419
Step 200, mean loss 0.4067302976312106
Step 225, mean loss 0.4983747673429977
Unrolled forward losses 7.000014733590548
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  2:59:50.405629 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.29814128728981
Training Loss (progress: 0.10): 0.2759950307785476
Training Loss (progress: 0.20): 0.30644391533807086
Training Loss (progress: 0.30): 0.28247507812719835
Training Loss (progress: 0.40): 0.2395868254854328
Training Loss (progress: 0.50): 0.2366986299242305
Training Loss (progress: 0.60): 0.26366322435591827
Training Loss (progress: 0.70): 0.2594274194000757
Training Loss (progress: 0.80): 0.26318570856990425
Training Loss (progress: 0.90): 0.25552115699444533
Evaluation on validation dataset:
Step 25, mean loss 0.14396961597365693
Step 50, mean loss 0.13445185168379525
Step 75, mean loss 0.1304653534525617
Step 100, mean loss 0.1473702511838407
Step 125, mean loss 0.1459320458944066
Step 150, mean loss 0.19625717267155873
Step 175, mean loss 0.2694885300717034
Step 200, mean loss 0.33916027351212763
Step 225, mean loss 0.2866079934302136
Unrolled forward losses 4.528648634617179
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.1463654927904371
Step 50, mean loss 0.1551147928629985
Step 75, mean loss 0.15128703486148914
Step 100, mean loss 0.1902763523429695
Step 125, mean loss 0.24560561738686743
Step 150, mean loss 0.18606465856525997
Step 175, mean loss 0.22497993112338957
Step 200, mean loss 0.27166641309139006
Step 225, mean loss 0.3623610714434111
Unrolled forward losses 4.981949096605866
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  4:39:59.183598 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.2698965890099138
Training Loss (progress: 0.10): 0.21978059420347842
Training Loss (progress: 0.20): 0.22756329011465865
Training Loss (progress: 0.30): 0.24224108508217482
Training Loss (progress: 0.40): 0.2507959495958767
Training Loss (progress: 0.50): 0.24730213686750638
Training Loss (progress: 0.60): 0.23438616445889288
Training Loss (progress: 0.70): 0.2352367304806166
Training Loss (progress: 0.80): 0.22039403525858375
Training Loss (progress: 0.90): 0.2313475541905134
Evaluation on validation dataset:
Step 25, mean loss 0.13036883661865922
Step 50, mean loss 0.10051817830751746
Step 75, mean loss 0.11099078987011798
Step 100, mean loss 0.13252189024025374
Step 125, mean loss 0.13352332891386876
Step 150, mean loss 0.18807293004338804
Step 175, mean loss 0.2837788210405541
Step 200, mean loss 0.34984655527943465
Step 225, mean loss 0.2501456230994111
Unrolled forward losses 3.5903271640936767
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.13481220038945058
Step 50, mean loss 0.13370196431465076
Step 75, mean loss 0.1379353735304049
Step 100, mean loss 0.17058588976695907
Step 125, mean loss 0.22021085801220935
Step 150, mean loss 0.1743254717669649
Step 175, mean loss 0.18784576351162785
Step 200, mean loss 0.24229329991060586
Step 225, mean loss 0.30817176062575014
Unrolled forward losses 4.178169522486597
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  6:21:17.429441 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.23101502715550584
Training Loss (progress: 0.10): 0.22038146081261206
Training Loss (progress: 0.20): 0.22705610925884137
Training Loss (progress: 0.30): 0.20752431393356227
Training Loss (progress: 0.40): 0.19780354169630238
Training Loss (progress: 0.50): 0.2286992414272968
Training Loss (progress: 0.60): 0.1983214317826822
Training Loss (progress: 0.70): 0.21657860250315797
Training Loss (progress: 0.80): 0.19923318014096744
Training Loss (progress: 0.90): 0.20635012676252248
Evaluation on validation dataset:
Step 25, mean loss 0.10931596208547623
Step 50, mean loss 0.08390606241861158
Step 75, mean loss 0.10054019356097918
Step 100, mean loss 0.11374759216645855
Step 125, mean loss 0.10821597119796843
Step 150, mean loss 0.17689221955551135
Step 175, mean loss 0.2540948111284024
Step 200, mean loss 0.323525474992544
Step 225, mean loss 0.22766274209775889
Unrolled forward losses 3.2813372365559577
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.11444551667819228
Step 50, mean loss 0.10884875345873335
Step 75, mean loss 0.11306747477866508
Step 100, mean loss 0.1507393325086342
Step 125, mean loss 0.17567202629262602
Step 150, mean loss 0.13829476487982528
Step 175, mean loss 0.17377932098305993
Step 200, mean loss 0.2167326987596453
Step 225, mean loss 0.28869641068526025
Unrolled forward losses 3.531465721675278
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  8:03:01.607867 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.18657130292940424
Training Loss (progress: 0.10): 0.181759582919312
Training Loss (progress: 0.20): 0.18229533158959607
Training Loss (progress: 0.30): 0.18799841504236722
Training Loss (progress: 0.40): 0.16719116996743158
Training Loss (progress: 0.50): 0.17432899797980184
Training Loss (progress: 0.60): 0.173632794500374
Training Loss (progress: 0.70): 0.17744873295376884
Training Loss (progress: 0.80): 0.18119397635622064
Training Loss (progress: 0.90): 0.19289540043883344
Evaluation on validation dataset:
Step 25, mean loss 0.09889197145135804
Step 50, mean loss 0.08799750660050513
Step 75, mean loss 0.09133443157434637
Step 100, mean loss 0.10168703170767447
Step 125, mean loss 0.09264355171281742
Step 150, mean loss 0.14432549547719192
Step 175, mean loss 0.23258871656039057
Step 200, mean loss 0.264077503068346
Step 225, mean loss 0.21695242668191247
Unrolled forward losses 2.987364584658735
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10266825264605636
Step 50, mean loss 0.09351441704389214
Step 75, mean loss 0.1022559502566649
Step 100, mean loss 0.1372083306518035
Step 125, mean loss 0.16738859379142806
Step 150, mean loss 0.12050188778041658
Step 175, mean loss 0.1504791610101363
Step 200, mean loss 0.18828138848206571
Step 225, mean loss 0.2584006581694958
Unrolled forward losses 3.3118338736725446
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  9:45:31.550989 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.17932252370995866
Training Loss (progress: 0.10): 0.18022247465343924
Training Loss (progress: 0.20): 0.16847304663706347
Training Loss (progress: 0.30): 0.16311121808274825
Training Loss (progress: 0.40): 0.17767024931636818
Training Loss (progress: 0.50): 0.17318110160630984
Training Loss (progress: 0.60): 0.1609346670270217
Training Loss (progress: 0.70): 0.17150210153928258
Training Loss (progress: 0.80): 0.15707924412021618
Training Loss (progress: 0.90): 0.1659355819178813
Evaluation on validation dataset:
Step 25, mean loss 0.095114653967695
Step 50, mean loss 0.07680001377878024
Step 75, mean loss 0.08369236108728023
Step 100, mean loss 0.09498413019986332
Step 125, mean loss 0.09063549034573028
Step 150, mean loss 0.1422934776194226
Step 175, mean loss 0.230633330755394
Step 200, mean loss 0.28240290323544415
Step 225, mean loss 0.20708769708089242
Unrolled forward losses 3.216043132412135
Unrolled forward base losses 2.927822615141285
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.17206523666924192
Training Loss (progress: 0.10): 0.15552242155251594
Training Loss (progress: 0.20): 0.1664495121566165
Training Loss (progress: 0.30): 0.16634860004521063
Training Loss (progress: 0.40): 0.1625733004434015
Training Loss (progress: 0.50): 0.17326531470073253
Training Loss (progress: 0.60): 0.16707787812624542
Training Loss (progress: 0.70): 0.17685287706240163
Training Loss (progress: 0.80): 0.14462815512012334
Training Loss (progress: 0.90): 0.1652802876706262
Evaluation on validation dataset:
Step 25, mean loss 0.08741568881477563
Step 50, mean loss 0.07396608966175314
Step 75, mean loss 0.07680958949983457
Step 100, mean loss 0.0959997617280671
Step 125, mean loss 0.09161915659810989
Step 150, mean loss 0.1379980293386003
Step 175, mean loss 0.22939109232255
Step 200, mean loss 0.27803824462171006
Step 225, mean loss 0.19634154657241149
Unrolled forward losses 2.909275743161074
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09475589331144581
Step 50, mean loss 0.08468461248027684
Step 75, mean loss 0.09440661365910144
Step 100, mean loss 0.14366831648746337
Step 125, mean loss 0.16456248964212628
Step 150, mean loss 0.11799612272435582
Step 175, mean loss 0.14942413455144377
Step 200, mean loss 0.17572378324989366
Step 225, mean loss 0.24073847412535904
Unrolled forward losses 3.249194009066346
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  13:12:30.999861 

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.1429196441795199
Training Loss (progress: 0.10): 0.1661359035879043
Training Loss (progress: 0.20): 0.16567561328970618
Training Loss (progress: 0.30): 0.16982428522364648
Training Loss (progress: 0.40): 0.1538379670460048
Training Loss (progress: 0.50): 0.16724981378901674
Training Loss (progress: 0.60): 0.15646675768102453
Training Loss (progress: 0.70): 0.1615439567102456
Training Loss (progress: 0.80): 0.15433607406073327
Training Loss (progress: 0.90): 0.16351853276645112
Evaluation on validation dataset:
Step 25, mean loss 0.08500419577000115
Step 50, mean loss 0.0670415549697068
Step 75, mean loss 0.07668001168746505
Step 100, mean loss 0.08929753008299596
Step 125, mean loss 0.08915961307992779
Step 150, mean loss 0.13118824965176554
Step 175, mean loss 0.22338227148181633
Step 200, mean loss 0.27929034139649167
Step 225, mean loss 0.19605682403832536
Unrolled forward losses 2.8490758758804517
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0920619942563354
Step 50, mean loss 0.07705352945391121
Step 75, mean loss 0.09628721072045232
Step 100, mean loss 0.13871494567229734
Step 125, mean loss 0.1538312507493964
Step 150, mean loss 0.11146135367320496
Step 175, mean loss 0.13856935979031765
Step 200, mean loss 0.17259212078963798
Step 225, mean loss 0.24875190206282427
Unrolled forward losses 3.2280535799250485
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  14:56:55.614029 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.17420670452657164
Training Loss (progress: 0.10): 0.1656846089830782
Training Loss (progress: 0.20): 0.1612543799744217
Training Loss (progress: 0.30): 0.15458099498452937
Training Loss (progress: 0.40): 0.1506719575434529
Training Loss (progress: 0.50): 0.14879561091582708
Training Loss (progress: 0.60): 0.14836553658287888
Training Loss (progress: 0.70): 0.15241320221257357
Training Loss (progress: 0.80): 0.14078906220852383
Training Loss (progress: 0.90): 0.15595299336588223
Evaluation on validation dataset:
Step 25, mean loss 0.07804951596759714
Step 50, mean loss 0.06729754648901792
Step 75, mean loss 0.07752859666073961
Step 100, mean loss 0.08892424244647412
Step 125, mean loss 0.08320402496501572
Step 150, mean loss 0.12527126322130724
Step 175, mean loss 0.21674580688640166
Step 200, mean loss 0.27453878004646093
Step 225, mean loss 0.18747688579070157
Unrolled forward losses 2.6691368919500467
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08360450132602679
Step 50, mean loss 0.07057709625014894
Step 75, mean loss 0.09182254427353309
Step 100, mean loss 0.11931476433467342
Step 125, mean loss 0.15283402170968705
Step 150, mean loss 0.10567058843973881
Step 175, mean loss 0.1305395070920196
Step 200, mean loss 0.163625860285965
Step 225, mean loss 0.23167955685377997
Unrolled forward losses 3.1050712658442463
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  16:41:36.513656 

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.1295791417526379
Training Loss (progress: 0.10): 0.13706748077380707
Training Loss (progress: 0.20): 0.13629285636438102
Training Loss (progress: 0.30): 0.1391102719176097
Training Loss (progress: 0.40): 0.13413469174576909
Training Loss (progress: 0.50): 0.14293210990953667
Training Loss (progress: 0.60): 0.1455161539227969
Training Loss (progress: 0.70): 0.13473306801825966
Training Loss (progress: 0.80): 0.1435689363545198
Training Loss (progress: 0.90): 0.14702765965231734
Evaluation on validation dataset:
Step 25, mean loss 0.07427184594153499
Step 50, mean loss 0.062497221058474
Step 75, mean loss 0.06727538737838701
Step 100, mean loss 0.07957111576286598
Step 125, mean loss 0.07679180870476626
Step 150, mean loss 0.11428056263231987
Step 175, mean loss 0.18722101796352417
Step 200, mean loss 0.2471132330353184
Step 225, mean loss 0.17963530892993146
Unrolled forward losses 2.62305040577622
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08020719921454725
Step 50, mean loss 0.06781211583728296
Step 75, mean loss 0.08481125496289624
Step 100, mean loss 0.12247300700104952
Step 125, mean loss 0.14392107717705446
Step 150, mean loss 0.1052046751250785
Step 175, mean loss 0.13139217412404314
Step 200, mean loss 0.16161997715507187
Step 225, mean loss 0.2269876742896455
Unrolled forward losses 2.9541348670989827
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  18:27:56.114799 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.12988050436734708
Training Loss (progress: 0.10): 0.13138494451399274
Training Loss (progress: 0.20): 0.1486543915622727
Training Loss (progress: 0.30): 0.14600985704144528
Training Loss (progress: 0.40): 0.1386625094012706
Training Loss (progress: 0.50): 0.1394987831030539
Training Loss (progress: 0.60): 0.14253722887586565
Training Loss (progress: 0.70): 0.13616187043870662
Training Loss (progress: 0.80): 0.14860783884556905
Training Loss (progress: 0.90): 0.13251558326133533
Evaluation on validation dataset:
Step 25, mean loss 0.07489609178085327
Step 50, mean loss 0.06146149734248063
Step 75, mean loss 0.06497272222046083
Step 100, mean loss 0.0761515126513361
Step 125, mean loss 0.07474167881276017
Step 150, mean loss 0.11187517435201819
Step 175, mean loss 0.18425845071227326
Step 200, mean loss 0.24906508304816158
Step 225, mean loss 0.1768274564451805
Unrolled forward losses 2.5138063866430294
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08082504123494466
Step 50, mean loss 0.07026762872468986
Step 75, mean loss 0.08171672772159852
Step 100, mean loss 0.12156854939834638
Step 125, mean loss 0.14356292271988297
Step 150, mean loss 0.10143160230771066
Step 175, mean loss 0.1311156707716038
Step 200, mean loss 0.16266620702168444
Step 225, mean loss 0.22682865950219977
Unrolled forward losses 2.8225722990846425
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  20:15:02.492633 

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.13947613611785464
Training Loss (progress: 0.10): 0.136219288442491
Training Loss (progress: 0.20): 0.14143536046124808
Training Loss (progress: 0.30): 0.1381940412865703
Training Loss (progress: 0.40): 0.12837674995578835
Training Loss (progress: 0.50): 0.1319807796506016
Training Loss (progress: 0.60): 0.12319138384665738
Training Loss (progress: 0.70): 0.14100205316142797
Training Loss (progress: 0.80): 0.14365033271143735
Training Loss (progress: 0.90): 0.14664380641933872
Evaluation on validation dataset:
Step 25, mean loss 0.07062063390512198
Step 50, mean loss 0.057539013502113615
Step 75, mean loss 0.06581630246398869
Step 100, mean loss 0.07885175780006884
Step 125, mean loss 0.07711419337227073
Step 150, mean loss 0.11430133909725226
Step 175, mean loss 0.19499066393535386
Step 200, mean loss 0.2484108151910058
Step 225, mean loss 0.17925446218350144
Unrolled forward losses 2.654995468103997
Unrolled forward base losses 2.927822615141285
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.14047151818886197
Training Loss (progress: 0.10): 0.13285944951010606
Training Loss (progress: 0.20): 0.12918856529555858
Training Loss (progress: 0.30): 0.13066309127244768
Training Loss (progress: 0.40): 0.12845372762315063
Training Loss (progress: 0.50): 0.14378763992034246
Training Loss (progress: 0.60): 0.12462472185872644
Training Loss (progress: 0.70): 0.12167133989541229
Training Loss (progress: 0.80): 0.13601046136239048
Training Loss (progress: 0.90): 0.12922145467767931
Evaluation on validation dataset:
Step 25, mean loss 0.07025041996114012
Step 50, mean loss 0.058035099539654626
Step 75, mean loss 0.06447563940400564
Step 100, mean loss 0.07609165012088559
Step 125, mean loss 0.07400325321206895
Step 150, mean loss 0.11285919317503333
Step 175, mean loss 0.18779090645627294
Step 200, mean loss 0.24345442447055662
Step 225, mean loss 0.17644821341830483
Unrolled forward losses 2.5431118698495645
Unrolled forward base losses 2.927822615141285
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.12892538395726008
Training Loss (progress: 0.10): 0.13048572584982726
Training Loss (progress: 0.20): 0.1418118061662315
Training Loss (progress: 0.30): 0.12115464354254346
Training Loss (progress: 0.40): 0.1303862311426688
Training Loss (progress: 0.50): 0.1346499413195063
Training Loss (progress: 0.60): 0.1231313867738837
Training Loss (progress: 0.70): 0.14245251919546847
Training Loss (progress: 0.80): 0.12577792643293526
Training Loss (progress: 0.90): 0.13131827005516555
Evaluation on validation dataset:
Step 25, mean loss 0.0696738652365325
Step 50, mean loss 0.05897886954228701
Step 75, mean loss 0.063609608579929
Step 100, mean loss 0.0757907795067326
Step 125, mean loss 0.07501739744426535
Step 150, mean loss 0.10665879182833117
Step 175, mean loss 0.17698218862605927
Step 200, mean loss 0.23650966204332674
Step 225, mean loss 0.17473910876187215
Unrolled forward losses 2.4502064105346597
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07420744465729251
Step 50, mean loss 0.06497827929904532
Step 75, mean loss 0.07849024683837515
Step 100, mean loss 0.12202028370925219
Step 125, mean loss 0.13821248149721777
Step 150, mean loss 0.10114621671460039
Step 175, mean loss 0.12398618120019447
Step 200, mean loss 0.15534046045347066
Step 225, mean loss 0.22567337314848815
Unrolled forward losses 2.7534051801016286
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  1 day, 1:37:49.508653 

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.14051693528436687
Training Loss (progress: 0.10): 0.13241812681294968
Training Loss (progress: 0.20): 0.13630563688471825
Training Loss (progress: 0.30): 0.13091144365099627
Training Loss (progress: 0.40): 0.1340249344134771
Training Loss (progress: 0.50): 0.12545114035799917
Training Loss (progress: 0.60): 0.12157999227185227
Training Loss (progress: 0.70): 0.12617983448575512
Training Loss (progress: 0.80): 0.12025444024966334
Training Loss (progress: 0.90): 0.12813139268895654
Evaluation on validation dataset:
Step 25, mean loss 0.06714752465631277
Step 50, mean loss 0.056156176386983656
Step 75, mean loss 0.06105365842833771
Step 100, mean loss 0.07346410046155868
Step 125, mean loss 0.07131345971278097
Step 150, mean loss 0.1067233232192658
Step 175, mean loss 0.17889757825394698
Step 200, mean loss 0.23974423840226505
Step 225, mean loss 0.17252844080834945
Unrolled forward losses 2.388183357099836
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07285885563878397
Step 50, mean loss 0.06257977175873117
Step 75, mean loss 0.07795168070356788
Step 100, mean loss 0.11732026739814454
Step 125, mean loss 0.13656574315219414
Step 150, mean loss 0.09961809215679412
Step 175, mean loss 0.12387616498712745
Step 200, mean loss 0.1541477479719976
Step 225, mean loss 0.2258986995457519
Unrolled forward losses 2.733680244759372
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  1 day, 3:25:34.372974 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.12787853858322543
Training Loss (progress: 0.10): 0.1193511676057784
Training Loss (progress: 0.20): 0.12011843630862944
Training Loss (progress: 0.30): 0.12506722702889517
Training Loss (progress: 0.40): 0.13061427977337886
Training Loss (progress: 0.50): 0.11250301770285391
Training Loss (progress: 0.60): 0.11764035687513771
Training Loss (progress: 0.70): 0.12542004307252244
Training Loss (progress: 0.80): 0.1249395826116091
Training Loss (progress: 0.90): 0.12633992633277238
Evaluation on validation dataset:
Step 25, mean loss 0.06686527429245728
Step 50, mean loss 0.057270549790807423
Step 75, mean loss 0.061018265735096174
Step 100, mean loss 0.0752816878823488
Step 125, mean loss 0.07211430637618328
Step 150, mean loss 0.10940302293094162
Step 175, mean loss 0.1827695634939358
Step 200, mean loss 0.24134132434090008
Step 225, mean loss 0.17125185579452246
Unrolled forward losses 2.418228243533478
Unrolled forward base losses 2.927822615141285
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.13624780511426896
Training Loss (progress: 0.10): 0.13117304146180989
Training Loss (progress: 0.20): 0.1260076295338537
Training Loss (progress: 0.30): 0.12840991491613726
Training Loss (progress: 0.40): 0.1318269107741453
Training Loss (progress: 0.50): 0.12509256792703896
Training Loss (progress: 0.60): 0.12743975318299408
Training Loss (progress: 0.70): 0.12497223687647295
Training Loss (progress: 0.80): 0.12930258015505325
Training Loss (progress: 0.90): 0.1286587676771563
Evaluation on validation dataset:
Step 25, mean loss 0.06567105886152215
Step 50, mean loss 0.055980580403395826
Step 75, mean loss 0.06081529490226586
Step 100, mean loss 0.07261051442652142
Step 125, mean loss 0.07169393962141102
Step 150, mean loss 0.10566152561114109
Step 175, mean loss 0.1772303114572847
Step 200, mean loss 0.23649888998247576
Step 225, mean loss 0.1737605579404669
Unrolled forward losses 2.388564761134843
Unrolled forward base losses 2.927822615141285
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.1254498681903055
Training Loss (progress: 0.10): 0.13003085984479634
Training Loss (progress: 0.20): 0.12843335056106644
Training Loss (progress: 0.30): 0.12946658517373213
Training Loss (progress: 0.40): 0.1302565008277108
Training Loss (progress: 0.50): 0.1214107431996277
Training Loss (progress: 0.60): 0.12460284940167245
Training Loss (progress: 0.70): 0.13020915436250807
Training Loss (progress: 0.80): 0.12604770537469875
Training Loss (progress: 0.90): 0.12573559035066706
Evaluation on validation dataset:
Step 25, mean loss 0.0647744130798169
Step 50, mean loss 0.05476483135337975
Step 75, mean loss 0.06003100845610699
Step 100, mean loss 0.07266486981413685
Step 125, mean loss 0.07168045070777371
Step 150, mean loss 0.10577229100845655
Step 175, mean loss 0.1702946738629007
Step 200, mean loss 0.2362049500666904
Step 225, mean loss 0.17368199425417552
Unrolled forward losses 2.3912631127527733
Unrolled forward base losses 2.927822615141285
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.12586285571175224
Training Loss (progress: 0.10): 0.12466961612450167
Training Loss (progress: 0.20): 0.12048470066222365
Training Loss (progress: 0.30): 0.12588182265017442
Training Loss (progress: 0.40): 0.13184136009634423
Training Loss (progress: 0.50): 0.12171916651359235
Training Loss (progress: 0.60): 0.1353659452277103
Training Loss (progress: 0.70): 0.12447726144572019
Training Loss (progress: 0.80): 0.13296859082131404
Training Loss (progress: 0.90): 0.12267000810782629
Evaluation on validation dataset:
Step 25, mean loss 0.06437887200654634
Step 50, mean loss 0.05549502341410843
Step 75, mean loss 0.06244564224887073
Step 100, mean loss 0.07255475636490061
Step 125, mean loss 0.07091307086403958
Step 150, mean loss 0.10691944466416374
Step 175, mean loss 0.17800711319090168
Step 200, mean loss 0.23276542348023582
Step 225, mean loss 0.17157324700022059
Unrolled forward losses 2.40245194485503
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.12164197446584171
Training Loss (progress: 0.10): 0.12294052130573693
Training Loss (progress: 0.20): 0.12632260985573776
Training Loss (progress: 0.30): 0.1253870884227884
Training Loss (progress: 0.40): 0.12597744853482573
Training Loss (progress: 0.50): 0.12471130329657397
Training Loss (progress: 0.60): 0.12689749433052744
Training Loss (progress: 0.70): 0.12535977435161616
Training Loss (progress: 0.80): 0.12121592354663799
Training Loss (progress: 0.90): 0.12792996060780787
Evaluation on validation dataset:
Step 25, mean loss 0.064542414470963
Step 50, mean loss 0.05397178784715836
Step 75, mean loss 0.05905432634972038
Step 100, mean loss 0.07144719544161929
Step 125, mean loss 0.07210372528609232
Step 150, mean loss 0.10633548741186041
Step 175, mean loss 0.17749614310412182
Step 200, mean loss 0.23662298146638078
Step 225, mean loss 0.16937473416057836
Unrolled forward losses 2.4172291899961835
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.11784106178182985
Training Loss (progress: 0.10): 0.11644236843273148
Training Loss (progress: 0.20): 0.11946333135407516
Training Loss (progress: 0.30): 0.1249578605713883
Training Loss (progress: 0.40): 0.11682437817688204
Training Loss (progress: 0.50): 0.13239885361522988
Training Loss (progress: 0.60): 0.13651157220275947
Training Loss (progress: 0.70): 0.12478068698827076
Training Loss (progress: 0.80): 0.11658366759659441
Training Loss (progress: 0.90): 0.12147740735463654
Evaluation on validation dataset:
Step 25, mean loss 0.06487438922313478
Step 50, mean loss 0.056361969782888266
Step 75, mean loss 0.06102045395523205
Step 100, mean loss 0.07185420489358282
Step 125, mean loss 0.07004778562519912
Step 150, mean loss 0.10327779503791006
Step 175, mean loss 0.17259217228111368
Step 200, mean loss 0.23561658062709612
Step 225, mean loss 0.17177029118075854
Unrolled forward losses 2.416905708025247
Unrolled forward base losses 2.927822615141285
Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.11932737455399396
Training Loss (progress: 0.10): 0.12412219993163147
Training Loss (progress: 0.20): 0.12684265322001387
Training Loss (progress: 0.30): 0.12982651110626983
Training Loss (progress: 0.40): 0.12629836012173956
Training Loss (progress: 0.50): 0.12290423589790166
Training Loss (progress: 0.60): 0.11911289662563963
Training Loss (progress: 0.70): 0.12683065218061096
Training Loss (progress: 0.80): 0.12715891631283688
Training Loss (progress: 0.90): 0.11901870883097251
Evaluation on validation dataset:
Step 25, mean loss 0.06241549866352945
Step 50, mean loss 0.05319127066694862
Step 75, mean loss 0.06025180442244775
Step 100, mean loss 0.07133887139027903
Step 125, mean loss 0.06993536243865142
Step 150, mean loss 0.1056032123238202
Step 175, mean loss 0.1688912087961058
Step 200, mean loss 0.22381889551452083
Step 225, mean loss 0.17406339744509908
Unrolled forward losses 2.3986202147092417
Unrolled forward base losses 2.927822615141285
Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.1135449286099148
Training Loss (progress: 0.10): 0.11665197124015714
Training Loss (progress: 0.20): 0.12457296866660934
Training Loss (progress: 0.30): 0.12851146741826297
Training Loss (progress: 0.40): 0.12774568853582105
Training Loss (progress: 0.50): 0.11751066375191255
Training Loss (progress: 0.60): 0.1216985009567135
Training Loss (progress: 0.70): 0.11405779161491644
Training Loss (progress: 0.80): 0.12325359045202561
Training Loss (progress: 0.90): 0.1238609490521574
Evaluation on validation dataset:
Step 25, mean loss 0.061371917527638584
Step 50, mean loss 0.05420059814079904
Step 75, mean loss 0.060075263371032604
Step 100, mean loss 0.06997009867604533
Step 125, mean loss 0.06940435860786077
Step 150, mean loss 0.10358300126691314
Step 175, mean loss 0.166761452415133
Step 200, mean loss 0.23036501362894674
Step 225, mean loss 0.168401289911016
Unrolled forward losses 2.405151875521966
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.1146485337910234
Training Loss (progress: 0.10): 0.11912351452151858
Training Loss (progress: 0.20): 0.11521253313086698
Training Loss (progress: 0.30): 0.12603711962728403
Training Loss (progress: 0.40): 0.12158826335889698
Training Loss (progress: 0.50): 0.12581875642041143
Training Loss (progress: 0.60): 0.12146039552412567
Training Loss (progress: 0.70): 0.12363235622850048
Training Loss (progress: 0.80): 0.1189777967027729
Training Loss (progress: 0.90): 0.12095404344932041
Evaluation on validation dataset:
Step 25, mean loss 0.06106111274334412
Step 50, mean loss 0.054531793065379995
Step 75, mean loss 0.058994383331554115
Step 100, mean loss 0.07122679520415305
Step 125, mean loss 0.06926120635161756
Step 150, mean loss 0.1031378597601589
Step 175, mean loss 0.170326340039359
Step 200, mean loss 0.23518286576459005
Step 225, mean loss 0.172639811765523
Unrolled forward losses 2.367799807042781
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06667940686597493
Step 50, mean loss 0.0586287162582948
Step 75, mean loss 0.07344626891084793
Step 100, mean loss 0.11378499370441036
Step 125, mean loss 0.12908390817996818
Step 150, mean loss 0.09666811209855516
Step 175, mean loss 0.11666356679193371
Step 200, mean loss 0.1479230565561584
Step 225, mean loss 0.2240094260357548
Unrolled forward losses 2.6160328604405683
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11151013.pt
Training time:  1 day, 19:51:43.513868 

Test loss: 2.6160328604405683
Training time (until epoch 24):  {datetime.timedelta(days=1, seconds=71503, microseconds=513868)}
