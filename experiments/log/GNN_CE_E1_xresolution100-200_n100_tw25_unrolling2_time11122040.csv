Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Number of parameters: 1031645
Training started at: 2024-11-12 20:40:51
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.3943501279773665
Training Loss (progress: 0.10): 0.5652539585470313
Training Loss (progress: 0.20): 0.4403655073451095
Training Loss (progress: 0.30): 0.3014864373470175
Training Loss (progress: 0.40): 0.2680070261718506
Training Loss (progress: 0.50): 0.23111216198781218
Training Loss (progress: 0.60): 0.19372660167537314
Training Loss (progress: 0.70): 0.1718978364077774
Training Loss (progress: 0.80): 0.1628573523904177
Training Loss (progress: 0.90): 0.15122827057094207
Evaluation on validation dataset:
Step 25, mean loss 0.17594273042593334
Step 50, mean loss 0.21898967484759646
Step 75, mean loss 0.21094423012846752
Step 100, mean loss 0.3358823341376401
Step 125, mean loss 0.25456797534178327
Step 150, mean loss 0.35853975572598784
Step 175, mean loss 0.5550077843277719
Step 200, mean loss 0.600885351955071
Step 225, mean loss 0.6150221649673714
Unrolled forward losses 40.493896674861446
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.21044207802853795
Step 50, mean loss 0.2591362506863268
Step 75, mean loss 0.26095070887452976
Step 100, mean loss 0.34741404924947283
Step 125, mean loss 0.4366484796779415
Step 150, mean loss 0.29076501987092723
Step 175, mean loss 0.3971050588133128
Step 200, mean loss 0.6023220096780968
Step 225, mean loss 0.681224927842092
Unrolled forward losses 41.15766319145236
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1:20:00.603910 

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.3907570140602129
Training Loss (progress: 0.10): 0.34093095005312346
Training Loss (progress: 0.20): 0.32932414852187886
Training Loss (progress: 0.30): 0.3100665858862414
Training Loss (progress: 0.40): 0.31329349161699194
Training Loss (progress: 0.50): 0.25579279934148147
Training Loss (progress: 0.60): 0.2645057928394349
Training Loss (progress: 0.70): 0.2363458515177261
Training Loss (progress: 0.80): 0.22123434305708747
Training Loss (progress: 0.90): 0.21744069797898447
Evaluation on validation dataset:
Step 25, mean loss 0.1732618381999662
Step 50, mean loss 0.21688460094414996
Step 75, mean loss 0.1836749886065958
Step 100, mean loss 0.23262626316990098
Step 125, mean loss 0.2516078092781484
Step 150, mean loss 0.31603078181033073
Step 175, mean loss 0.317468944627613
Step 200, mean loss 0.3670053656068302
Step 225, mean loss 0.366275466398296
Unrolled forward losses 6.170049620754866
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.18723463939331214
Step 50, mean loss 0.2141283646264935
Step 75, mean loss 0.20976654007928297
Step 100, mean loss 0.27584725369607965
Step 125, mean loss 0.47384230735906085
Step 150, mean loss 0.27476274070966655
Step 175, mean loss 0.3100336733870365
Step 200, mean loss 0.4212524957248402
Step 225, mean loss 0.5115673727048908
Unrolled forward losses 7.859020702756835
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  2:46:11.761121 

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.3020874848070876
Training Loss (progress: 0.10): 0.29748127327997376
Training Loss (progress: 0.20): 0.2632507568216867
Training Loss (progress: 0.30): 0.2785922301790612
Training Loss (progress: 0.40): 0.30815492502015174
Training Loss (progress: 0.50): 0.27120187298557674
Training Loss (progress: 0.60): 0.28022482651450176
Training Loss (progress: 0.70): 0.25680546281044553
Training Loss (progress: 0.80): 0.2722660934567333
Training Loss (progress: 0.90): 0.2501968718782498
Evaluation on validation dataset:
Step 25, mean loss 0.17836131412375672
Step 50, mean loss 0.15440279860701633
Step 75, mean loss 0.14230726948313122
Step 100, mean loss 0.15746863230659447
Step 125, mean loss 0.18269075671577406
Step 150, mean loss 0.1977745412513042
Step 175, mean loss 0.24044603331676365
Step 200, mean loss 0.312071915702482
Step 225, mean loss 0.30665915184271697
Unrolled forward losses 4.082880840108466
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.17774481411858428
Step 50, mean loss 0.14816075829827657
Step 75, mean loss 0.15641553365493244
Step 100, mean loss 0.18178831291936454
Step 125, mean loss 0.30763585010907746
Step 150, mean loss 0.20646336667809753
Step 175, mean loss 0.22326594140226663
Step 200, mean loss 0.30702138313168914
Step 225, mean loss 0.4038517162490612
Unrolled forward losses 5.503659520123973
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  4:18:30.334753 

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.2657585098655168
Training Loss (progress: 0.10): 0.23640608978674849
Training Loss (progress: 0.20): 0.24779782265763595
Training Loss (progress: 0.30): 0.24052947286939122
Training Loss (progress: 0.40): 0.24918175624699349
Training Loss (progress: 0.50): 0.22976209864559166
Training Loss (progress: 0.60): 0.2325641310433319
Training Loss (progress: 0.70): 0.23105734586578514
Training Loss (progress: 0.80): 0.23124832197323855
Training Loss (progress: 0.90): 0.22545694388102414
Evaluation on validation dataset:
Step 25, mean loss 0.17572273274253658
Step 50, mean loss 0.13114803579349776
Step 75, mean loss 0.14666361023281946
Step 100, mean loss 0.14151499574402532
Step 125, mean loss 0.16952354452026497
Step 150, mean loss 0.18061101204348062
Step 175, mean loss 0.2348062970314606
Step 200, mean loss 0.3356558748256173
Step 225, mean loss 0.2925271752061169
Unrolled forward losses 3.89047024612834
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.17494585785025107
Step 50, mean loss 0.12736027311670706
Step 75, mean loss 0.16647003909471875
Step 100, mean loss 0.1826017009710207
Step 125, mean loss 0.29420474824816045
Step 150, mean loss 0.20222328921637828
Step 175, mean loss 0.22471107527328188
Step 200, mean loss 0.28766437311152004
Step 225, mean loss 0.3730777768708232
Unrolled forward losses 5.437908510084208
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  5:51:29.744832 

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.23020096987071312
Training Loss (progress: 0.10): 0.2202343397557734
Training Loss (progress: 0.20): 0.23068096850357678
Training Loss (progress: 0.30): 0.21174134205282108
Training Loss (progress: 0.40): 0.2009959332036055
Training Loss (progress: 0.50): 0.22184829568187248
Training Loss (progress: 0.60): 0.22769471762682328
Training Loss (progress: 0.70): 0.20836188701779565
Training Loss (progress: 0.80): 0.1978835836571481
Training Loss (progress: 0.90): 0.21247594905149478
Evaluation on validation dataset:
Step 25, mean loss 0.12462593847128609
Step 50, mean loss 0.10421549807216143
Step 75, mean loss 0.10780841461948329
Step 100, mean loss 0.10659036998894075
Step 125, mean loss 0.13738600076204094
Step 150, mean loss 0.1647834410300137
Step 175, mean loss 0.1799770426550091
Step 200, mean loss 0.29596604177885255
Step 225, mean loss 0.22694778885090494
Unrolled forward losses 2.9311642699355662
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.13123153546378152
Step 50, mean loss 0.1034546271275801
Step 75, mean loss 0.10941207054390105
Step 100, mean loss 0.14443629307575745
Step 125, mean loss 0.23860845962300226
Step 150, mean loss 0.16152650586413386
Step 175, mean loss 0.1862049802748836
Step 200, mean loss 0.23359369760590565
Step 225, mean loss 0.32284565747156574
Unrolled forward losses 3.9822623474791814
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  7:25:02.087442 

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.1887277576733614
Training Loss (progress: 0.10): 0.20073240578334048
Training Loss (progress: 0.20): 0.2101278904903557
Training Loss (progress: 0.30): 0.1731252808878426
Training Loss (progress: 0.40): 0.17303422222157616
Training Loss (progress: 0.50): 0.18211998709127566
Training Loss (progress: 0.60): 0.17663444659959823
Training Loss (progress: 0.70): 0.17035473758132783
Training Loss (progress: 0.80): 0.18132989637898647
Training Loss (progress: 0.90): 0.17415745095458032
Evaluation on validation dataset:
Step 25, mean loss 0.10617658922538226
Step 50, mean loss 0.09939118805438604
Step 75, mean loss 0.10702343072025822
Step 100, mean loss 0.10576563915558046
Step 125, mean loss 0.13194524883668377
Step 150, mean loss 0.15166196792460346
Step 175, mean loss 0.18588022984708988
Step 200, mean loss 0.30162238417525744
Step 225, mean loss 0.2190234575764683
Unrolled forward losses 2.6400476634446113
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.11174184741183862
Step 50, mean loss 0.10009109642286884
Step 75, mean loss 0.10552618169051597
Step 100, mean loss 0.13825745128049174
Step 125, mean loss 0.20375818902175813
Step 150, mean loss 0.15516525800425546
Step 175, mean loss 0.1677465117160362
Step 200, mean loss 0.20279886378998974
Step 225, mean loss 0.29220808394465425
Unrolled forward losses 3.403629183322612
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  8:58:48.895793 

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.19253549952108973
Training Loss (progress: 0.10): 0.1872702829126319
Training Loss (progress: 0.20): 0.15926303049263102
Training Loss (progress: 0.30): 0.17918260439356834
Training Loss (progress: 0.40): 0.1801487291088443
Training Loss (progress: 0.50): 0.16299400074289241
Training Loss (progress: 0.60): 0.1731259246715951
Training Loss (progress: 0.70): 0.1735610149007598
Training Loss (progress: 0.80): 0.16122079355207955
Training Loss (progress: 0.90): 0.16226136783057638
Evaluation on validation dataset:
Step 25, mean loss 0.09746968991258165
Step 50, mean loss 0.09631773797286859
Step 75, mean loss 0.09217086170140412
Step 100, mean loss 0.09838284567192938
Step 125, mean loss 0.12155006299896902
Step 150, mean loss 0.1471417695333055
Step 175, mean loss 0.18315574416911345
Step 200, mean loss 0.30915447221571674
Step 225, mean loss 0.2116536816728399
Unrolled forward losses 2.389016972464405
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.10107102540697444
Step 50, mean loss 0.08994474245505812
Step 75, mean loss 0.10287252664014347
Step 100, mean loss 0.1353270796166558
Step 125, mean loss 0.19567453234784032
Step 150, mean loss 0.1523665124004042
Step 175, mean loss 0.16796294871398038
Step 200, mean loss 0.2043385061574232
Step 225, mean loss 0.27843449957027966
Unrolled forward losses 3.0772911344725546
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  10:33:44.253971 

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.16277163580234583
Training Loss (progress: 0.10): 0.16354882030943627
Training Loss (progress: 0.20): 0.16913590513063942
Training Loss (progress: 0.30): 0.1565804179611606
Training Loss (progress: 0.40): 0.16367258003163745
Training Loss (progress: 0.50): 0.16608200864895042
Training Loss (progress: 0.60): 0.16678081513238846
Training Loss (progress: 0.70): 0.16378175064441775
Training Loss (progress: 0.80): 0.15003949237377678
Training Loss (progress: 0.90): 0.15371825211370535
Evaluation on validation dataset:
Step 25, mean loss 0.08797981757570732
Step 50, mean loss 0.09139846422972123
Step 75, mean loss 0.08617986806749667
Step 100, mean loss 0.08904609063823876
Step 125, mean loss 0.11182891358757457
Step 150, mean loss 0.14090048131625976
Step 175, mean loss 0.1608029773298159
Step 200, mean loss 0.2845644892409118
Step 225, mean loss 0.19316707963663443
Unrolled forward losses 2.29664912332561
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09366181437907574
Step 50, mean loss 0.08275691861208566
Step 75, mean loss 0.09308366164948453
Step 100, mean loss 0.12727443733092564
Step 125, mean loss 0.19206071400607494
Step 150, mean loss 0.1495300380921218
Step 175, mean loss 0.15679455557642336
Step 200, mean loss 0.19660018354653708
Step 225, mean loss 0.26876377314233085
Unrolled forward losses 2.8902971265377673
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  12:08:09.564645 

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.15430995645793835
Training Loss (progress: 0.10): 0.16639284142030977
Training Loss (progress: 0.20): 0.1668187586176563
Training Loss (progress: 0.30): 0.16701649482387024
Training Loss (progress: 0.40): 0.16596748022673943
Training Loss (progress: 0.50): 0.15952355850037442
Training Loss (progress: 0.60): 0.16591757085024678
Training Loss (progress: 0.70): 0.16051888683952084
Training Loss (progress: 0.80): 0.1585649322804465
Training Loss (progress: 0.90): 0.15470129525401358
Evaluation on validation dataset:
Step 25, mean loss 0.08344633151443251
Step 50, mean loss 0.08035353791575811
Step 75, mean loss 0.08768961438529219
Step 100, mean loss 0.08884239994888349
Step 125, mean loss 0.10981709575358979
Step 150, mean loss 0.14227479577163002
Step 175, mean loss 0.16753339302803708
Step 200, mean loss 0.29053567511188677
Step 225, mean loss 0.19032158645483135
Unrolled forward losses 2.262962506131508
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.09067774042632382
Step 50, mean loss 0.08001301324391286
Step 75, mean loss 0.09014203971069866
Step 100, mean loss 0.13292735163900815
Step 125, mean loss 0.18206472408602353
Step 150, mean loss 0.13986634357166638
Step 175, mean loss 0.14890084812659155
Step 200, mean loss 0.19833305984545113
Step 225, mean loss 0.2705331685548933
Unrolled forward losses 2.983665860181338
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  13:43:18.415173 

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.15641416619634244
Training Loss (progress: 0.10): 0.1588262293660687
Training Loss (progress: 0.20): 0.17157206407415312
Training Loss (progress: 0.30): 0.16189666061093827
Training Loss (progress: 0.40): 0.16263638663292113
Training Loss (progress: 0.50): 0.16258671867463864
Training Loss (progress: 0.60): 0.15503303596288487
Training Loss (progress: 0.70): 0.15507959677554234
Training Loss (progress: 0.80): 0.15840863077070302
Training Loss (progress: 0.90): 0.15176754073686308
Evaluation on validation dataset:
Step 25, mean loss 0.07719606677960215
Step 50, mean loss 0.09063577656347795
Step 75, mean loss 0.08102896279636068
Step 100, mean loss 0.08748821800815126
Step 125, mean loss 0.11035631118677527
Step 150, mean loss 0.14698894271834806
Step 175, mean loss 0.17032490717661947
Step 200, mean loss 0.28733318707400607
Step 225, mean loss 0.18284411667707584
Unrolled forward losses 2.543009087404668
Unrolled forward base losses 2.927822615141285
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.14962829576486195
Training Loss (progress: 0.10): 0.16479632168932257
Training Loss (progress: 0.20): 0.14304224134143675
Training Loss (progress: 0.30): 0.14610375335284848
Training Loss (progress: 0.40): 0.13638832127183584
Training Loss (progress: 0.50): 0.14036972418452465
Training Loss (progress: 0.60): 0.14458844083984573
Training Loss (progress: 0.70): 0.1479187177033732
Training Loss (progress: 0.80): 0.14766905118990156
Training Loss (progress: 0.90): 0.1448273406446291
Evaluation on validation dataset:
Step 25, mean loss 0.07288576950826306
Step 50, mean loss 0.07846042961747278
Step 75, mean loss 0.07646116820215923
Step 100, mean loss 0.08403139668376264
Step 125, mean loss 0.10299631257090541
Step 150, mean loss 0.1320927085277807
Step 175, mean loss 0.15602645719862462
Step 200, mean loss 0.26992807737375163
Step 225, mean loss 0.17931163924246002
Unrolled forward losses 2.127620562554048
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.08012133144375709
Step 50, mean loss 0.07003534150512605
Step 75, mean loss 0.0822132290742055
Step 100, mean loss 0.12164546128054782
Step 125, mean loss 0.16143786171451996
Step 150, mean loss 0.12700955162865193
Step 175, mean loss 0.14004154597628563
Step 200, mean loss 0.17418132138314363
Step 225, mean loss 0.24835372083655086
Unrolled forward losses 2.7333136594715493
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  16:54:06.815160 

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.13620271479968357
Training Loss (progress: 0.10): 0.13634711063445792
Training Loss (progress: 0.20): 0.15000865001949365
Training Loss (progress: 0.30): 0.15443647079770859
Training Loss (progress: 0.40): 0.14663534539506112
Training Loss (progress: 0.50): 0.14164898219310057
Training Loss (progress: 0.60): 0.15009457311504457
Training Loss (progress: 0.70): 0.14451696217908552
Training Loss (progress: 0.80): 0.13758452413471198
Training Loss (progress: 0.90): 0.14727585011057484
Evaluation on validation dataset:
Step 25, mean loss 0.0696842360563105
Step 50, mean loss 0.07014361477245047
Step 75, mean loss 0.07988419595110756
Step 100, mean loss 0.08656080715168962
Step 125, mean loss 0.10805271258344465
Step 150, mean loss 0.13665052306650763
Step 175, mean loss 0.16257510547833637
Step 200, mean loss 0.28385286976545787
Step 225, mean loss 0.19016972621857048
Unrolled forward losses 2.2454746446432337
Unrolled forward base losses 2.927822615141285
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.14465441047919816
Training Loss (progress: 0.10): 0.14280280203330492
Training Loss (progress: 0.20): 0.14232175690686644
Training Loss (progress: 0.30): 0.1350635757737843
Training Loss (progress: 0.40): 0.14631830567381476
Training Loss (progress: 0.50): 0.1341889263031327
Training Loss (progress: 0.60): 0.14304296639176095
Training Loss (progress: 0.70): 0.15210848851959147
Training Loss (progress: 0.80): 0.14017490995686802
Training Loss (progress: 0.90): 0.13814346812146955
Evaluation on validation dataset:
Step 25, mean loss 0.0698761873620766
Step 50, mean loss 0.07889048197302295
Step 75, mean loss 0.07391980117883547
Step 100, mean loss 0.08173013110919974
Step 125, mean loss 0.10282703717749535
Step 150, mean loss 0.13286415857650138
Step 175, mean loss 0.15764280170628225
Step 200, mean loss 0.2714386580060017
Step 225, mean loss 0.17610932751746394
Unrolled forward losses 2.1436000868948453
Unrolled forward base losses 2.927822615141285
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.1452583824777653
Training Loss (progress: 0.10): 0.13149316243946613
Training Loss (progress: 0.20): 0.12700535083848405
Training Loss (progress: 0.30): 0.1366549314154688
Training Loss (progress: 0.40): 0.1263966296895154
Training Loss (progress: 0.50): 0.1428073187251383
Training Loss (progress: 0.60): 0.13319624912700231
Training Loss (progress: 0.70): 0.15065699519104764
Training Loss (progress: 0.80): 0.1321667100671495
Training Loss (progress: 0.90): 0.14809188304850687
Evaluation on validation dataset:
Step 25, mean loss 0.0662731412230288
Step 50, mean loss 0.07423852917689955
Step 75, mean loss 0.07106708306066967
Step 100, mean loss 0.08199504611170429
Step 125, mean loss 0.10216527270386466
Step 150, mean loss 0.1370581444525841
Step 175, mean loss 0.15174770294581524
Step 200, mean loss 0.27106681594577053
Step 225, mean loss 0.17296739419054127
Unrolled forward losses 2.2009269989354916
Unrolled forward base losses 2.927822615141285
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.1389257296978591
Training Loss (progress: 0.10): 0.1384367782702922
Training Loss (progress: 0.20): 0.13258742115745425
Training Loss (progress: 0.30): 0.14231655694059686
Training Loss (progress: 0.40): 0.14380501441974725
Training Loss (progress: 0.50): 0.14068174382257953
Training Loss (progress: 0.60): 0.13382910469907155
Training Loss (progress: 0.70): 0.1298683555992235
Training Loss (progress: 0.80): 0.1360015281114633
Training Loss (progress: 0.90): 0.1316416268947594
Evaluation on validation dataset:
Step 25, mean loss 0.06607878045279411
Step 50, mean loss 0.07873543964400206
Step 75, mean loss 0.0700105998689792
Step 100, mean loss 0.07928044969721211
Step 125, mean loss 0.10070560156364063
Step 150, mean loss 0.13546172943019325
Step 175, mean loss 0.16182952870948372
Step 200, mean loss 0.2752386318907523
Step 225, mean loss 0.1694070556581771
Unrolled forward losses 2.1774799689457085
Unrolled forward base losses 2.927822615141285
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.13685573217524888
Training Loss (progress: 0.10): 0.12487803470820034
Training Loss (progress: 0.20): 0.13044020704221204
Training Loss (progress: 0.30): 0.12879306397081092
Training Loss (progress: 0.40): 0.12813585273482866
Training Loss (progress: 0.50): 0.1201357561575079
Training Loss (progress: 0.60): 0.13770930508459137
Training Loss (progress: 0.70): 0.12780033079512662
Training Loss (progress: 0.80): 0.12340348319756175
Training Loss (progress: 0.90): 0.1386063363934615
Evaluation on validation dataset:
Step 25, mean loss 0.06671469318628398
Step 50, mean loss 0.07258932967964582
Step 75, mean loss 0.07120385666326706
Step 100, mean loss 0.08019643429030979
Step 125, mean loss 0.09677206562946504
Step 150, mean loss 0.13097934209057444
Step 175, mean loss 0.15583839691705098
Step 200, mean loss 0.2710080334918804
Step 225, mean loss 0.1742853618338575
Unrolled forward losses 2.0769880018857987
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.07445670189747741
Step 50, mean loss 0.06801760884636107
Step 75, mean loss 0.07767558645988386
Step 100, mean loss 0.11862299862721289
Step 125, mean loss 0.15609008919673006
Step 150, mean loss 0.12227503174689733
Step 175, mean loss 0.1334044816097253
Step 200, mean loss 0.16665068104330533
Step 225, mean loss 0.2408771362970879
Unrolled forward losses 2.5081706854541475
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1 day, 0:54:05.747273 

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.12242346600909879
Training Loss (progress: 0.10): 0.1269125962160068
Training Loss (progress: 0.20): 0.1255862039864397
Training Loss (progress: 0.30): 0.12675283100361168
Training Loss (progress: 0.40): 0.12969022569971297
Training Loss (progress: 0.50): 0.12409092464757027
Training Loss (progress: 0.60): 0.13142728146612587
Training Loss (progress: 0.70): 0.13038048274266992
Training Loss (progress: 0.80): 0.11918508758523566
Training Loss (progress: 0.90): 0.13676425249483506
Evaluation on validation dataset:
Step 25, mean loss 0.06509133926274789
Step 50, mean loss 0.07093800652992323
Step 75, mean loss 0.0700820001082472
Step 100, mean loss 0.08066810818281442
Step 125, mean loss 0.09737582452555096
Step 150, mean loss 0.13083998861998195
Step 175, mean loss 0.15329407322978045
Step 200, mean loss 0.27196304461173826
Step 225, mean loss 0.17379441751006808
Unrolled forward losses 2.076231696034829
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0720190450731712
Step 50, mean loss 0.06591943103786094
Step 75, mean loss 0.07749409878348726
Step 100, mean loss 0.1206519940839024
Step 125, mean loss 0.1525372745601467
Step 150, mean loss 0.11969753248959172
Step 175, mean loss 0.13051985990863113
Step 200, mean loss 0.16151714649460114
Step 225, mean loss 0.23495149476352192
Unrolled forward losses 2.5200237111824038
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1 day, 4:07:09.218351 

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.12280137565600023
Training Loss (progress: 0.10): 0.13059380288190373
Training Loss (progress: 0.20): 0.12844596245915085
Training Loss (progress: 0.30): 0.12272700992910018
Training Loss (progress: 0.40): 0.1286069728856951
Training Loss (progress: 0.50): 0.13147112757929097
Training Loss (progress: 0.60): 0.11964940930506059
Training Loss (progress: 0.70): 0.12561109856074146
Training Loss (progress: 0.80): 0.13543879440284687
Training Loss (progress: 0.90): 0.140578117905737
Evaluation on validation dataset:
Step 25, mean loss 0.06315183643920833
Step 50, mean loss 0.06831960982201077
Step 75, mean loss 0.06710987627389288
Step 100, mean loss 0.0778140440929538
Step 125, mean loss 0.09676474506959129
Step 150, mean loss 0.13297321105093754
Step 175, mean loss 0.15090831912246505
Step 200, mean loss 0.2667398547197302
Step 225, mean loss 0.17164738797628748
Unrolled forward losses 2.106076392075251
Unrolled forward base losses 2.927822615141285
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.12922931287195388
Training Loss (progress: 0.10): 0.1389852962700957
Training Loss (progress: 0.20): 0.12995086508553197
Training Loss (progress: 0.30): 0.13069882345520997
Training Loss (progress: 0.40): 0.1258197191902601
Training Loss (progress: 0.50): 0.12007803508042664
Training Loss (progress: 0.60): 0.12702742822022628
Training Loss (progress: 0.70): 0.11878514252797866
Training Loss (progress: 0.80): 0.12635625340755213
Training Loss (progress: 0.90): 0.1277866621093475
Evaluation on validation dataset:
Step 25, mean loss 0.06259626115066605
Step 50, mean loss 0.0708273241384516
Step 75, mean loss 0.06863167324420597
Step 100, mean loss 0.07944326800194847
Step 125, mean loss 0.09522590488956272
Step 150, mean loss 0.13044061919485647
Step 175, mean loss 0.15294841872525464
Step 200, mean loss 0.26766364766835793
Step 225, mean loss 0.17259154082061337
Unrolled forward losses 2.0609850125168094
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.0700006561422131
Step 50, mean loss 0.0649692314062254
Step 75, mean loss 0.0775448005989067
Step 100, mean loss 0.12026416265277946
Step 125, mean loss 0.14883577744080634
Step 150, mean loss 0.11912204605420063
Step 175, mean loss 0.12832141345275866
Step 200, mean loss 0.1611914505510334
Step 225, mean loss 0.23881409105248816
Unrolled forward losses 2.502213326543894
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1 day, 7:20:52.824241 

Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.13852689363790957
Training Loss (progress: 0.10): 0.12768328378592733
Training Loss (progress: 0.20): 0.1342046825667984
Training Loss (progress: 0.30): 0.12265325119812764
Training Loss (progress: 0.40): 0.13257970649002007
Training Loss (progress: 0.50): 0.12363181529577615
Training Loss (progress: 0.60): 0.12615997949518767
Training Loss (progress: 0.70): 0.11710634332501238
Training Loss (progress: 0.80): 0.1300380008767786
Training Loss (progress: 0.90): 0.12202320686601092
Evaluation on validation dataset:
Step 25, mean loss 0.06361545296164736
Step 50, mean loss 0.0684981983585993
Step 75, mean loss 0.06665541972920551
Step 100, mean loss 0.0776948948484523
Step 125, mean loss 0.09675647928938369
Step 150, mean loss 0.1267386174686876
Step 175, mean loss 0.1503457963520426
Step 200, mean loss 0.2639263067609194
Step 225, mean loss 0.16963822532525236
Unrolled forward losses 2.0869109529551912
Unrolled forward base losses 2.927822615141285
Epoch 20
Starting epoch 20...
Training Loss (progress: 0.00): 0.12896901446691356
Training Loss (progress: 0.10): 0.11858821411723847
Training Loss (progress: 0.20): 0.13038123745163824
Training Loss (progress: 0.30): 0.12792982041525627
Training Loss (progress: 0.40): 0.12027952407306297
Training Loss (progress: 0.50): 0.12464616363568413
Training Loss (progress: 0.60): 0.1231702118135816
Training Loss (progress: 0.70): 0.1281766376765273
Training Loss (progress: 0.80): 0.12020136485478913
Training Loss (progress: 0.90): 0.13064799718071163
Evaluation on validation dataset:
Step 25, mean loss 0.0614016438149343
Step 50, mean loss 0.06996073108778524
Step 75, mean loss 0.0683190322940382
Step 100, mean loss 0.07909636865607288
Step 125, mean loss 0.09464135100272911
Step 150, mean loss 0.13162848380026823
Step 175, mean loss 0.15084193026142073
Step 200, mean loss 0.2617856200630244
Step 225, mean loss 0.17173063133185906
Unrolled forward losses 2.0894149726816496
Unrolled forward base losses 2.927822615141285
Epoch 21
Starting epoch 21...
Training Loss (progress: 0.00): 0.12556171701584454
Training Loss (progress: 0.10): 0.11978324935351264
Training Loss (progress: 0.20): 0.12279090454286322
Training Loss (progress: 0.30): 0.1257647177547072
Training Loss (progress: 0.40): 0.11790857485354769
Training Loss (progress: 0.50): 0.12414104874825324
Training Loss (progress: 0.60): 0.12230513594582308
Training Loss (progress: 0.70): 0.11809425533226488
Training Loss (progress: 0.80): 0.12313792665358475
Training Loss (progress: 0.90): 0.11797355603719868
Evaluation on validation dataset:
Step 25, mean loss 0.06235267879095648
Step 50, mean loss 0.06941816306137634
Step 75, mean loss 0.06775464167587458
Step 100, mean loss 0.07853561541413487
Step 125, mean loss 0.09518228865985576
Step 150, mean loss 0.12899360297076473
Step 175, mean loss 0.14968238247320648
Step 200, mean loss 0.2611089578661144
Step 225, mean loss 0.17313988505412733
Unrolled forward losses 2.0454828891407617
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.069490283778474
Step 50, mean loss 0.06510490590630022
Step 75, mean loss 0.07590288190993111
Step 100, mean loss 0.11922118927107346
Step 125, mean loss 0.14824790470518015
Step 150, mean loss 0.12004866433611525
Step 175, mean loss 0.12955779491096736
Step 200, mean loss 0.16192638795025582
Step 225, mean loss 0.23143981331290062
Unrolled forward losses 2.4648429357076775
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1 day, 12:13:04.419230 

Epoch 22
Starting epoch 22...
Training Loss (progress: 0.00): 0.1307981812450546
Training Loss (progress: 0.10): 0.1257581476917656
Training Loss (progress: 0.20): 0.125629820347471
Training Loss (progress: 0.30): 0.12058601904920435
Training Loss (progress: 0.40): 0.1263474900100862
Training Loss (progress: 0.50): 0.12351956011377531
Training Loss (progress: 0.60): 0.1350394058282039
Training Loss (progress: 0.70): 0.12112398945017207
Training Loss (progress: 0.80): 0.13034750301441295
Training Loss (progress: 0.90): 0.12791423092540913
Evaluation on validation dataset:
Step 25, mean loss 0.06051984261453806
Step 50, mean loss 0.06864382684341792
Step 75, mean loss 0.06690777174534152
Step 100, mean loss 0.07892108041905066
Step 125, mean loss 0.09592359171850212
Step 150, mean loss 0.12717477880611863
Step 175, mean loss 0.15537666305825787
Step 200, mean loss 0.2667614730660549
Step 225, mean loss 0.17162518953224043
Unrolled forward losses 2.032521413218456
Unrolled forward base losses 2.927822615141285
Evaluation on test dataset:
Step 25, mean loss 0.06820363343001269
Step 50, mean loss 0.06471209434807568
Step 75, mean loss 0.07607579105335115
Step 100, mean loss 0.1184537900499962
Step 125, mean loss 0.15001418126764882
Step 150, mean loss 0.11998631929706108
Step 175, mean loss 0.12986063516481294
Step 200, mean loss 0.16287913730380388
Step 225, mean loss 0.23705350383860313
Unrolled forward losses 2.5262039297101624
Unrolled forward base losses 3.162220099443931
Saved model at models/GNN_CE_E1_xresolution100-200_n100_tw25_unrolling2_time11122040.pt
Training time:  1 day, 13:53:24.197330 

Epoch 23
Starting epoch 23...
Training Loss (progress: 0.00): 0.1285773894882142
Training Loss (progress: 0.10): 0.12547037297641225
Training Loss (progress: 0.20): 0.1276695269655442
Training Loss (progress: 0.30): 0.1241723200891228
Training Loss (progress: 0.40): 0.12769392792109768
Training Loss (progress: 0.50): 0.12036057352820194
Training Loss (progress: 0.60): 0.1158057754595024
Training Loss (progress: 0.70): 0.12443306334120968
Training Loss (progress: 0.80): 0.11690384273455662
Training Loss (progress: 0.90): 0.12158755145247294
Evaluation on validation dataset:
Step 25, mean loss 0.06078050638897875
Step 50, mean loss 0.0680203769933965
Step 75, mean loss 0.06672847151896245
Step 100, mean loss 0.0779214540338855
Step 125, mean loss 0.09490035840879646
Step 150, mean loss 0.1276529216376843
Step 175, mean loss 0.14937224874333363
Step 200, mean loss 0.2578762552970555
Step 225, mean loss 0.16648256429359787
Unrolled forward losses 2.08121078748751
Unrolled forward base losses 2.927822615141285
Epoch 24
Starting epoch 24...
Training Loss (progress: 0.00): 0.12315352132045962
Training Loss (progress: 0.10): 0.1239604088046381
Training Loss (progress: 0.20): 0.13013164691762946
Training Loss (progress: 0.30): 0.11752252084700515
Training Loss (progress: 0.40): 0.13505219005022748
Training Loss (progress: 0.50): 0.12826247336165666
Training Loss (progress: 0.60): 0.1278689319150903
Training Loss (progress: 0.70): 0.12253612570777912
Training Loss (progress: 0.80): 0.1301086768752036
Training Loss (progress: 0.90): 0.12296309348618732
Evaluation on validation dataset:
Step 25, mean loss 0.0628173185477363
Step 50, mean loss 0.06803142070577925
Step 75, mean loss 0.06586174529782418
Step 100, mean loss 0.07884325937783457
Step 125, mean loss 0.09505603140196425
Step 150, mean loss 0.12656072311566946
Step 175, mean loss 0.14890218750138287
Step 200, mean loss 0.25858564165871567
Step 225, mean loss 0.17113546052848777
Unrolled forward losses 2.102095381964703
Unrolled forward base losses 2.927822615141285
Test loss: 2.5262039297101624
Training time (until epoch 22):  {datetime.timedelta(days=1, seconds=50004, microseconds=197330)}
